{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TF Object Detection_v1.4",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "1Ju-7yAFx9uqWz8rmnPmarMuvrk1XziOb",
      "authorship_tag": "ABX9TyOvJdE5YUPsvw+wZAdKk2Yk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dc40/F1CarObjectDetector/blob/master/TF_Object_Detection_v1_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HALV-0Tqbkhi",
        "outputId": "1eb0c780-f605-4edc-e2f5-6ae0c20ee3b1"
      },
      "source": [
        "!pip install tensorflow-gpu==2.4.1"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu==2.4.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/cc/a27e73cf8b23f2ce4bdd2b7089a42a7819ce6dd7366dceba406ddc5daa9c/tensorflow_gpu-2.4.1-cp37-cp37m-manylinux2010_x86_64.whl (394.3MB)\n",
            "\u001b[K     |████████████████████████████████| 394.3MB 41kB/s \n",
            "\u001b[?25hRequirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.4.1) (3.3.0)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.4.1) (1.15.0)\n",
            "Collecting gast==0.3.3\n",
            "  Downloading https://files.pythonhosted.org/packages/d6/84/759f5dd23fec8ba71952d97bcc7e2c9d7d63bdc582421f3cd4be845f0c98/gast-0.3.3-py2.py3-none-any.whl\n",
            "Collecting h5py~=2.10.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/c0/abde58b837e066bca19a3f7332d9d0493521d7dd6b48248451a9e3fe2214/h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 60.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.4.1) (1.6.3)\n",
            "Collecting tensorflow-estimator<2.5.0,>=2.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/7e/622d9849abf3afb81e482ffc170758742e392ee129ce1540611199a59237/tensorflow_estimator-2.4.0-py2.py3-none-any.whl (462kB)\n",
            "\u001b[K     |████████████████████████████████| 471kB 66.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.4.1) (1.19.5)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.4.1) (0.36.2)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.4.1) (0.12.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.4.1) (1.1.2)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.4.1) (3.7.4.3)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.4.1) (2.5.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.4.1) (1.12)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.4.1) (1.12.1)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.4.1) (3.17.3)\n",
            "Collecting grpcio~=1.32.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/06/54/1c8be62beafe7fb1548d2968e518ca040556b46b0275399d4f3186c56d79/grpcio-1.32.0-cp37-cp37m-manylinux2014_x86_64.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 63.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.4.1) (1.1.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.4.1) (0.2.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow-gpu==2.4.1) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow-gpu==2.4.1) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow-gpu==2.4.1) (1.8.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow-gpu==2.4.1) (3.3.4)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow-gpu==2.4.1) (57.0.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow-gpu==2.4.1) (1.32.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow-gpu==2.4.1) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow-gpu==2.4.1) (0.4.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow-gpu==2.4.1) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow-gpu==2.4.1) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow-gpu==2.4.1) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow-gpu==2.4.1) (3.0.4)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow-gpu==2.4.1) (4.6.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow-gpu==2.4.1) (4.2.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow-gpu==2.4.1) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow-gpu==2.4.1) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow-gpu==2.4.1) (1.3.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow-gpu==2.4.1) (3.4.1)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow-gpu==2.4.1) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow-gpu==2.4.1) (3.1.1)\n",
            "\u001b[31mERROR: tensorflow 2.5.0 has requirement gast==0.4.0, but you'll have gast 0.3.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.5.0 has requirement grpcio~=1.34.0, but you'll have grpcio 1.32.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.5.0 has requirement h5py~=3.1.0, but you'll have h5py 2.10.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.5.0 has requirement tensorflow-estimator<2.6.0,>=2.5.0rc0, but you'll have tensorflow-estimator 2.4.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: gast, h5py, tensorflow-estimator, grpcio, tensorflow-gpu\n",
            "  Found existing installation: gast 0.4.0\n",
            "    Uninstalling gast-0.4.0:\n",
            "      Successfully uninstalled gast-0.4.0\n",
            "  Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "  Found existing installation: tensorflow-estimator 2.5.0\n",
            "    Uninstalling tensorflow-estimator-2.5.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.5.0\n",
            "  Found existing installation: grpcio 1.34.1\n",
            "    Uninstalling grpcio-1.34.1:\n",
            "      Successfully uninstalled grpcio-1.34.1\n",
            "Successfully installed gast-0.3.3 grpcio-1.32.0 h5py-2.10.0 tensorflow-estimator-2.4.0 tensorflow-gpu-2.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHvbssR6chQl",
        "outputId": "de9e71a0-06aa-4d1f-a39e-140c094da368"
      },
      "source": [
        "!git clone https://github.com/tensorflow/models.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'models'...\n",
            "remote: Enumerating objects: 58658, done.\u001b[K\n",
            "remote: Counting objects: 100% (384/384), done.\u001b[K\n",
            "remote: Compressing objects: 100% (163/163), done.\u001b[K\n",
            "remote: Total 58658 (delta 233), reused 359 (delta 219), pack-reused 58274\u001b[K\n",
            "Receiving objects: 100% (58658/58658), 573.39 MiB | 31.25 MiB/s, done.\n",
            "Resolving deltas: 100% (40706/40706), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "s_notlotchay",
        "outputId": "729ca508-f635-47fe-a17b-82806a64e0d5"
      },
      "source": [
        "pwd"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mn2aAJo4chdS",
        "outputId": "63c16b7f-ac02-4f30-96ad-f9fd9afaf180"
      },
      "source": [
        "cd /content/models/research"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "sryJz2cichfp",
        "outputId": "503bb4e6-9c67-4d7f-e366-08f833d65c68"
      },
      "source": [
        "pwd"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/models/research'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2azurHIschhy"
      },
      "source": [
        "!protoc object_detection/protos/*.proto --python_out=."
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "faYosET4chkB",
        "outputId": "0b647937-f364-4a67-d18a-0bd385680a53"
      },
      "source": [
        "!git clone https://github.com/cocodataset/cocoapi.git"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'cocoapi'...\n",
            "remote: Enumerating objects: 975, done.\u001b[K\n",
            "remote: Total 975 (delta 0), reused 0 (delta 0), pack-reused 975\u001b[K\n",
            "Receiving objects: 100% (975/975), 11.72 MiB | 30.32 MiB/s, done.\n",
            "Resolving deltas: 100% (576/576), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "umhNMRufchmS",
        "outputId": "47147583-ae66-4e07-a146-95c46505f3bd"
      },
      "source": [
        "cd cocoapi/PythonAPI"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research/cocoapi/PythonAPI\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bir5TbNYchoU",
        "outputId": "a48ab50c-ca30-48e4-e144-d39b6cefced7"
      },
      "source": [
        "!make"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "python setup.py build_ext --inplace\n",
            "running build_ext\n",
            "cythoning pycocotools/_mask.pyx to pycocotools/_mask.c\n",
            "/usr/local/lib/python3.7/dist-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /content/models/research/cocoapi/PythonAPI/pycocotools/_mask.pyx\n",
            "  tree = Parsing.p_module(s, pxd, full_module_name)\n",
            "building 'pycocotools._mask' extension\n",
            "creating build\n",
            "creating build/common\n",
            "creating build/temp.linux-x86_64-3.7\n",
            "creating build/temp.linux-x86_64-3.7/pycocotools\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.7/dist-packages/numpy/core/include -I../common -I/usr/include/python3.7m -c ../common/maskApi.c -o build/temp.linux-x86_64-3.7/../common/maskApi.o -Wno-cpp -Wno-unused-function -std=c99\n",
            "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleDecode\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K../common/maskApi.c:46:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "       \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K( k=0; k<R[i].cnts[j]; k++ ) *(M++)=v; v=!v; }}\n",
            "       \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:46:49:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’\n",
            "       for( k=0; k<R[i].cnts[j]; k++ ) *(M++)=v; \u001b[01;36m\u001b[Kv\u001b[m\u001b[K=!v; }}\n",
            "                                                 \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleFrPoly\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K../common/maskApi.c:166:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "   \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K(j=0; j<k; j++) x[j]=(int)(scale*xy[j*2+0]+.5); x[k]=x[0];\n",
            "   \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:166:54:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’\n",
            "   for(j=0; j<k; j++) x[j]=(int)(scale*xy[j*2+0]+.5); \u001b[01;36m\u001b[Kx\u001b[m\u001b[K[k]=x[0];\n",
            "                                                      \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:167:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "   \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K(j=0; j<k; j++) y[j]=(int)(scale*xy[j*2+1]+.5); y[k]=y[0];\n",
            "   \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:167:54:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’\n",
            "   for(j=0; j<k; j++) y[j]=(int)(scale*xy[j*2+1]+.5); \u001b[01;36m\u001b[Ky\u001b[m\u001b[K[k]=y[0];\n",
            "                                                      \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleToString\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K../common/maskApi.c:212:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "       \u001b[01;35m\u001b[Kif\u001b[m\u001b[K(more) c |= 0x20; c+=48; s[p++]=c;\n",
            "       \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:212:27:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’\n",
            "       if(more) c |= 0x20; \u001b[01;36m\u001b[Kc\u001b[m\u001b[K+=48; s[p++]=c;\n",
            "                           \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleFrString\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K../common/maskApi.c:220:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kwhile\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "   \u001b[01;35m\u001b[Kwhile\u001b[m\u001b[K( s[m] ) m++; cnts=malloc(sizeof(uint)*m); m=0;\n",
            "   \u001b[01;35m\u001b[K^~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:220:22:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kwhile\u001b[m\u001b[K’\n",
            "   while( s[m] ) m++; \u001b[01;36m\u001b[Kcnts\u001b[m\u001b[K=malloc(sizeof(uint)*m); m=0;\n",
            "                      \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:228:5:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "     \u001b[01;35m\u001b[Kif\u001b[m\u001b[K(m>2) x+=(long) cnts[m-2]; cnts[m++]=(uint) x;\n",
            "     \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:228:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’\n",
            "     if(m>2) x+=(long) cnts[m-2]; \u001b[01;36m\u001b[Kcnts\u001b[m\u001b[K[m++]=(uint) x;\n",
            "                                  \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleToBbox\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K../common/maskApi.c:141:31:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kxp\u001b[m\u001b[K’ may be used uninitialized in this function [\u001b[01;35m\u001b[K-Wmaybe-uninitialized\u001b[m\u001b[K]\n",
            "       if(j%2==0) xp=x; else if\u001b[01;35m\u001b[K(\u001b[m\u001b[Kxp<x) { ys=0; ye=h-1; }\n",
            "                               \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.7/dist-packages/numpy/core/include -I../common -I/usr/include/python3.7m -c pycocotools/_mask.c -o build/temp.linux-x86_64-3.7/pycocotools/_mask.o -Wno-cpp -Wno-unused-function -std=c99\n",
            "creating build/lib.linux-x86_64-3.7\n",
            "creating build/lib.linux-x86_64-3.7/pycocotools\n",
            "x86_64-linux-gnu-gcc -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.7/../common/maskApi.o build/temp.linux-x86_64-3.7/pycocotools/_mask.o -o build/lib.linux-x86_64-3.7/pycocotools/_mask.cpython-37m-x86_64-linux-gnu.so\n",
            "copying build/lib.linux-x86_64-3.7/pycocotools/_mask.cpython-37m-x86_64-linux-gnu.so -> pycocotools\n",
            "rm -rf build\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7rq3QE2chs9"
      },
      "source": [
        "cp -r pycocotools /content/models/research"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WqDlptn-chxe",
        "outputId": "c298e913-9433-48ba-ee49-d5cc4984c33b"
      },
      "source": [
        "cd .."
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research/cocoapi\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AjkhcxYkch0J",
        "outputId": "ff2aa1bc-b6bd-4f2d-f597-f8565ba9d5fe"
      },
      "source": [
        "cd .."
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCTjXExach2q"
      },
      "source": [
        "cp object_detection/packages/tf2/setup.py ."
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqwPm5BAch4-",
        "outputId": "3485c57a-5db9-414c-fb24-0c17debc6a47"
      },
      "source": [
        "!python -m pip install ."
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing /content/models/research\n",
            "Collecting avro-python3\n",
            "  Downloading https://files.pythonhosted.org/packages/cc/97/7a6970380ca8db9139a3cc0b0e3e0dd3e4bc584fb3644e1d06e71e1a55f0/avro-python3-1.10.2.tar.gz\n",
            "Collecting apache-beam\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/28/f0/83e04f7a693695f4ce3765fce1e573abbbf32153a309829651de056f8924/apache_beam-2.31.0-cp37-cp37m-manylinux2010_x86_64.whl (9.7MB)\n",
            "\u001b[K     |████████████████████████████████| 9.7MB 11.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (7.1.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (4.2.6)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (3.2.2)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.29.23)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.5.5)\n",
            "Collecting tf-slim\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/97/b0f4a64df018ca018cc035d44f2ef08f91e2e8aa67271f6f19633a015ff7/tf_slim-1.1.0-py2.py3-none-any.whl (352kB)\n",
            "\u001b[K     |████████████████████████████████| 358kB 51.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.15.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.0.2)\n",
            "Collecting lvis\n",
            "  Downloading https://files.pythonhosted.org/packages/72/b6/1992240ab48310b5360bfdd1d53163f43bb97d90dc5dc723c67d41c38e78/lvis-0.5.3-py3-none-any.whl\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.4.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.1.5)\n",
            "Collecting tf-models-official\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/96/08/81bbc275e8e9c6d1e03dd26daec3a67f45e6322804cbce3d51f93eae1961/tf_models_official-2.5.0-py2.py3-none-any.whl (1.6MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6MB 35.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio<2,>=1.29.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.32.0)\n",
            "Requirement already satisfied: httplib2<0.20.0,>=0.8 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (0.17.4)\n",
            "Collecting dill<0.3.2,>=0.3.1.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c7/11/345f3173809cea7f1a193bfbf02403fff250a3360e0e118a1630985e547d/dill-0.3.1.1.tar.gz (151kB)\n",
            "\u001b[K     |████████████████████████████████| 153kB 56.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<1.21.0,>=1.14.3 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.19.5)\n",
            "Requirement already satisfied: oauth2client<5,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (4.1.3)\n",
            "Requirement already satisfied: pyarrow<5.0.0,>=0.15.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (3.0.0)\n",
            "Requirement already satisfied: pytz>=2018.3 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (2018.9)\n",
            "Requirement already satisfied: typing-extensions<3.8.0,>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (3.7.4.3)\n",
            "Requirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.3.0)\n",
            "Collecting future<1.0.0,>=0.18.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/0b/38b06fd9b92dc2b68d58b75f900e97884c45bedd2ff83203d933cf5851c9/future-0.18.2.tar.gz (829kB)\n",
            "\u001b[K     |████████████████████████████████| 829kB 47.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: pymongo<4.0.0,>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (3.11.4)\n",
            "Collecting hdfs<3.0.0,>=2.1.0\n",
            "  Downloading https://files.pythonhosted.org/packages/08/f7/4c3fad73123a24d7394b6f40d1ec9c1cbf2e921cfea1797216ffd0a51fb1/hdfs-2.6.0-py3-none-any.whl\n",
            "Requirement already satisfied: python-dateutil<3,>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (2.8.1)\n",
            "Collecting fastavro<2,>=0.21.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/92/10ee74edb0a39f4a7af1cf271b3ac725c54f5c243c26fa5059cd794d15d7/fastavro-1.4.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3MB 60.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.7)\n",
            "Collecting requests<3.0.0,>=2.24.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/c1/24814557f1d22c56d50280771a17307e6bf87b70727d975fd6b2ce6b014a/requests-2.25.1-py2.py3-none-any.whl (61kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 8.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf<4,>=3.12.2 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (3.17.3)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->object-detection==0.1) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->object-detection==0.1) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->object-detection==0.1) (1.3.1)\n",
            "Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from tf-slim->object-detection==0.1) (0.12.0)\n",
            "Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.7/dist-packages (from pycocotools->object-detection==0.1) (57.0.0)\n",
            "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (4.1.2.30)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (4.0.1)\n",
            "Collecting pyyaml>=5.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7a/a5/393c087efdc78091afa2af9f1378762f9821c9c1d7a22c5753fb5ac5f97a/PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636kB)\n",
            "\u001b[K     |████████████████████████████████| 645kB 60.3MB/s \n",
            "\u001b[?25hCollecting tensorflow-addons\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/66/4b/e893d194e626c24b3df2253066aa418f46a432fdb68250cde14bf9bb0700/tensorflow_addons-0.13.0-cp37-cp37m-manylinux2010_x86_64.whl (679kB)\n",
            "\u001b[K     |████████████████████████████████| 686kB 61.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (0.12.0)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ac/aa/1437691b0c7c83086ebb79ce2da16e00bef024f24fec2a5161c35476f499/sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 60.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow>=2.5.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (2.5.0)\n",
            "Collecting seqeval\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9d/2d/233c79d5b4e5ab1dbf111242299153f3caddddbb691219f363ad55ce783d/seqeval-1.2.2.tar.gz (43kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 8.6MB/s \n",
            "\u001b[?25hCollecting py-cpuinfo>=3.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e6/ba/77120e44cbe9719152415b97d5bfb29f4053ee987d6cb63f55ce7d50fadc/py-cpuinfo-8.0.0.tar.gz (99kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 13.7MB/s \n",
            "\u001b[?25hCollecting sacrebleu\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/57/0c7ca4e31a126189dab99c19951910bd081dea5bbd25f24b77107750eae7/sacrebleu-1.5.1-py3-none-any.whl (54kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 9.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: gin-config in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (0.4.0)\n",
            "Collecting tensorflow-model-optimization>=0.4.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/78/8f/f6969dc64709c5c5e22cfd7057a83adbc927e6855a431b234168222cbf03/tensorflow_model_optimization-0.6.0-py2.py3-none-any.whl (211kB)\n",
            "\u001b[K     |████████████████████████████████| 215kB 64.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (5.4.8)\n",
            "Collecting opencv-python-headless\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/53/48036b28d46c1ed45ec655ae7ef6caab45e4452834d63817fdef64f333a3/opencv_python_headless-4.5.3.56-cp37-cp37m-manylinux2014_x86_64.whl (37.1MB)\n",
            "\u001b[K     |████████████████████████████████| 37.2MB 140kB/s \n",
            "\u001b[?25hRequirement already satisfied: google-cloud-bigquery>=0.31.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (1.21.0)\n",
            "Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (1.5.12)\n",
            "Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (1.12.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.7/dist-packages (from oauth2client<5,>=2.0.1->apache-beam->object-detection==0.1) (0.2.8)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from oauth2client<5,>=2.0.1->apache-beam->object-detection==0.1) (4.7.2)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from oauth2client<5,>=2.0.1->apache-beam->object-detection==0.1) (0.4.8)\n",
            "Requirement already satisfied: docopt in /usr/local/lib/python3.7/dist-packages (from hdfs<3.0.0,>=2.1.0->apache-beam->object-detection==0.1) (0.6.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (3.0.4)\n",
            "Requirement already satisfied: importlib-resources; python_version < \"3.9\" in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (5.2.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (0.1.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (4.41.1)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (2.3)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (21.2.0)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons->tf-models-official->object-detection==0.1) (2.7.1)\n",
            "Collecting h5py~=3.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9d/74/9eae2bedd8201ab464308f42c601a12d79727a1c87f0c867fdefb212c6cf/h5py-3.1.0-cp37-cp37m-manylinux1_x86_64.whl (4.0MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0MB 55.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-nightly~=2.5.0.dev in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (2.5.0.dev2021032900)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (1.6.3)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (1.12.1)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (1.1.2)\n",
            "Requirement already satisfied: tensorboard~=2.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (2.5.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (1.12)\n",
            "Collecting gast==0.4.0\n",
            "  Downloading https://files.pythonhosted.org/packages/b6/48/583c032b79ae5b3daa02225a675aeb673e58d2cb698e78510feceb11958c/gast-0.4.0-py3-none-any.whl\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (0.36.2)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (0.2.0)\n",
            "Collecting tensorflow-estimator<2.6.0,>=2.5.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ec/78/b27f73e923becc6e79e18fe112cf75e3200d1ee35b0dba8fa46181bce56c/tensorflow_estimator-2.5.0-py2.py3-none-any.whl (462kB)\n",
            "\u001b[K     |████████████████████████████████| 471kB 57.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (3.3.0)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval->tf-models-official->object-detection==0.1) (0.22.2.post1)\n",
            "Collecting portalocker==2.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/89/a6/3814b7107e0788040870e8825eebf214d72166adf656ba7d4bf14759a06a/portalocker-2.0.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: google-resumable-media!=0.4.0,<0.5.0dev,>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from google-cloud-bigquery>=0.31.0->tf-models-official->object-detection==0.1) (0.4.1)\n",
            "Requirement already satisfied: google-cloud-core<2.0dev,>=1.0.3 in /usr/local/lib/python3.7/dist-packages (from google-cloud-bigquery>=0.31.0->tf-models-official->object-detection==0.1) (1.0.3)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official->object-detection==0.1) (5.0.2)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (0.0.4)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (3.0.1)\n",
            "Requirement already satisfied: google-auth>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (1.32.1)\n",
            "Requirement already satisfied: google-api-core<2dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (1.26.3)\n",
            "Requirement already satisfied: zipp>=3.1.0; python_version < \"3.10\" in /usr/local/lib/python3.7/dist-packages (from importlib-resources; python_version < \"3.9\"->tensorflow-datasets->tf-models-official->object-detection==0.1) (3.4.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-metadata->tensorflow-datasets->tf-models-official->object-detection==0.1) (1.53.0)\n",
            "Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (1.5.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (3.3.4)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (1.8.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (0.4.4)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official->object-detection==0.1) (1.0.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official->object-detection==0.1) (1.3)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (4.2.2)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (20.9)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (4.6.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (1.3.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (3.1.1)\n",
            "Building wheels for collected packages: object-detection, avro-python3, dill, future, seqeval, py-cpuinfo\n",
            "  Building wheel for object-detection (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for object-detection: filename=object_detection-0.1-cp37-none-any.whl size=1658497 sha256=a20e9717908c18e0c7f0cb2cfbb8276a44e0f4e1071552e2693430abbe687883\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-5_p2vpk2/wheels/94/49/4b/39b051683087a22ef7e80ec52152a27249d1a644ccf4e442ea\n",
            "  Building wheel for avro-python3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for avro-python3: filename=avro_python3-1.10.2-cp37-none-any.whl size=44011 sha256=1e7b42434246656325ad091587a65ad7095328fe2921fac5fca8f0fefe963498\n",
            "  Stored in directory: /root/.cache/pip/wheels/ee/ee/18/c466221ca6900e3efce2f4ea9c329288808679aecdcb2838d3\n",
            "  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dill: filename=dill-0.3.1.1-cp37-none-any.whl size=78545 sha256=a3831552f59c778dd5272aa388d95b8e20f6e1ba8507336c313be713d998c745\n",
            "  Stored in directory: /root/.cache/pip/wheels/59/b1/91/f02e76c732915c4015ab4010f3015469866c1eb9b14058d8e7\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for future: filename=future-0.18.2-cp37-none-any.whl size=491070 sha256=5525a6b62b9a02dce0318ff08efdbe91c6c1e9eff159c5d72ad7c81e81d13550\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/99/a0/81daf51dcd359a9377b110a8a886b3895921802d2fc1b2397e\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-cp37-none-any.whl size=16184 sha256=69826ad19fcde4f2293b8e09dd636dc5b6dd078817035edead1c9af96bbec31c\n",
            "  Stored in directory: /root/.cache/pip/wheels/52/df/1b/45d75646c37428f7e626214704a0e35bd3cfc32eda37e59e5f\n",
            "  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py-cpuinfo: filename=py_cpuinfo-8.0.0-cp37-none-any.whl size=22258 sha256=aad10b129c6e010de869ca7f53110ac53ebbfb545744732bb20f04d7e4fd1e19\n",
            "  Stored in directory: /root/.cache/pip/wheels/2e/15/f5/aa2a056d223903b52cf4870134e3a01df0c723816835dd08db\n",
            "Successfully built object-detection avro-python3 dill future seqeval py-cpuinfo\n",
            "\u001b[31mERROR: tensorflow 2.5.0 has requirement grpcio~=1.34.0, but you'll have grpcio 1.32.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-gpu 2.4.1 has requirement gast==0.3.3, but you'll have gast 0.4.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-gpu 2.4.1 has requirement h5py~=2.10.0, but you'll have h5py 3.1.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-gpu 2.4.1 has requirement tensorflow-estimator<2.5.0,>=2.4.0, but you'll have tensorflow-estimator 2.5.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: multiprocess 0.70.12.2 has requirement dill>=0.3.4, but you'll have dill 0.3.1.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement requests~=2.23.0, but you'll have requests 2.25.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: apache-beam 2.31.0 has requirement avro-python3!=1.9.2,<1.10.0,>=1.8.1, but you'll have avro-python3 1.10.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: avro-python3, dill, future, requests, hdfs, fastavro, apache-beam, tf-slim, lvis, pyyaml, tensorflow-addons, sentencepiece, seqeval, py-cpuinfo, portalocker, sacrebleu, tensorflow-model-optimization, opencv-python-headless, tf-models-official, object-detection, h5py, gast, tensorflow-estimator\n",
            "  Found existing installation: dill 0.3.4\n",
            "    Uninstalling dill-0.3.4:\n",
            "      Successfully uninstalled dill-0.3.4\n",
            "  Found existing installation: future 0.16.0\n",
            "    Uninstalling future-0.16.0:\n",
            "      Successfully uninstalled future-0.16.0\n",
            "  Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Found existing installation: h5py 2.10.0\n",
            "    Uninstalling h5py-2.10.0:\n",
            "      Successfully uninstalled h5py-2.10.0\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorflow-estimator 2.4.0\n",
            "    Uninstalling tensorflow-estimator-2.4.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.4.0\n",
            "Successfully installed apache-beam-2.31.0 avro-python3-1.10.2 dill-0.3.1.1 fastavro-1.4.2 future-0.18.2 gast-0.4.0 h5py-3.1.0 hdfs-2.6.0 lvis-0.5.3 object-detection-0.1 opencv-python-headless-4.5.3.56 portalocker-2.0.0 py-cpuinfo-8.0.0 pyyaml-5.4.1 requests-2.25.1 sacrebleu-1.5.1 sentencepiece-0.1.96 seqeval-1.2.2 tensorflow-addons-0.13.0 tensorflow-estimator-2.5.0 tensorflow-model-optimization-0.6.0 tf-models-official-2.5.0 tf-slim-1.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7rcc5JIch7U",
        "outputId": "e11aff33-c51b-4b44-9aaf-9aef0f62e659"
      },
      "source": [
        "!python object_detection/builders/model_builder_tf2_test.py"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-07-11 13:58:51.499128: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "Running tests under Python 3.7.10: /usr/bin/python3\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
            "2021-07-11 13:58:53.912180: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "2021-07-11 13:58:53.913002: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
            "2021-07-11 13:58:53.968204: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-11 13:58:53.968819: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\n",
            "coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n",
            "2021-07-11 13:58:53.968855: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-07-11 13:58:54.029566: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
            "2021-07-11 13:58:54.029642: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
            "2021-07-11 13:58:54.143624: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
            "2021-07-11 13:58:54.181682: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
            "2021-07-11 13:58:54.380390: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-07-11 13:58:54.394839: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
            "2021-07-11 13:58:54.399200: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
            "2021-07-11 13:58:54.399341: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-11 13:58:54.399993: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-11 13:58:54.400524: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
            "2021-07-11 13:58:54.400881: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2021-07-11 13:58:54.401031: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "2021-07-11 13:58:54.401175: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-11 13:58:54.401782: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\n",
            "coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n",
            "2021-07-11 13:58:54.401813: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-07-11 13:58:54.401844: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
            "2021-07-11 13:58:54.401862: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
            "2021-07-11 13:58:54.401881: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
            "2021-07-11 13:58:54.401902: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
            "2021-07-11 13:58:54.401929: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-07-11 13:58:54.401953: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
            "2021-07-11 13:58:54.401976: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
            "2021-07-11 13:58:54.402045: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-11 13:58:54.402616: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-11 13:58:54.403112: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
            "2021-07-11 13:58:54.403154: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-07-11 13:58:55.090192: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-07-11 13:58:55.090249: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
            "2021-07-11 13:58:55.090258: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
            "2021-07-11 13:58:55.090472: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-11 13:58:55.091090: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-11 13:58:55.091638: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-11 13:58:55.092135: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2021-07-11 13:58:55.092174: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14957 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "W0711 13:58:55.380081 140649210214272 model_builder.py:1088] Building experimental DeepMAC meta-arch. Some features may be omitted.\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 1.9s\n",
            "I0711 13:58:55.801658 140649210214272 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 1.9s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.56s\n",
            "I0711 13:58:56.363156 140649210214272 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.56s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.36s\n",
            "I0711 13:58:56.722324 140649210214272 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.36s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.32s\n",
            "I0711 13:58:57.044872 140649210214272 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.32s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
            "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
            "W0711 13:58:57.046968 140649210214272 mobilenet_v2.py:286] `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "9412608/9406464 [==============================] - 0s 0us/step\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 0.95s\n",
            "I0711 13:58:57.993890 140649210214272 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 0.95s\n",
            "[  FAILED  ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "I0711 13:58:57.996520 140649210214272 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.03s\n",
            "I0711 13:58:58.023272 140649210214272 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.03s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.02s\n",
            "I0711 13:58:58.042817 140649210214272 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.02s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s\n",
            "I0711 13:58:58.062610 140649210214272 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.13s\n",
            "I0711 13:58:58.196724 140649210214272 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.13s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.13s\n",
            "I0711 13:58:58.329279 140649210214272 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.13s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.14s\n",
            "I0711 13:58:58.467343 140649210214272 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.14s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.14s\n",
            "I0711 13:58:58.604243 140649210214272 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.14s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.14s\n",
            "I0711 13:58:58.745149 140649210214272 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.14s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.04s\n",
            "I0711 13:58:58.785843 140649210214272 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.04s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "I0711 13:58:59.058013 140649210214272 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b0\n",
            "I0711 13:58:59.058174 140649210214272 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 64\n",
            "I0711 13:58:59.058230 140649210214272 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 3\n",
            "I0711 13:58:59.062467 140649210214272 efficientnet_model.py:147] round_filter input=32 output=32\n",
            "I0711 13:58:59.077213 140649210214272 efficientnet_model.py:147] round_filter input=32 output=32\n",
            "I0711 13:58:59.077328 140649210214272 efficientnet_model.py:147] round_filter input=16 output=16\n",
            "I0711 13:58:59.132050 140649210214272 efficientnet_model.py:147] round_filter input=16 output=16\n",
            "I0711 13:58:59.132173 140649210214272 efficientnet_model.py:147] round_filter input=24 output=24\n",
            "I0711 13:58:59.264149 140649210214272 efficientnet_model.py:147] round_filter input=24 output=24\n",
            "I0711 13:58:59.264303 140649210214272 efficientnet_model.py:147] round_filter input=40 output=40\n",
            "I0711 13:58:59.395497 140649210214272 efficientnet_model.py:147] round_filter input=40 output=40\n",
            "I0711 13:58:59.395641 140649210214272 efficientnet_model.py:147] round_filter input=80 output=80\n",
            "I0711 13:58:59.597434 140649210214272 efficientnet_model.py:147] round_filter input=80 output=80\n",
            "I0711 13:58:59.597618 140649210214272 efficientnet_model.py:147] round_filter input=112 output=112\n",
            "I0711 13:58:59.797183 140649210214272 efficientnet_model.py:147] round_filter input=112 output=112\n",
            "I0711 13:58:59.797341 140649210214272 efficientnet_model.py:147] round_filter input=192 output=192\n",
            "I0711 13:59:00.177087 140649210214272 efficientnet_model.py:147] round_filter input=192 output=192\n",
            "I0711 13:59:00.177247 140649210214272 efficientnet_model.py:147] round_filter input=320 output=320\n",
            "I0711 13:59:00.241568 140649210214272 efficientnet_model.py:147] round_filter input=1280 output=1280\n",
            "I0711 13:59:00.267815 140649210214272 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0711 13:59:00.336806 140649210214272 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b1\n",
            "I0711 13:59:00.336946 140649210214272 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 88\n",
            "I0711 13:59:00.336993 140649210214272 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 4\n",
            "I0711 13:59:00.341204 140649210214272 efficientnet_model.py:147] round_filter input=32 output=32\n",
            "I0711 13:59:00.354748 140649210214272 efficientnet_model.py:147] round_filter input=32 output=32\n",
            "I0711 13:59:00.354853 140649210214272 efficientnet_model.py:147] round_filter input=16 output=16\n",
            "I0711 13:59:00.463995 140649210214272 efficientnet_model.py:147] round_filter input=16 output=16\n",
            "I0711 13:59:00.464129 140649210214272 efficientnet_model.py:147] round_filter input=24 output=24\n",
            "I0711 13:59:00.678424 140649210214272 efficientnet_model.py:147] round_filter input=24 output=24\n",
            "I0711 13:59:00.678589 140649210214272 efficientnet_model.py:147] round_filter input=40 output=40\n",
            "I0711 13:59:00.879857 140649210214272 efficientnet_model.py:147] round_filter input=40 output=40\n",
            "I0711 13:59:00.880012 140649210214272 efficientnet_model.py:147] round_filter input=80 output=80\n",
            "I0711 13:59:01.155412 140649210214272 efficientnet_model.py:147] round_filter input=80 output=80\n",
            "I0711 13:59:01.155586 140649210214272 efficientnet_model.py:147] round_filter input=112 output=112\n",
            "I0711 13:59:01.430155 140649210214272 efficientnet_model.py:147] round_filter input=112 output=112\n",
            "I0711 13:59:01.430313 140649210214272 efficientnet_model.py:147] round_filter input=192 output=192\n",
            "I0711 13:59:01.769102 140649210214272 efficientnet_model.py:147] round_filter input=192 output=192\n",
            "I0711 13:59:01.769261 140649210214272 efficientnet_model.py:147] round_filter input=320 output=320\n",
            "I0711 13:59:01.905709 140649210214272 efficientnet_model.py:147] round_filter input=1280 output=1280\n",
            "I0711 13:59:01.931062 140649210214272 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0711 13:59:02.006572 140649210214272 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b2\n",
            "I0711 13:59:02.006735 140649210214272 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 112\n",
            "I0711 13:59:02.006797 140649210214272 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 5\n",
            "I0711 13:59:02.011009 140649210214272 efficientnet_model.py:147] round_filter input=32 output=32\n",
            "I0711 13:59:02.026529 140649210214272 efficientnet_model.py:147] round_filter input=32 output=32\n",
            "I0711 13:59:02.026656 140649210214272 efficientnet_model.py:147] round_filter input=16 output=16\n",
            "I0711 13:59:02.134208 140649210214272 efficientnet_model.py:147] round_filter input=16 output=16\n",
            "I0711 13:59:02.134340 140649210214272 efficientnet_model.py:147] round_filter input=24 output=24\n",
            "I0711 13:59:02.337326 140649210214272 efficientnet_model.py:147] round_filter input=24 output=24\n",
            "I0711 13:59:02.337498 140649210214272 efficientnet_model.py:147] round_filter input=40 output=48\n",
            "I0711 13:59:02.544071 140649210214272 efficientnet_model.py:147] round_filter input=40 output=48\n",
            "I0711 13:59:02.544247 140649210214272 efficientnet_model.py:147] round_filter input=80 output=88\n",
            "I0711 13:59:02.814466 140649210214272 efficientnet_model.py:147] round_filter input=80 output=88\n",
            "I0711 13:59:02.814648 140649210214272 efficientnet_model.py:147] round_filter input=112 output=120\n",
            "I0711 13:59:03.230555 140649210214272 efficientnet_model.py:147] round_filter input=112 output=120\n",
            "I0711 13:59:03.230712 140649210214272 efficientnet_model.py:147] round_filter input=192 output=208\n",
            "I0711 13:59:03.570904 140649210214272 efficientnet_model.py:147] round_filter input=192 output=208\n",
            "I0711 13:59:03.571084 140649210214272 efficientnet_model.py:147] round_filter input=320 output=352\n",
            "I0711 13:59:03.706103 140649210214272 efficientnet_model.py:147] round_filter input=1280 output=1408\n",
            "I0711 13:59:03.732315 140649210214272 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0711 13:59:03.805896 140649210214272 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b3\n",
            "I0711 13:59:03.806069 140649210214272 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 160\n",
            "I0711 13:59:03.806139 140649210214272 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 6\n",
            "I0711 13:59:03.810298 140649210214272 efficientnet_model.py:147] round_filter input=32 output=40\n",
            "I0711 13:59:03.824305 140649210214272 efficientnet_model.py:147] round_filter input=32 output=40\n",
            "I0711 13:59:03.824415 140649210214272 efficientnet_model.py:147] round_filter input=16 output=24\n",
            "I0711 13:59:03.933113 140649210214272 efficientnet_model.py:147] round_filter input=16 output=24\n",
            "I0711 13:59:03.933386 140649210214272 efficientnet_model.py:147] round_filter input=24 output=32\n",
            "I0711 13:59:04.136901 140649210214272 efficientnet_model.py:147] round_filter input=24 output=32\n",
            "I0711 13:59:04.137075 140649210214272 efficientnet_model.py:147] round_filter input=40 output=48\n",
            "I0711 13:59:04.336927 140649210214272 efficientnet_model.py:147] round_filter input=40 output=48\n",
            "I0711 13:59:04.337102 140649210214272 efficientnet_model.py:147] round_filter input=80 output=96\n",
            "I0711 13:59:04.683591 140649210214272 efficientnet_model.py:147] round_filter input=80 output=96\n",
            "I0711 13:59:04.683763 140649210214272 efficientnet_model.py:147] round_filter input=112 output=136\n",
            "I0711 13:59:05.025194 140649210214272 efficientnet_model.py:147] round_filter input=112 output=136\n",
            "I0711 13:59:05.025365 140649210214272 efficientnet_model.py:147] round_filter input=192 output=232\n",
            "I0711 13:59:05.428225 140649210214272 efficientnet_model.py:147] round_filter input=192 output=232\n",
            "I0711 13:59:05.428393 140649210214272 efficientnet_model.py:147] round_filter input=320 output=384\n",
            "I0711 13:59:05.563699 140649210214272 efficientnet_model.py:147] round_filter input=1280 output=1536\n",
            "I0711 13:59:05.587972 140649210214272 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0711 13:59:05.668399 140649210214272 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b4\n",
            "I0711 13:59:05.668567 140649210214272 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 224\n",
            "I0711 13:59:05.668640 140649210214272 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 7\n",
            "I0711 13:59:05.672809 140649210214272 efficientnet_model.py:147] round_filter input=32 output=48\n",
            "I0711 13:59:05.686641 140649210214272 efficientnet_model.py:147] round_filter input=32 output=48\n",
            "I0711 13:59:05.686750 140649210214272 efficientnet_model.py:147] round_filter input=16 output=24\n",
            "I0711 13:59:05.792822 140649210214272 efficientnet_model.py:147] round_filter input=16 output=24\n",
            "I0711 13:59:05.792959 140649210214272 efficientnet_model.py:147] round_filter input=24 output=32\n",
            "I0711 13:59:06.063068 140649210214272 efficientnet_model.py:147] round_filter input=24 output=32\n",
            "I0711 13:59:06.063245 140649210214272 efficientnet_model.py:147] round_filter input=40 output=56\n",
            "I0711 13:59:06.335902 140649210214272 efficientnet_model.py:147] round_filter input=40 output=56\n",
            "I0711 13:59:06.336075 140649210214272 efficientnet_model.py:147] round_filter input=80 output=112\n",
            "I0711 13:59:06.921825 140649210214272 efficientnet_model.py:147] round_filter input=80 output=112\n",
            "I0711 13:59:06.922010 140649210214272 efficientnet_model.py:147] round_filter input=112 output=160\n",
            "I0711 13:59:07.323512 140649210214272 efficientnet_model.py:147] round_filter input=112 output=160\n",
            "I0711 13:59:07.323681 140649210214272 efficientnet_model.py:147] round_filter input=192 output=272\n",
            "I0711 13:59:07.867916 140649210214272 efficientnet_model.py:147] round_filter input=192 output=272\n",
            "I0711 13:59:07.868093 140649210214272 efficientnet_model.py:147] round_filter input=320 output=448\n",
            "I0711 13:59:08.002764 140649210214272 efficientnet_model.py:147] round_filter input=1280 output=1792\n",
            "I0711 13:59:08.026759 140649210214272 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0711 13:59:08.113618 140649210214272 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b5\n",
            "I0711 13:59:08.113763 140649210214272 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 288\n",
            "I0711 13:59:08.113815 140649210214272 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 7\n",
            "I0711 13:59:08.117964 140649210214272 efficientnet_model.py:147] round_filter input=32 output=48\n",
            "I0711 13:59:08.131822 140649210214272 efficientnet_model.py:147] round_filter input=32 output=48\n",
            "I0711 13:59:08.131936 140649210214272 efficientnet_model.py:147] round_filter input=16 output=24\n",
            "I0711 13:59:08.290612 140649210214272 efficientnet_model.py:147] round_filter input=16 output=24\n",
            "I0711 13:59:08.290764 140649210214272 efficientnet_model.py:147] round_filter input=24 output=40\n",
            "I0711 13:59:08.621977 140649210214272 efficientnet_model.py:147] round_filter input=24 output=40\n",
            "I0711 13:59:08.622130 140649210214272 efficientnet_model.py:147] round_filter input=40 output=64\n",
            "I0711 13:59:08.958444 140649210214272 efficientnet_model.py:147] round_filter input=40 output=64\n",
            "I0711 13:59:08.958612 140649210214272 efficientnet_model.py:147] round_filter input=80 output=128\n",
            "I0711 13:59:09.424235 140649210214272 efficientnet_model.py:147] round_filter input=80 output=128\n",
            "I0711 13:59:09.424396 140649210214272 efficientnet_model.py:147] round_filter input=112 output=176\n",
            "I0711 13:59:09.888801 140649210214272 efficientnet_model.py:147] round_filter input=112 output=176\n",
            "I0711 13:59:09.888958 140649210214272 efficientnet_model.py:147] round_filter input=192 output=304\n",
            "I0711 13:59:10.493459 140649210214272 efficientnet_model.py:147] round_filter input=192 output=304\n",
            "I0711 13:59:10.493625 140649210214272 efficientnet_model.py:147] round_filter input=320 output=512\n",
            "I0711 13:59:10.874530 140649210214272 efficientnet_model.py:147] round_filter input=1280 output=2048\n",
            "I0711 13:59:10.903858 140649210214272 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0711 13:59:11.003633 140649210214272 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b6\n",
            "I0711 13:59:11.003776 140649210214272 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 384\n",
            "I0711 13:59:11.003837 140649210214272 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 8\n",
            "I0711 13:59:11.007950 140649210214272 efficientnet_model.py:147] round_filter input=32 output=56\n",
            "I0711 13:59:11.022097 140649210214272 efficientnet_model.py:147] round_filter input=32 output=56\n",
            "I0711 13:59:11.022201 140649210214272 efficientnet_model.py:147] round_filter input=16 output=32\n",
            "I0711 13:59:11.186018 140649210214272 efficientnet_model.py:147] round_filter input=16 output=32\n",
            "I0711 13:59:11.186166 140649210214272 efficientnet_model.py:147] round_filter input=24 output=40\n",
            "I0711 13:59:11.590508 140649210214272 efficientnet_model.py:147] round_filter input=24 output=40\n",
            "I0711 13:59:11.590664 140649210214272 efficientnet_model.py:147] round_filter input=40 output=72\n",
            "I0711 13:59:11.993004 140649210214272 efficientnet_model.py:147] round_filter input=40 output=72\n",
            "I0711 13:59:11.993161 140649210214272 efficientnet_model.py:147] round_filter input=80 output=144\n",
            "I0711 13:59:12.533879 140649210214272 efficientnet_model.py:147] round_filter input=80 output=144\n",
            "I0711 13:59:12.534036 140649210214272 efficientnet_model.py:147] round_filter input=112 output=200\n",
            "I0711 13:59:13.081076 140649210214272 efficientnet_model.py:147] round_filter input=112 output=200\n",
            "I0711 13:59:13.081238 140649210214272 efficientnet_model.py:147] round_filter input=192 output=344\n",
            "I0711 13:59:13.822456 140649210214272 efficientnet_model.py:147] round_filter input=192 output=344\n",
            "I0711 13:59:13.822624 140649210214272 efficientnet_model.py:147] round_filter input=320 output=576\n",
            "I0711 13:59:14.021044 140649210214272 efficientnet_model.py:147] round_filter input=1280 output=2304\n",
            "I0711 13:59:14.045507 140649210214272 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0711 13:59:14.156811 140649210214272 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b7\n",
            "I0711 13:59:14.156960 140649210214272 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 384\n",
            "I0711 13:59:14.157008 140649210214272 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 8\n",
            "I0711 13:59:14.161133 140649210214272 efficientnet_model.py:147] round_filter input=32 output=64\n",
            "I0711 13:59:14.174936 140649210214272 efficientnet_model.py:147] round_filter input=32 output=64\n",
            "I0711 13:59:14.175033 140649210214272 efficientnet_model.py:147] round_filter input=16 output=32\n",
            "I0711 13:59:14.388535 140649210214272 efficientnet_model.py:147] round_filter input=16 output=32\n",
            "I0711 13:59:14.388684 140649210214272 efficientnet_model.py:147] round_filter input=24 output=48\n",
            "I0711 13:59:15.098135 140649210214272 efficientnet_model.py:147] round_filter input=24 output=48\n",
            "I0711 13:59:15.098333 140649210214272 efficientnet_model.py:147] round_filter input=40 output=80\n",
            "I0711 13:59:15.571402 140649210214272 efficientnet_model.py:147] round_filter input=40 output=80\n",
            "I0711 13:59:15.571591 140649210214272 efficientnet_model.py:147] round_filter input=80 output=160\n",
            "I0711 13:59:16.273981 140649210214272 efficientnet_model.py:147] round_filter input=80 output=160\n",
            "I0711 13:59:16.274151 140649210214272 efficientnet_model.py:147] round_filter input=112 output=224\n",
            "I0711 13:59:16.951001 140649210214272 efficientnet_model.py:147] round_filter input=112 output=224\n",
            "I0711 13:59:16.951174 140649210214272 efficientnet_model.py:147] round_filter input=192 output=384\n",
            "I0711 13:59:17.836026 140649210214272 efficientnet_model.py:147] round_filter input=192 output=384\n",
            "I0711 13:59:17.836204 140649210214272 efficientnet_model.py:147] round_filter input=320 output=640\n",
            "I0711 13:59:18.110892 140649210214272 efficientnet_model.py:147] round_filter input=1280 output=2560\n",
            "I0711 13:59:18.144716 140649210214272 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 19.48s\n",
            "I0711 13:59:18.270564 140649210214272 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 19.48s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
            "I0711 13:59:18.276804 140649210214272 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "I0711 13:59:18.278507 140649210214272 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "I0711 13:59:18.279037 140649210214272 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "I0711 13:59:18.280442 140649210214272 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "[ RUN      ] ModelBuilderTF2Test.test_session\n",
            "[  SKIPPED ] ModelBuilderTF2Test.test_session\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "I0711 13:59:18.281796 140649210214272 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "I0711 13:59:18.282207 140649210214272 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "I0711 13:59:18.283157 140649210214272 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "======================================================================\n",
            "ERROR: test_create_center_net_model_mobilenet (__main__.ModelBuilderTF2Test)\n",
            "ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
            "Test building a CenterNet model using bilinear interpolation.\n",
            "----------------------------------------------------------------------\n",
            "Traceback (most recent call last):\n",
            "  File \"object_detection/builders/model_builder_tf2_test.py\", line 497, in test_create_center_net_model_mobilenet\n",
            "    model = model_builder.build(config, is_training=True)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/object_detection/builders/model_builder.py\", line 1227, in build\n",
            "    add_summaries)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/object_detection/builders/model_builder.py\", line 1078, in _build_center_net_model\n",
            "    center_net_config.feature_extractor, is_training)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/object_detection/builders/model_builder.py\", line 1192, in _build_center_net_feature_extractor\n",
            "    **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/object_detection/models/center_net_mobilenet_v2_fpn_feature_extractor.py\", line 156, in mobilenet_v2_fpn\n",
            "    weights='imagenet' if depth_multiplier == 1.0 else None)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/object_detection/models/keras_models/mobilenet_v2.py\", line 333, in mobilenet_v2\n",
            "    **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/applications/mobilenet_v2.py\", line 407, in MobileNetV2\n",
            "    model.load_weights(weights_path)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\", line 2234, in load_weights\n",
            "    hdf5_format.load_weights_from_hdf5_group(f, self.layers)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/saving/hdf5_format.py\", line 662, in load_weights_from_hdf5_group\n",
            "    original_keras_version = f.attrs['keras_version'].decode('utf8')\n",
            "AttributeError: 'str' object has no attribute 'decode'\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "Ran 24 tests in 24.377s\n",
            "\n",
            "FAILED (errors=1, skipped=1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BNLNEuv3d2xf",
        "outputId": "4e734adc-46d9-48bf-d42c-832f66417e9e"
      },
      "source": [
        "cd /content/training_demo/pre-trained-models"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/training_demo/pre-trained-models\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H3hWZ26Yd20B",
        "outputId": "8c3c3a99-de14-4226-f692-ac20a2617f7c"
      },
      "source": [
        "!wget http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_resnet101_v1_fpn_640x640_coco17_tpu-8.tar.gz"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-07-11 14:04:13--  http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_resnet101_v1_fpn_640x640_coco17_tpu-8.tar.gz\n",
            "Resolving download.tensorflow.org (download.tensorflow.org)... 74.125.135.128, 2607:f8b0:400e:c09::80\n",
            "Connecting to download.tensorflow.org (download.tensorflow.org)|74.125.135.128|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 386527459 (369M) [application/x-tar]\n",
            "Saving to: ‘ssd_resnet101_v1_fpn_640x640_coco17_tpu-8.tar.gz.1’\n",
            "\n",
            "ssd_resnet101_v1_fp 100%[===================>] 368.62M   184MB/s    in 2.0s    \n",
            "\n",
            "2021-07-11 14:04:15 (184 MB/s) - ‘ssd_resnet101_v1_fpn_640x640_coco17_tpu-8.tar.gz.1’ saved [386527459/386527459]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3zXdQNOxd22H",
        "outputId": "c9eb2316-f291-4a19-c957-7fd90bcc9159"
      },
      "source": [
        "!tar -xvf ssd_resnet101_v1_fpn_640x640_coco17_tpu-8.tar.gz"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/\n",
            "ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/checkpoint/\n",
            "ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/checkpoint/ckpt-0.data-00000-of-00001\n",
            "ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/checkpoint/checkpoint\n",
            "ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/checkpoint/ckpt-0.index\n",
            "ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/pipeline.config\n",
            "ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/saved_model/\n",
            "ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/saved_model/saved_model.pb\n",
            "ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/saved_model/assets/\n",
            "ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/saved_model/variables/\n",
            "ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/saved_model/variables/variables.data-00000-of-00001\n",
            "ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/saved_model/variables/variables.index\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Kj0oG29md24h",
        "outputId": "28bf1ffd-f05c-4191-d662-942dc39c633b"
      },
      "source": [
        "pwd"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/training_demo/pre-trained-models'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3g9poaYd26k",
        "outputId": "ca1d4f0b-0d17-4c97-ece6-47b55acba710"
      },
      "source": [
        "cd /content/training_demo"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/training_demo\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4RVOp7i7d288",
        "outputId": "b011491b-62c0-40c1-e834-638244ca4971"
      },
      "source": [
        "ls"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mannotations\u001b[0m/         export_tflite_graph_tf2.py  \u001b[01;34mmodels\u001b[0m/\n",
            "\u001b[01;34mexported_models\u001b[0m/     \u001b[01;34mimages\u001b[0m/                     \u001b[01;34mpre-trained-models\u001b[0m/\n",
            "exporter_main_v2.py  model_main_tf2.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xuVybrOGd2_M",
        "outputId": "17b177d8-aa1e-431b-bb4b-ad74586e5a37"
      },
      "source": [
        "# Create train data:\n",
        "!python generate_tfrecord.py -x /content/training_demo/images/train -l /content/training_demo/annotations/label_map.pbtxt -o /content/training_demo/annotations/train.record\n",
        "\n",
        "# Create test data:\n",
        "!python generate_tfrecord.py -x /content/training_demo/images/test -l /content/training_demo/annotations/label_map.pbtxt -o /content/training_demo/annotations/test.record"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Successfully created the TFRecord file: /content/training_demo/annotations/train.record\n",
            "Successfully created the TFRecord file: /content/training_demo/annotations/test.record\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "XgI_HP6jd3BN",
        "outputId": "cbc84c12-4787-4020-81e3-985361ca3af8"
      },
      "source": [
        "pwd"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/training_demo'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JA7gTPphd3Dd",
        "outputId": "c44d1eb7-4513-4d6f-b312-451b2382daad"
      },
      "source": [
        "!python model_main_tf2.py --model_dir=/content/training_demo/models/my_ssd_resnet101_v1_fpn --pipeline_config_path=/content/training_demo/models/my_ssd_resnet101_v1_fpn/pipeline.config"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-07-11 15:30:45.678625: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-07-11 15:30:48.192544: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "2021-07-11 15:30:48.193399: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
            "2021-07-11 15:30:48.207170: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-11 15:30:48.207769: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\n",
            "coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n",
            "2021-07-11 15:30:48.207802: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-07-11 15:30:48.210821: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
            "2021-07-11 15:30:48.210898: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
            "2021-07-11 15:30:48.212583: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
            "2021-07-11 15:30:48.212980: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
            "2021-07-11 15:30:48.215088: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-07-11 15:30:48.215696: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
            "2021-07-11 15:30:48.215885: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
            "2021-07-11 15:30:48.215976: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-11 15:30:48.216673: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-11 15:30:48.217369: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
            "2021-07-11 15:30:48.217821: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2021-07-11 15:30:48.218000: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "2021-07-11 15:30:48.218097: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-11 15:30:48.218650: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\n",
            "coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n",
            "2021-07-11 15:30:48.218675: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-07-11 15:30:48.218701: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
            "2021-07-11 15:30:48.218715: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
            "2021-07-11 15:30:48.218726: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
            "2021-07-11 15:30:48.218739: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
            "2021-07-11 15:30:48.218752: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-07-11 15:30:48.218771: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
            "2021-07-11 15:30:48.218785: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
            "2021-07-11 15:30:48.218838: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-11 15:30:48.219373: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-11 15:30:48.219895: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
            "2021-07-11 15:30:48.219949: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-07-11 15:30:48.876629: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-07-11 15:30:48.876673: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
            "2021-07-11 15:30:48.876688: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
            "2021-07-11 15:30:48.876932: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-11 15:30:48.877581: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-11 15:30:48.878160: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-11 15:30:48.878667: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2021-07-11 15:30:48.878707: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14957 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "I0711 15:30:48.880375 140349244585856 mirrored_strategy.py:350] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "INFO:tensorflow:Maybe overwriting train_steps: None\n",
            "I0711 15:30:48.884421 140349244585856 config_util.py:552] Maybe overwriting train_steps: None\n",
            "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
            "I0711 15:30:48.884569 140349244585856 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py:558: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "W0711 15:30:49.002500 140349244585856 deprecation.py:339] From /usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py:558: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/training_demo/annotations/train.record']\n",
            "I0711 15:30:49.006522 140349244585856 dataset_builder.py:163] Reading unweighted datasets: ['/content/training_demo/annotations/train.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/training_demo/annotations/train.record']\n",
            "I0711 15:30:49.006679 140349244585856 dataset_builder.py:80] Reading record datasets for input file: ['/content/training_demo/annotations/train.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I0711 15:30:49.006742 140349244585856 dataset_builder.py:81] Number of filenames to read: 1\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W0711 15:30:49.006791 140349244585856 dataset_builder.py:88] num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.\n",
            "W0711 15:30:49.008538 140349244585856 deprecation.py:339] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W0711 15:30:49.023701 140349244585856 deprecation.py:339] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "WARNING:tensorflow:AutoGraph could not transform <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7fa51016a990>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "W0711 15:30:49.058549 140349244585856 ag_logging.py:146] AutoGraph could not transform <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7fa51016a990>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function build at 0x7fa51b804440> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "W0711 15:30:49.294633 140349244585856 ag_logging.py:146] AutoGraph could not transform <function build at 0x7fa51b804440> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function build at 0x7fa51ba3a290> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "W0711 15:30:49.362781 140349244585856 ag_logging.py:146] AutoGraph could not transform <function build at 0x7fa51ba3a290> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function transform_input_data at 0x7fa51b81b0e0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "W0711 15:30:49.400149 140349244585856 ag_logging.py:146] AutoGraph could not transform <function transform_input_data at 0x7fa51b81b0e0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:201: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "W0711 15:30:49.405857 140349244585856 deprecation.py:339] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:201: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:201: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "W0711 15:30:49.472695 140349244585856 deprecation.py:339] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:201: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/inputs.py:284: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0711 15:30:49.542808 140349244585856 deprecation.py:339] From /usr/local/lib/python3.7/dist-packages/object_detection/inputs.py:284: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:AutoGraph could not transform <function pad_input_data_to_static_shapes at 0x7fa51b81b170> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "W0711 15:30:49.800976 140349244585856 ag_logging.py:146] AutoGraph could not transform <function pad_input_data_to_static_shapes at 0x7fa51b81b170> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function _get_features_dict at 0x7fa51b81b3b0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "W0711 15:30:50.035400 140349244585856 ag_logging.py:146] AutoGraph could not transform <function _get_features_dict at 0x7fa51b81b3b0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function _get_labels_dict at 0x7fa51b81b290> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "W0711 15:30:50.053537 140349244585856 ag_logging.py:146] AutoGraph could not transform <function _get_labels_dict at 0x7fa51b81b290> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "2021-07-11 15:30:50.145659: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
            "2021-07-11 15:30:50.149709: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199995000 Hz\n",
            "WARNING:tensorflow:AutoGraph could not transform <function call_for_each_replica at 0x7fa54bf18680> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "W0711 15:30:51.170698 140349244585856 ag_logging.py:146] AutoGraph could not transform <function call_for_each_replica at 0x7fa54bf18680> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/backend.py:434: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n",
            "WARNING:tensorflow:AutoGraph could not transform <function unstack_batch at 0x7fa51b7af9e0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "W0711 15:30:51.226477 140345335805696 ag_logging.py:146] AutoGraph could not transform <function unstack_batch at 0x7fa51b7af9e0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function _compute_losses_and_predictions_dicts at 0x7fa52ee6e170> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "W0711 15:30:51.241722 140345335805696 ag_logging.py:146] AutoGraph could not transform <function _compute_losses_and_predictions_dicts at 0x7fa52ee6e170> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <bound method SSDResNetV1FpnKerasFeatureExtractor._extract_features of <object_detection.models.ssd_resnet_v1_fpn_keras_feature_extractor.SSDResNet101V1FpnKerasFeatureExtractor object at 0x7fa51b58e1d0>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "W0711 15:30:53.308272 140345335805696 ag_logging.py:146] AutoGraph could not transform <bound method SSDResNetV1FpnKerasFeatureExtractor._extract_features of <object_detection.models.ssd_resnet_v1_fpn_keras_feature_extractor.SSDResNet101V1FpnKerasFeatureExtractor object at 0x7fa51b58e1d0>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <bound method KerasFpnTopDownFeatureMaps.call of <object_detection.models.feature_map_generators.KerasFpnTopDownFeatureMaps object at 0x7fa4b619b250>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "W0711 15:30:54.156940 140345335805696 ag_logging.py:146] AutoGraph could not transform <bound method KerasFpnTopDownFeatureMaps.call of <object_detection.models.feature_map_generators.KerasFpnTopDownFeatureMaps object at 0x7fa4b619b250>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <bound method WeightSharedConvolutionalBoxPredictor._predict of <object_detection.predictors.convolutional_keras_box_predictor.WeightSharedConvolutionalBoxPredictor object at 0x7fa510211a90>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "W0711 15:30:54.817504 140345335805696 ag_logging.py:146] AutoGraph could not transform <bound method WeightSharedConvolutionalBoxPredictor._predict of <object_detection.predictors.convolutional_keras_box_predictor.WeightSharedConvolutionalBoxPredictor object at 0x7fa510211a90>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <bound method WeightSharedConvolutionalBoxHead._predict of <object_detection.predictors.heads.keras_box_head.WeightSharedConvolutionalBoxHead object at 0x7fa51022e750>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "W0711 15:30:54.889505 140345335805696 ag_logging.py:146] AutoGraph could not transform <bound method WeightSharedConvolutionalBoxHead._predict of <object_detection.predictors.heads.keras_box_head.WeightSharedConvolutionalBoxHead object at 0x7fa51022e750>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <bound method WeightSharedConvolutionalClassHead._predict of <object_detection.predictors.heads.keras_class_head.WeightSharedConvolutionalClassHead object at 0x7fa51b801c50>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "W0711 15:30:54.949277 140345335805696 ag_logging.py:146] AutoGraph could not transform <bound method WeightSharedConvolutionalClassHead._predict of <object_detection.predictors.heads.keras_class_head.WeightSharedConvolutionalClassHead object at 0x7fa51b801c50>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "2021-07-11 15:31:02.695339: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
            "2021-07-11 15:31:02.944223: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
            "2021-07-11 15:31:02.965572: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0711 15:31:13.417972 140349244585856 cross_device_ops.py:565] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0711 15:31:13.419179 140349244585856 cross_device_ops.py:565] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0711 15:31:13.420832 140349244585856 cross_device_ops.py:565] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0711 15:31:13.421562 140349244585856 cross_device_ops.py:565] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0711 15:31:13.423226 140349244585856 cross_device_ops.py:565] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0711 15:31:13.423969 140349244585856 cross_device_ops.py:565] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0711 15:31:13.425916 140349244585856 cross_device_ops.py:565] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0711 15:31:13.426650 140349244585856 cross_device_ops.py:565] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0711 15:31:13.427958 140349244585856 cross_device_ops.py:565] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0711 15:31:13.428687 140349244585856 cross_device_ops.py:565] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "WARNING:tensorflow:AutoGraph could not transform <function train_loop.<locals>.train_step_fn at 0x7fa4b5761680> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "W0711 15:31:14.181584 140348496070400 ag_logging.py:146] AutoGraph could not transform <function train_loop.<locals>.train_step_fn at 0x7fa4b5761680> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:605: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n",
            "W0711 15:31:14.197758 140348496070400 deprecation.py:537] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:605: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n",
            "INFO:tensorflow:Step 100 per-step time 1.472s\n",
            "I0711 15:33:41.292003 140349244585856 model_lib_v2.py:700] Step 100 per-step time 1.472s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.26342157,\n",
            " 'Loss/localization_loss': 0.19664383,\n",
            " 'Loss/regularization_loss': 0.28564703,\n",
            " 'Loss/total_loss': 0.7457124,\n",
            " 'learning_rate': 0.014666351}\n",
            "I0711 15:33:41.292340 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.26342157,\n",
            " 'Loss/localization_loss': 0.19664383,\n",
            " 'Loss/regularization_loss': 0.28564703,\n",
            " 'Loss/total_loss': 0.7457124,\n",
            " 'learning_rate': 0.014666351}\n",
            "INFO:tensorflow:Step 200 per-step time 0.969s\n",
            "I0711 15:35:18.212743 140349244585856 model_lib_v2.py:700] Step 200 per-step time 0.969s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.17821339,\n",
            " 'Loss/localization_loss': 0.12276799,\n",
            " 'Loss/regularization_loss': 0.2855549,\n",
            " 'Loss/total_loss': 0.5865363,\n",
            " 'learning_rate': 0.0159997}\n",
            "I0711 15:35:18.213061 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.17821339,\n",
            " 'Loss/localization_loss': 0.12276799,\n",
            " 'Loss/regularization_loss': 0.2855549,\n",
            " 'Loss/total_loss': 0.5865363,\n",
            " 'learning_rate': 0.0159997}\n",
            "INFO:tensorflow:Step 300 per-step time 0.970s\n",
            "I0711 15:36:55.243732 140349244585856 model_lib_v2.py:700] Step 300 per-step time 0.970s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.12845924,\n",
            " 'Loss/localization_loss': 0.06989343,\n",
            " 'Loss/regularization_loss': 0.28467825,\n",
            " 'Loss/total_loss': 0.48303092,\n",
            " 'learning_rate': 0.01733305}\n",
            "I0711 15:36:55.244030 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.12845924,\n",
            " 'Loss/localization_loss': 0.06989343,\n",
            " 'Loss/regularization_loss': 0.28467825,\n",
            " 'Loss/total_loss': 0.48303092,\n",
            " 'learning_rate': 0.01733305}\n",
            "INFO:tensorflow:Step 400 per-step time 0.971s\n",
            "I0711 15:38:32.297004 140349244585856 model_lib_v2.py:700] Step 400 per-step time 0.971s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.102872625,\n",
            " 'Loss/localization_loss': 0.05141472,\n",
            " 'Loss/regularization_loss': 0.28278217,\n",
            " 'Loss/total_loss': 0.4370695,\n",
            " 'learning_rate': 0.0186664}\n",
            "I0711 15:38:32.297337 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.102872625,\n",
            " 'Loss/localization_loss': 0.05141472,\n",
            " 'Loss/regularization_loss': 0.28278217,\n",
            " 'Loss/total_loss': 0.4370695,\n",
            " 'learning_rate': 0.0186664}\n",
            "INFO:tensorflow:Step 500 per-step time 0.970s\n",
            "I0711 15:40:09.274438 140349244585856 model_lib_v2.py:700] Step 500 per-step time 0.970s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.11904434,\n",
            " 'Loss/localization_loss': 0.06057071,\n",
            " 'Loss/regularization_loss': 0.28031236,\n",
            " 'Loss/total_loss': 0.4599274,\n",
            " 'learning_rate': 0.01999975}\n",
            "I0711 15:40:09.274779 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.11904434,\n",
            " 'Loss/localization_loss': 0.06057071,\n",
            " 'Loss/regularization_loss': 0.28031236,\n",
            " 'Loss/total_loss': 0.4599274,\n",
            " 'learning_rate': 0.01999975}\n",
            "INFO:tensorflow:Step 600 per-step time 0.969s\n",
            "I0711 15:41:46.177539 140349244585856 model_lib_v2.py:700] Step 600 per-step time 0.969s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.13633473,\n",
            " 'Loss/localization_loss': 0.05855053,\n",
            " 'Loss/regularization_loss': 0.27761722,\n",
            " 'Loss/total_loss': 0.47250247,\n",
            " 'learning_rate': 0.0213331}\n",
            "I0711 15:41:46.177869 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.13633473,\n",
            " 'Loss/localization_loss': 0.05855053,\n",
            " 'Loss/regularization_loss': 0.27761722,\n",
            " 'Loss/total_loss': 0.47250247,\n",
            " 'learning_rate': 0.0213331}\n",
            "INFO:tensorflow:Step 700 per-step time 0.970s\n",
            "I0711 15:43:23.176686 140349244585856 model_lib_v2.py:700] Step 700 per-step time 0.970s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07219243,\n",
            " 'Loss/localization_loss': 0.028770985,\n",
            " 'Loss/regularization_loss': 0.27458563,\n",
            " 'Loss/total_loss': 0.37554905,\n",
            " 'learning_rate': 0.02266645}\n",
            "I0711 15:43:23.176977 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.07219243,\n",
            " 'Loss/localization_loss': 0.028770985,\n",
            " 'Loss/regularization_loss': 0.27458563,\n",
            " 'Loss/total_loss': 0.37554905,\n",
            " 'learning_rate': 0.02266645}\n",
            "INFO:tensorflow:Step 800 per-step time 0.970s\n",
            "I0711 15:45:00.182701 140349244585856 model_lib_v2.py:700] Step 800 per-step time 0.970s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07628829,\n",
            " 'Loss/localization_loss': 0.03757402,\n",
            " 'Loss/regularization_loss': 0.27152947,\n",
            " 'Loss/total_loss': 0.38539177,\n",
            " 'learning_rate': 0.023999799}\n",
            "I0711 15:45:00.183031 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.07628829,\n",
            " 'Loss/localization_loss': 0.03757402,\n",
            " 'Loss/regularization_loss': 0.27152947,\n",
            " 'Loss/total_loss': 0.38539177,\n",
            " 'learning_rate': 0.023999799}\n",
            "INFO:tensorflow:Step 900 per-step time 0.970s\n",
            "I0711 15:46:37.160859 140349244585856 model_lib_v2.py:700] Step 900 per-step time 0.970s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.0751957,\n",
            " 'Loss/localization_loss': 0.032628637,\n",
            " 'Loss/regularization_loss': 0.2682393,\n",
            " 'Loss/total_loss': 0.37606364,\n",
            " 'learning_rate': 0.025333151}\n",
            "I0711 15:46:37.161149 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.0751957,\n",
            " 'Loss/localization_loss': 0.032628637,\n",
            " 'Loss/regularization_loss': 0.2682393,\n",
            " 'Loss/total_loss': 0.37606364,\n",
            " 'learning_rate': 0.025333151}\n",
            "INFO:tensorflow:Step 1000 per-step time 0.969s\n",
            "I0711 15:48:14.078894 140349244585856 model_lib_v2.py:700] Step 1000 per-step time 0.969s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.106322035,\n",
            " 'Loss/localization_loss': 0.03152837,\n",
            " 'Loss/regularization_loss': 0.26498532,\n",
            " 'Loss/total_loss': 0.40283573,\n",
            " 'learning_rate': 0.0266665}\n",
            "I0711 15:48:14.079216 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.106322035,\n",
            " 'Loss/localization_loss': 0.03152837,\n",
            " 'Loss/regularization_loss': 0.26498532,\n",
            " 'Loss/total_loss': 0.40283573,\n",
            " 'learning_rate': 0.0266665}\n",
            "INFO:tensorflow:Step 1100 per-step time 0.983s\n",
            "I0711 15:49:52.348622 140349244585856 model_lib_v2.py:700] Step 1100 per-step time 0.983s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.05866629,\n",
            " 'Loss/localization_loss': 0.023191992,\n",
            " 'Loss/regularization_loss': 0.261883,\n",
            " 'Loss/total_loss': 0.34374127,\n",
            " 'learning_rate': 0.02799985}\n",
            "I0711 15:49:52.348949 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.05866629,\n",
            " 'Loss/localization_loss': 0.023191992,\n",
            " 'Loss/regularization_loss': 0.261883,\n",
            " 'Loss/total_loss': 0.34374127,\n",
            " 'learning_rate': 0.02799985}\n",
            "INFO:tensorflow:Step 1200 per-step time 0.970s\n",
            "I0711 15:51:29.348538 140349244585856 model_lib_v2.py:700] Step 1200 per-step time 0.970s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.068819195,\n",
            " 'Loss/localization_loss': 0.038115695,\n",
            " 'Loss/regularization_loss': 0.2582491,\n",
            " 'Loss/total_loss': 0.365184,\n",
            " 'learning_rate': 0.0293332}\n",
            "I0711 15:51:29.348846 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.068819195,\n",
            " 'Loss/localization_loss': 0.038115695,\n",
            " 'Loss/regularization_loss': 0.2582491,\n",
            " 'Loss/total_loss': 0.365184,\n",
            " 'learning_rate': 0.0293332}\n",
            "INFO:tensorflow:Step 1300 per-step time 0.970s\n",
            "I0711 15:53:06.323267 140349244585856 model_lib_v2.py:700] Step 1300 per-step time 0.970s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.06368733,\n",
            " 'Loss/localization_loss': 0.027828773,\n",
            " 'Loss/regularization_loss': 0.25404984,\n",
            " 'Loss/total_loss': 0.34556594,\n",
            " 'learning_rate': 0.03066655}\n",
            "I0711 15:53:06.323581 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.06368733,\n",
            " 'Loss/localization_loss': 0.027828773,\n",
            " 'Loss/regularization_loss': 0.25404984,\n",
            " 'Loss/total_loss': 0.34556594,\n",
            " 'learning_rate': 0.03066655}\n",
            "INFO:tensorflow:Step 1400 per-step time 0.970s\n",
            "I0711 15:54:43.363641 140349244585856 model_lib_v2.py:700] Step 1400 per-step time 0.970s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.06544956,\n",
            " 'Loss/localization_loss': 0.02383212,\n",
            " 'Loss/regularization_loss': 0.25068343,\n",
            " 'Loss/total_loss': 0.3399651,\n",
            " 'learning_rate': 0.0319999}\n",
            "I0711 15:54:43.363940 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.06544956,\n",
            " 'Loss/localization_loss': 0.02383212,\n",
            " 'Loss/regularization_loss': 0.25068343,\n",
            " 'Loss/total_loss': 0.3399651,\n",
            " 'learning_rate': 0.0319999}\n",
            "INFO:tensorflow:Step 1500 per-step time 0.970s\n",
            "I0711 15:56:20.335770 140349244585856 model_lib_v2.py:700] Step 1500 per-step time 0.970s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.05883079,\n",
            " 'Loss/localization_loss': 0.01667938,\n",
            " 'Loss/regularization_loss': 0.24651168,\n",
            " 'Loss/total_loss': 0.32202184,\n",
            " 'learning_rate': 0.03333325}\n",
            "I0711 15:56:20.336070 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.05883079,\n",
            " 'Loss/localization_loss': 0.01667938,\n",
            " 'Loss/regularization_loss': 0.24651168,\n",
            " 'Loss/total_loss': 0.32202184,\n",
            " 'learning_rate': 0.03333325}\n",
            "INFO:tensorflow:Step 1600 per-step time 0.971s\n",
            "I0711 15:57:57.402230 140349244585856 model_lib_v2.py:700] Step 1600 per-step time 0.971s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.081336886,\n",
            " 'Loss/localization_loss': 0.035320885,\n",
            " 'Loss/regularization_loss': 0.24353181,\n",
            " 'Loss/total_loss': 0.3601896,\n",
            " 'learning_rate': 0.034666598}\n",
            "I0711 15:57:57.402551 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.081336886,\n",
            " 'Loss/localization_loss': 0.035320885,\n",
            " 'Loss/regularization_loss': 0.24353181,\n",
            " 'Loss/total_loss': 0.3601896,\n",
            " 'learning_rate': 0.034666598}\n",
            "INFO:tensorflow:Step 1700 per-step time 0.971s\n",
            "I0711 15:59:34.464474 140349244585856 model_lib_v2.py:700] Step 1700 per-step time 0.971s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.072279125,\n",
            " 'Loss/localization_loss': 0.032919224,\n",
            " 'Loss/regularization_loss': 0.24025744,\n",
            " 'Loss/total_loss': 0.3454558,\n",
            " 'learning_rate': 0.03599995}\n",
            "I0711 15:59:34.464779 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.072279125,\n",
            " 'Loss/localization_loss': 0.032919224,\n",
            " 'Loss/regularization_loss': 0.24025744,\n",
            " 'Loss/total_loss': 0.3454558,\n",
            " 'learning_rate': 0.03599995}\n",
            "INFO:tensorflow:Step 1800 per-step time 0.969s\n",
            "I0711 16:01:11.405317 140349244585856 model_lib_v2.py:700] Step 1800 per-step time 0.969s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.068445824,\n",
            " 'Loss/localization_loss': 0.023740629,\n",
            " 'Loss/regularization_loss': 0.23734047,\n",
            " 'Loss/total_loss': 0.3295269,\n",
            " 'learning_rate': 0.037333302}\n",
            "I0711 16:01:11.405612 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.068445824,\n",
            " 'Loss/localization_loss': 0.023740629,\n",
            " 'Loss/regularization_loss': 0.23734047,\n",
            " 'Loss/total_loss': 0.3295269,\n",
            " 'learning_rate': 0.037333302}\n",
            "INFO:tensorflow:Step 1900 per-step time 0.970s\n",
            "I0711 16:02:48.388954 140349244585856 model_lib_v2.py:700] Step 1900 per-step time 0.970s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.080561705,\n",
            " 'Loss/localization_loss': 0.022448014,\n",
            " 'Loss/regularization_loss': 0.23593894,\n",
            " 'Loss/total_loss': 0.33894867,\n",
            " 'learning_rate': 0.03866665}\n",
            "I0711 16:02:48.389266 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.080561705,\n",
            " 'Loss/localization_loss': 0.022448014,\n",
            " 'Loss/regularization_loss': 0.23593894,\n",
            " 'Loss/total_loss': 0.33894867,\n",
            " 'learning_rate': 0.03866665}\n",
            "INFO:tensorflow:Step 2000 per-step time 0.970s\n",
            "I0711 16:04:25.404817 140349244585856 model_lib_v2.py:700] Step 2000 per-step time 0.970s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07347975,\n",
            " 'Loss/localization_loss': 0.030498639,\n",
            " 'Loss/regularization_loss': 0.23476374,\n",
            " 'Loss/total_loss': 0.33874214,\n",
            " 'learning_rate': 0.04}\n",
            "I0711 16:04:25.405133 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.07347975,\n",
            " 'Loss/localization_loss': 0.030498639,\n",
            " 'Loss/regularization_loss': 0.23476374,\n",
            " 'Loss/total_loss': 0.33874214,\n",
            " 'learning_rate': 0.04}\n",
            "INFO:tensorflow:Step 2100 per-step time 0.983s\n",
            "I0711 16:06:03.708733 140349244585856 model_lib_v2.py:700] Step 2100 per-step time 0.983s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07032479,\n",
            " 'Loss/localization_loss': 0.024650251,\n",
            " 'Loss/regularization_loss': 0.23080727,\n",
            " 'Loss/total_loss': 0.32578233,\n",
            " 'learning_rate': 0.039984576}\n",
            "I0711 16:06:03.709031 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.07032479,\n",
            " 'Loss/localization_loss': 0.024650251,\n",
            " 'Loss/regularization_loss': 0.23080727,\n",
            " 'Loss/total_loss': 0.32578233,\n",
            " 'learning_rate': 0.039984576}\n",
            "INFO:tensorflow:Step 2200 per-step time 0.970s\n",
            "I0711 16:07:40.737470 140349244585856 model_lib_v2.py:700] Step 2200 per-step time 0.970s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.10236449,\n",
            " 'Loss/localization_loss': 0.0254802,\n",
            " 'Loss/regularization_loss': 0.22639993,\n",
            " 'Loss/total_loss': 0.35424462,\n",
            " 'learning_rate': 0.039938346}\n",
            "I0711 16:07:40.737890 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.10236449,\n",
            " 'Loss/localization_loss': 0.0254802,\n",
            " 'Loss/regularization_loss': 0.22639993,\n",
            " 'Loss/total_loss': 0.35424462,\n",
            " 'learning_rate': 0.039938346}\n",
            "INFO:tensorflow:Step 2300 per-step time 0.971s\n",
            "I0711 16:09:17.876973 140349244585856 model_lib_v2.py:700] Step 2300 per-step time 0.971s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07113547,\n",
            " 'Loss/localization_loss': 0.017270835,\n",
            " 'Loss/regularization_loss': 0.2216321,\n",
            " 'Loss/total_loss': 0.3100384,\n",
            " 'learning_rate': 0.03986137}\n",
            "I0711 16:09:17.877266 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.07113547,\n",
            " 'Loss/localization_loss': 0.017270835,\n",
            " 'Loss/regularization_loss': 0.2216321,\n",
            " 'Loss/total_loss': 0.3100384,\n",
            " 'learning_rate': 0.03986137}\n",
            "INFO:tensorflow:Step 2400 per-step time 0.971s\n",
            "I0711 16:10:54.971877 140349244585856 model_lib_v2.py:700] Step 2400 per-step time 0.971s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.047457904,\n",
            " 'Loss/localization_loss': 0.02514852,\n",
            " 'Loss/regularization_loss': 0.21726899,\n",
            " 'Loss/total_loss': 0.28987542,\n",
            " 'learning_rate': 0.039753765}\n",
            "I0711 16:10:54.972183 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.047457904,\n",
            " 'Loss/localization_loss': 0.02514852,\n",
            " 'Loss/regularization_loss': 0.21726899,\n",
            " 'Loss/total_loss': 0.28987542,\n",
            " 'learning_rate': 0.039753765}\n",
            "INFO:tensorflow:Step 2500 per-step time 0.971s\n",
            "I0711 16:12:32.039989 140349244585856 model_lib_v2.py:700] Step 2500 per-step time 0.971s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.06142878,\n",
            " 'Loss/localization_loss': 0.018605074,\n",
            " 'Loss/regularization_loss': 0.21238779,\n",
            " 'Loss/total_loss': 0.29242164,\n",
            " 'learning_rate': 0.039615706}\n",
            "I0711 16:12:32.040316 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.06142878,\n",
            " 'Loss/localization_loss': 0.018605074,\n",
            " 'Loss/regularization_loss': 0.21238779,\n",
            " 'Loss/total_loss': 0.29242164,\n",
            " 'learning_rate': 0.039615706}\n",
            "INFO:tensorflow:Step 2600 per-step time 0.971s\n",
            "I0711 16:14:09.119056 140349244585856 model_lib_v2.py:700] Step 2600 per-step time 0.971s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.06958792,\n",
            " 'Loss/localization_loss': 0.021662053,\n",
            " 'Loss/regularization_loss': 0.20801264,\n",
            " 'Loss/total_loss': 0.2992626,\n",
            " 'learning_rate': 0.039447397}\n",
            "I0711 16:14:09.119348 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.06958792,\n",
            " 'Loss/localization_loss': 0.021662053,\n",
            " 'Loss/regularization_loss': 0.20801264,\n",
            " 'Loss/total_loss': 0.2992626,\n",
            " 'learning_rate': 0.039447397}\n",
            "INFO:tensorflow:Step 2700 per-step time 0.970s\n",
            "I0711 16:15:46.153156 140349244585856 model_lib_v2.py:700] Step 2700 per-step time 0.970s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.06419747,\n",
            " 'Loss/localization_loss': 0.024194412,\n",
            " 'Loss/regularization_loss': 0.20331688,\n",
            " 'Loss/total_loss': 0.29170877,\n",
            " 'learning_rate': 0.039249104}\n",
            "I0711 16:15:46.153460 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.06419747,\n",
            " 'Loss/localization_loss': 0.024194412,\n",
            " 'Loss/regularization_loss': 0.20331688,\n",
            " 'Loss/total_loss': 0.29170877,\n",
            " 'learning_rate': 0.039249104}\n",
            "INFO:tensorflow:Step 2800 per-step time 0.970s\n",
            "I0711 16:17:23.198499 140349244585856 model_lib_v2.py:700] Step 2800 per-step time 0.970s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.10387731,\n",
            " 'Loss/localization_loss': 0.022894328,\n",
            " 'Loss/regularization_loss': 0.19911708,\n",
            " 'Loss/total_loss': 0.32588872,\n",
            " 'learning_rate': 0.039021127}\n",
            "I0711 16:17:23.198774 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.10387731,\n",
            " 'Loss/localization_loss': 0.022894328,\n",
            " 'Loss/regularization_loss': 0.19911708,\n",
            " 'Loss/total_loss': 0.32588872,\n",
            " 'learning_rate': 0.039021127}\n",
            "INFO:tensorflow:Step 2900 per-step time 0.970s\n",
            "I0711 16:19:00.236942 140349244585856 model_lib_v2.py:700] Step 2900 per-step time 0.970s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.06000943,\n",
            " 'Loss/localization_loss': 0.012678872,\n",
            " 'Loss/regularization_loss': 0.19507326,\n",
            " 'Loss/total_loss': 0.26776156,\n",
            " 'learning_rate': 0.03876383}\n",
            "I0711 16:19:00.237283 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.06000943,\n",
            " 'Loss/localization_loss': 0.012678872,\n",
            " 'Loss/regularization_loss': 0.19507326,\n",
            " 'Loss/total_loss': 0.26776156,\n",
            " 'learning_rate': 0.03876383}\n",
            "INFO:tensorflow:Step 3000 per-step time 0.970s\n",
            "I0711 16:20:37.234988 140349244585856 model_lib_v2.py:700] Step 3000 per-step time 0.970s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.048963804,\n",
            " 'Loss/localization_loss': 0.018066097,\n",
            " 'Loss/regularization_loss': 0.19092831,\n",
            " 'Loss/total_loss': 0.2579582,\n",
            " 'learning_rate': 0.038477592}\n",
            "I0711 16:20:37.235272 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.048963804,\n",
            " 'Loss/localization_loss': 0.018066097,\n",
            " 'Loss/regularization_loss': 0.19092831,\n",
            " 'Loss/total_loss': 0.2579582,\n",
            " 'learning_rate': 0.038477592}\n",
            "INFO:tensorflow:Step 3100 per-step time 0.983s\n",
            "I0711 16:22:15.560822 140349244585856 model_lib_v2.py:700] Step 3100 per-step time 0.983s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.049716126,\n",
            " 'Loss/localization_loss': 0.0132001955,\n",
            " 'Loss/regularization_loss': 0.18676147,\n",
            " 'Loss/total_loss': 0.24967779,\n",
            " 'learning_rate': 0.03816286}\n",
            "I0711 16:22:15.561118 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.049716126,\n",
            " 'Loss/localization_loss': 0.0132001955,\n",
            " 'Loss/regularization_loss': 0.18676147,\n",
            " 'Loss/total_loss': 0.24967779,\n",
            " 'learning_rate': 0.03816286}\n",
            "INFO:tensorflow:Step 3200 per-step time 0.970s\n",
            "I0711 16:23:52.599554 140349244585856 model_lib_v2.py:700] Step 3200 per-step time 0.970s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.041247133,\n",
            " 'Loss/localization_loss': 0.012493236,\n",
            " 'Loss/regularization_loss': 0.18312429,\n",
            " 'Loss/total_loss': 0.23686466,\n",
            " 'learning_rate': 0.037820127}\n",
            "I0711 16:23:52.599859 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.041247133,\n",
            " 'Loss/localization_loss': 0.012493236,\n",
            " 'Loss/regularization_loss': 0.18312429,\n",
            " 'Loss/total_loss': 0.23686466,\n",
            " 'learning_rate': 0.037820127}\n",
            "INFO:tensorflow:Step 3300 per-step time 0.970s\n",
            "I0711 16:25:29.583904 140349244585856 model_lib_v2.py:700] Step 3300 per-step time 0.970s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.044803116,\n",
            " 'Loss/localization_loss': 0.013319265,\n",
            " 'Loss/regularization_loss': 0.17904404,\n",
            " 'Loss/total_loss': 0.23716642,\n",
            " 'learning_rate': 0.03744992}\n",
            "I0711 16:25:29.584208 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.044803116,\n",
            " 'Loss/localization_loss': 0.013319265,\n",
            " 'Loss/regularization_loss': 0.17904404,\n",
            " 'Loss/total_loss': 0.23716642,\n",
            " 'learning_rate': 0.03744992}\n",
            "INFO:tensorflow:Step 3400 per-step time 0.970s\n",
            "I0711 16:27:06.588567 140349244585856 model_lib_v2.py:700] Step 3400 per-step time 0.970s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.06941294,\n",
            " 'Loss/localization_loss': 0.030029772,\n",
            " 'Loss/regularization_loss': 0.17525975,\n",
            " 'Loss/total_loss': 0.27470246,\n",
            " 'learning_rate': 0.037052803}\n",
            "I0711 16:27:06.588864 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.06941294,\n",
            " 'Loss/localization_loss': 0.030029772,\n",
            " 'Loss/regularization_loss': 0.17525975,\n",
            " 'Loss/total_loss': 0.27470246,\n",
            " 'learning_rate': 0.037052803}\n",
            "INFO:tensorflow:Step 3500 per-step time 0.970s\n",
            "I0711 16:28:43.629562 140349244585856 model_lib_v2.py:700] Step 3500 per-step time 0.970s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.055523153,\n",
            " 'Loss/localization_loss': 0.012610247,\n",
            " 'Loss/regularization_loss': 0.17166789,\n",
            " 'Loss/total_loss': 0.23980129,\n",
            " 'learning_rate': 0.036629394}\n",
            "I0711 16:28:43.629907 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.055523153,\n",
            " 'Loss/localization_loss': 0.012610247,\n",
            " 'Loss/regularization_loss': 0.17166789,\n",
            " 'Loss/total_loss': 0.23980129,\n",
            " 'learning_rate': 0.036629394}\n",
            "INFO:tensorflow:Step 3600 per-step time 0.971s\n",
            "I0711 16:30:20.692789 140349244585856 model_lib_v2.py:700] Step 3600 per-step time 0.971s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.043648787,\n",
            " 'Loss/localization_loss': 0.0100365905,\n",
            " 'Loss/regularization_loss': 0.16817936,\n",
            " 'Loss/total_loss': 0.22186475,\n",
            " 'learning_rate': 0.03618034}\n",
            "I0711 16:30:20.693124 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.043648787,\n",
            " 'Loss/localization_loss': 0.0100365905,\n",
            " 'Loss/regularization_loss': 0.16817936,\n",
            " 'Loss/total_loss': 0.22186475,\n",
            " 'learning_rate': 0.03618034}\n",
            "INFO:tensorflow:Step 3700 per-step time 0.971s\n",
            "I0711 16:31:57.753032 140349244585856 model_lib_v2.py:700] Step 3700 per-step time 0.971s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.06606033,\n",
            " 'Loss/localization_loss': 0.017496366,\n",
            " 'Loss/regularization_loss': 0.16495186,\n",
            " 'Loss/total_loss': 0.24850856,\n",
            " 'learning_rate': 0.035706338}\n",
            "I0711 16:31:57.753316 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.06606033,\n",
            " 'Loss/localization_loss': 0.017496366,\n",
            " 'Loss/regularization_loss': 0.16495186,\n",
            " 'Loss/total_loss': 0.24850856,\n",
            " 'learning_rate': 0.035706338}\n",
            "INFO:tensorflow:Step 3800 per-step time 0.970s\n",
            "I0711 16:33:34.765349 140349244585856 model_lib_v2.py:700] Step 3800 per-step time 0.970s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.06331398,\n",
            " 'Loss/localization_loss': 0.018491456,\n",
            " 'Loss/regularization_loss': 0.16152176,\n",
            " 'Loss/total_loss': 0.2433272,\n",
            " 'learning_rate': 0.03520812}\n",
            "I0711 16:33:34.765665 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.06331398,\n",
            " 'Loss/localization_loss': 0.018491456,\n",
            " 'Loss/regularization_loss': 0.16152176,\n",
            " 'Loss/total_loss': 0.2433272,\n",
            " 'learning_rate': 0.03520812}\n",
            "INFO:tensorflow:Step 3900 per-step time 0.970s\n",
            "I0711 16:35:11.742936 140349244585856 model_lib_v2.py:700] Step 3900 per-step time 0.970s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.041623987,\n",
            " 'Loss/localization_loss': 0.009962377,\n",
            " 'Loss/regularization_loss': 0.15821725,\n",
            " 'Loss/total_loss': 0.20980361,\n",
            " 'learning_rate': 0.03468645}\n",
            "I0711 16:35:11.743259 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.041623987,\n",
            " 'Loss/localization_loss': 0.009962377,\n",
            " 'Loss/regularization_loss': 0.15821725,\n",
            " 'Loss/total_loss': 0.20980361,\n",
            " 'learning_rate': 0.03468645}\n",
            "INFO:tensorflow:Step 4000 per-step time 0.970s\n",
            "I0711 16:36:48.751927 140349244585856 model_lib_v2.py:700] Step 4000 per-step time 0.970s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.06182041,\n",
            " 'Loss/localization_loss': 0.016577946,\n",
            " 'Loss/regularization_loss': 0.1552976,\n",
            " 'Loss/total_loss': 0.23369595,\n",
            " 'learning_rate': 0.034142137}\n",
            "I0711 16:36:48.752220 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.06182041,\n",
            " 'Loss/localization_loss': 0.016577946,\n",
            " 'Loss/regularization_loss': 0.1552976,\n",
            " 'Loss/total_loss': 0.23369595,\n",
            " 'learning_rate': 0.034142137}\n",
            "INFO:tensorflow:Step 4100 per-step time 0.984s\n",
            "I0711 16:38:27.117330 140349244585856 model_lib_v2.py:700] Step 4100 per-step time 0.984s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.051763996,\n",
            " 'Loss/localization_loss': 0.016757088,\n",
            " 'Loss/regularization_loss': 0.15234238,\n",
            " 'Loss/total_loss': 0.22086346,\n",
            " 'learning_rate': 0.03357601}\n",
            "I0711 16:38:27.117632 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.051763996,\n",
            " 'Loss/localization_loss': 0.016757088,\n",
            " 'Loss/regularization_loss': 0.15234238,\n",
            " 'Loss/total_loss': 0.22086346,\n",
            " 'learning_rate': 0.03357601}\n",
            "INFO:tensorflow:Step 4200 per-step time 0.970s\n",
            "I0711 16:40:04.120397 140349244585856 model_lib_v2.py:700] Step 4200 per-step time 0.970s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.045283806,\n",
            " 'Loss/localization_loss': 0.012387036,\n",
            " 'Loss/regularization_loss': 0.1497143,\n",
            " 'Loss/total_loss': 0.20738515,\n",
            " 'learning_rate': 0.03298896}\n",
            "I0711 16:40:04.120700 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.045283806,\n",
            " 'Loss/localization_loss': 0.012387036,\n",
            " 'Loss/regularization_loss': 0.1497143,\n",
            " 'Loss/total_loss': 0.20738515,\n",
            " 'learning_rate': 0.03298896}\n",
            "INFO:tensorflow:Step 4300 per-step time 0.970s\n",
            "I0711 16:41:41.167634 140349244585856 model_lib_v2.py:700] Step 4300 per-step time 0.970s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.05044711,\n",
            " 'Loss/localization_loss': 0.011879006,\n",
            " 'Loss/regularization_loss': 0.14698778,\n",
            " 'Loss/total_loss': 0.2093139,\n",
            " 'learning_rate': 0.032381877}\n",
            "I0711 16:41:41.167945 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.05044711,\n",
            " 'Loss/localization_loss': 0.011879006,\n",
            " 'Loss/regularization_loss': 0.14698778,\n",
            " 'Loss/total_loss': 0.2093139,\n",
            " 'learning_rate': 0.032381877}\n",
            "INFO:tensorflow:Step 4400 per-step time 0.970s\n",
            "I0711 16:43:18.202832 140349244585856 model_lib_v2.py:700] Step 4400 per-step time 0.970s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.049706157,\n",
            " 'Loss/localization_loss': 0.010988591,\n",
            " 'Loss/regularization_loss': 0.14422987,\n",
            " 'Loss/total_loss': 0.20492461,\n",
            " 'learning_rate': 0.031755704}\n",
            "I0711 16:43:18.203123 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.049706157,\n",
            " 'Loss/localization_loss': 0.010988591,\n",
            " 'Loss/regularization_loss': 0.14422987,\n",
            " 'Loss/total_loss': 0.20492461,\n",
            " 'learning_rate': 0.031755704}\n",
            "INFO:tensorflow:Step 4500 per-step time 0.970s\n",
            "I0711 16:44:55.207297 140349244585856 model_lib_v2.py:700] Step 4500 per-step time 0.970s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.04422309,\n",
            " 'Loss/localization_loss': 0.011632953,\n",
            " 'Loss/regularization_loss': 0.14157645,\n",
            " 'Loss/total_loss': 0.19743249,\n",
            " 'learning_rate': 0.031111402}\n",
            "I0711 16:44:55.207583 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.04422309,\n",
            " 'Loss/localization_loss': 0.011632953,\n",
            " 'Loss/regularization_loss': 0.14157645,\n",
            " 'Loss/total_loss': 0.19743249,\n",
            " 'learning_rate': 0.031111402}\n",
            "INFO:tensorflow:Step 4600 per-step time 0.970s\n",
            "I0711 16:46:32.223466 140349244585856 model_lib_v2.py:700] Step 4600 per-step time 0.970s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.045429237,\n",
            " 'Loss/localization_loss': 0.0074224947,\n",
            " 'Loss/regularization_loss': 0.13903455,\n",
            " 'Loss/total_loss': 0.19188629,\n",
            " 'learning_rate': 0.03044997}\n",
            "I0711 16:46:32.223770 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.045429237,\n",
            " 'Loss/localization_loss': 0.0074224947,\n",
            " 'Loss/regularization_loss': 0.13903455,\n",
            " 'Loss/total_loss': 0.19188629,\n",
            " 'learning_rate': 0.03044997}\n",
            "INFO:tensorflow:Step 4700 per-step time 0.970s\n",
            "I0711 16:48:09.183425 140349244585856 model_lib_v2.py:700] Step 4700 per-step time 0.970s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.05955597,\n",
            " 'Loss/localization_loss': 0.014502276,\n",
            " 'Loss/regularization_loss': 0.13655238,\n",
            " 'Loss/total_loss': 0.21061063,\n",
            " 'learning_rate': 0.029772423}\n",
            "I0711 16:48:09.183723 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.05955597,\n",
            " 'Loss/localization_loss': 0.014502276,\n",
            " 'Loss/regularization_loss': 0.13655238,\n",
            " 'Loss/total_loss': 0.21061063,\n",
            " 'learning_rate': 0.029772423}\n",
            "INFO:tensorflow:Step 4800 per-step time 0.970s\n",
            "I0711 16:49:46.165625 140349244585856 model_lib_v2.py:700] Step 4800 per-step time 0.970s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.041500475,\n",
            " 'Loss/localization_loss': 0.0076028947,\n",
            " 'Loss/regularization_loss': 0.13417563,\n",
            " 'Loss/total_loss': 0.18327901,\n",
            " 'learning_rate': 0.029079808}\n",
            "I0711 16:49:46.165973 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.041500475,\n",
            " 'Loss/localization_loss': 0.0076028947,\n",
            " 'Loss/regularization_loss': 0.13417563,\n",
            " 'Loss/total_loss': 0.18327901,\n",
            " 'learning_rate': 0.029079808}\n",
            "INFO:tensorflow:Step 4900 per-step time 0.970s\n",
            "I0711 16:51:23.179236 140349244585856 model_lib_v2.py:700] Step 4900 per-step time 0.970s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.03589628,\n",
            " 'Loss/localization_loss': 0.010093587,\n",
            " 'Loss/regularization_loss': 0.13186108,\n",
            " 'Loss/total_loss': 0.17785095,\n",
            " 'learning_rate': 0.028373193}\n",
            "I0711 16:51:23.179559 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.03589628,\n",
            " 'Loss/localization_loss': 0.010093587,\n",
            " 'Loss/regularization_loss': 0.13186108,\n",
            " 'Loss/total_loss': 0.17785095,\n",
            " 'learning_rate': 0.028373193}\n",
            "INFO:tensorflow:Step 5000 per-step time 0.970s\n",
            "I0711 16:53:00.160323 140349244585856 model_lib_v2.py:700] Step 5000 per-step time 0.970s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.03917432,\n",
            " 'Loss/localization_loss': 0.006646765,\n",
            " 'Loss/regularization_loss': 0.12959665,\n",
            " 'Loss/total_loss': 0.17541774,\n",
            " 'learning_rate': 0.02765367}\n",
            "I0711 16:53:00.160674 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.03917432,\n",
            " 'Loss/localization_loss': 0.006646765,\n",
            " 'Loss/regularization_loss': 0.12959665,\n",
            " 'Loss/total_loss': 0.17541774,\n",
            " 'learning_rate': 0.02765367}\n",
            "INFO:tensorflow:Step 5100 per-step time 0.983s\n",
            "I0711 16:54:38.422866 140349244585856 model_lib_v2.py:700] Step 5100 per-step time 0.983s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.030375969,\n",
            " 'Loss/localization_loss': 0.0074626612,\n",
            " 'Loss/regularization_loss': 0.1274602,\n",
            " 'Loss/total_loss': 0.16529882,\n",
            " 'learning_rate': 0.02692234}\n",
            "I0711 16:54:38.423152 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.030375969,\n",
            " 'Loss/localization_loss': 0.0074626612,\n",
            " 'Loss/regularization_loss': 0.1274602,\n",
            " 'Loss/total_loss': 0.16529882,\n",
            " 'learning_rate': 0.02692234}\n",
            "INFO:tensorflow:Step 5200 per-step time 0.970s\n",
            "I0711 16:56:15.374706 140349244585856 model_lib_v2.py:700] Step 5200 per-step time 0.970s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.048002154,\n",
            " 'Loss/localization_loss': 0.008043099,\n",
            " 'Loss/regularization_loss': 0.12540247,\n",
            " 'Loss/total_loss': 0.18144771,\n",
            " 'learning_rate': 0.026180338}\n",
            "I0711 16:56:15.374989 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.048002154,\n",
            " 'Loss/localization_loss': 0.008043099,\n",
            " 'Loss/regularization_loss': 0.12540247,\n",
            " 'Loss/total_loss': 0.18144771,\n",
            " 'learning_rate': 0.026180338}\n",
            "INFO:tensorflow:Step 5300 per-step time 0.970s\n",
            "I0711 16:57:52.353914 140349244585856 model_lib_v2.py:700] Step 5300 per-step time 0.970s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.04014027,\n",
            " 'Loss/localization_loss': 0.015708433,\n",
            " 'Loss/regularization_loss': 0.12343602,\n",
            " 'Loss/total_loss': 0.17928472,\n",
            " 'learning_rate': 0.025428807}\n",
            "I0711 16:57:52.354223 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.04014027,\n",
            " 'Loss/localization_loss': 0.015708433,\n",
            " 'Loss/regularization_loss': 0.12343602,\n",
            " 'Loss/total_loss': 0.17928472,\n",
            " 'learning_rate': 0.025428807}\n",
            "INFO:tensorflow:Step 5400 per-step time 0.970s\n",
            "I0711 16:59:29.402894 140349244585856 model_lib_v2.py:700] Step 5400 per-step time 0.970s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.065903224,\n",
            " 'Loss/localization_loss': 0.018860392,\n",
            " 'Loss/regularization_loss': 0.121646136,\n",
            " 'Loss/total_loss': 0.20640975,\n",
            " 'learning_rate': 0.024668908}\n",
            "I0711 16:59:29.403183 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.065903224,\n",
            " 'Loss/localization_loss': 0.018860392,\n",
            " 'Loss/regularization_loss': 0.121646136,\n",
            " 'Loss/total_loss': 0.20640975,\n",
            " 'learning_rate': 0.024668908}\n",
            "INFO:tensorflow:Step 5500 per-step time 0.971s\n",
            "I0711 17:01:06.494667 140349244585856 model_lib_v2.py:700] Step 5500 per-step time 0.971s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.030773696,\n",
            " 'Loss/localization_loss': 0.0047332966,\n",
            " 'Loss/regularization_loss': 0.119806476,\n",
            " 'Loss/total_loss': 0.15531346,\n",
            " 'learning_rate': 0.023901805}\n",
            "I0711 17:01:06.494945 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.030773696,\n",
            " 'Loss/localization_loss': 0.0047332966,\n",
            " 'Loss/regularization_loss': 0.119806476,\n",
            " 'Loss/total_loss': 0.15531346,\n",
            " 'learning_rate': 0.023901805}\n",
            "INFO:tensorflow:Step 5600 per-step time 0.971s\n",
            "I0711 17:02:43.602731 140349244585856 model_lib_v2.py:700] Step 5600 per-step time 0.971s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.03278194,\n",
            " 'Loss/localization_loss': 0.0036094529,\n",
            " 'Loss/regularization_loss': 0.11802754,\n",
            " 'Loss/total_loss': 0.15441893,\n",
            " 'learning_rate': 0.02312869}\n",
            "I0711 17:02:43.603013 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.03278194,\n",
            " 'Loss/localization_loss': 0.0036094529,\n",
            " 'Loss/regularization_loss': 0.11802754,\n",
            " 'Loss/total_loss': 0.15441893,\n",
            " 'learning_rate': 0.02312869}\n",
            "INFO:tensorflow:Step 5700 per-step time 0.971s\n",
            "I0711 17:04:20.684350 140349244585856 model_lib_v2.py:700] Step 5700 per-step time 0.971s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.042725682,\n",
            " 'Loss/localization_loss': 0.009163855,\n",
            " 'Loss/regularization_loss': 0.11639726,\n",
            " 'Loss/total_loss': 0.1682868,\n",
            " 'learning_rate': 0.022350745}\n",
            "I0711 17:04:20.684648 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.042725682,\n",
            " 'Loss/localization_loss': 0.009163855,\n",
            " 'Loss/regularization_loss': 0.11639726,\n",
            " 'Loss/total_loss': 0.1682868,\n",
            " 'learning_rate': 0.022350745}\n",
            "INFO:tensorflow:Step 5800 per-step time 0.971s\n",
            "I0711 17:05:57.739275 140349244585856 model_lib_v2.py:700] Step 5800 per-step time 0.971s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.040107984,\n",
            " 'Loss/localization_loss': 0.0053834375,\n",
            " 'Loss/regularization_loss': 0.114868395,\n",
            " 'Loss/total_loss': 0.16035981,\n",
            " 'learning_rate': 0.02156918}\n",
            "I0711 17:05:57.739580 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.040107984,\n",
            " 'Loss/localization_loss': 0.0053834375,\n",
            " 'Loss/regularization_loss': 0.114868395,\n",
            " 'Loss/total_loss': 0.16035981,\n",
            " 'learning_rate': 0.02156918}\n",
            "INFO:tensorflow:Step 5900 per-step time 0.971s\n",
            "I0711 17:07:34.886016 140349244585856 model_lib_v2.py:700] Step 5900 per-step time 0.971s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.035289392,\n",
            " 'Loss/localization_loss': 0.0069132606,\n",
            " 'Loss/regularization_loss': 0.1133995,\n",
            " 'Loss/total_loss': 0.15560216,\n",
            " 'learning_rate': 0.020785196}\n",
            "I0711 17:07:34.886334 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.035289392,\n",
            " 'Loss/localization_loss': 0.0069132606,\n",
            " 'Loss/regularization_loss': 0.1133995,\n",
            " 'Loss/total_loss': 0.15560216,\n",
            " 'learning_rate': 0.020785196}\n",
            "INFO:tensorflow:Step 6000 per-step time 0.971s\n",
            "I0711 17:09:11.976390 140349244585856 model_lib_v2.py:700] Step 6000 per-step time 0.971s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.033659328,\n",
            " 'Loss/localization_loss': 0.004545609,\n",
            " 'Loss/regularization_loss': 0.111995056,\n",
            " 'Loss/total_loss': 0.1502,\n",
            " 'learning_rate': 0.019999998}\n",
            "I0711 17:09:11.976693 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.033659328,\n",
            " 'Loss/localization_loss': 0.004545609,\n",
            " 'Loss/regularization_loss': 0.111995056,\n",
            " 'Loss/total_loss': 0.1502,\n",
            " 'learning_rate': 0.019999998}\n",
            "INFO:tensorflow:Step 6100 per-step time 0.996s\n",
            "I0711 17:10:51.577495 140349244585856 model_lib_v2.py:700] Step 6100 per-step time 0.996s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.039014716,\n",
            " 'Loss/localization_loss': 0.007978324,\n",
            " 'Loss/regularization_loss': 0.11062307,\n",
            " 'Loss/total_loss': 0.15761611,\n",
            " 'learning_rate': 0.019214803}\n",
            "I0711 17:10:51.577793 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.039014716,\n",
            " 'Loss/localization_loss': 0.007978324,\n",
            " 'Loss/regularization_loss': 0.11062307,\n",
            " 'Loss/total_loss': 0.15761611,\n",
            " 'learning_rate': 0.019214803}\n",
            "INFO:tensorflow:Step 6200 per-step time 0.970s\n",
            "I0711 17:12:28.622799 140349244585856 model_lib_v2.py:700] Step 6200 per-step time 0.970s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.03548705,\n",
            " 'Loss/localization_loss': 0.0068983547,\n",
            " 'Loss/regularization_loss': 0.10929249,\n",
            " 'Loss/total_loss': 0.15167789,\n",
            " 'learning_rate': 0.018430816}\n",
            "I0711 17:12:28.623137 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.03548705,\n",
            " 'Loss/localization_loss': 0.0068983547,\n",
            " 'Loss/regularization_loss': 0.10929249,\n",
            " 'Loss/total_loss': 0.15167789,\n",
            " 'learning_rate': 0.018430816}\n",
            "INFO:tensorflow:Step 6300 per-step time 0.971s\n",
            "I0711 17:14:05.703110 140349244585856 model_lib_v2.py:700] Step 6300 per-step time 0.971s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.02869458,\n",
            " 'Loss/localization_loss': 0.0061177136,\n",
            " 'Loss/regularization_loss': 0.10805373,\n",
            " 'Loss/total_loss': 0.14286602,\n",
            " 'learning_rate': 0.017649252}\n",
            "I0711 17:14:05.703446 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.02869458,\n",
            " 'Loss/localization_loss': 0.0061177136,\n",
            " 'Loss/regularization_loss': 0.10805373,\n",
            " 'Loss/total_loss': 0.14286602,\n",
            " 'learning_rate': 0.017649252}\n",
            "INFO:tensorflow:Step 6400 per-step time 0.971s\n",
            "I0711 17:15:42.797521 140349244585856 model_lib_v2.py:700] Step 6400 per-step time 0.971s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.032571234,\n",
            " 'Loss/localization_loss': 0.004224631,\n",
            " 'Loss/regularization_loss': 0.106844135,\n",
            " 'Loss/total_loss': 0.14364,\n",
            " 'learning_rate': 0.01687131}\n",
            "I0711 17:15:42.797827 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.032571234,\n",
            " 'Loss/localization_loss': 0.004224631,\n",
            " 'Loss/regularization_loss': 0.106844135,\n",
            " 'Loss/total_loss': 0.14364,\n",
            " 'learning_rate': 0.01687131}\n",
            "INFO:tensorflow:Step 6500 per-step time 0.971s\n",
            "I0711 17:17:19.898181 140349244585856 model_lib_v2.py:700] Step 6500 per-step time 0.971s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.05150721,\n",
            " 'Loss/localization_loss': 0.010646814,\n",
            " 'Loss/regularization_loss': 0.10572288,\n",
            " 'Loss/total_loss': 0.1678769,\n",
            " 'learning_rate': 0.016098194}\n",
            "I0711 17:17:19.898518 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.05150721,\n",
            " 'Loss/localization_loss': 0.010646814,\n",
            " 'Loss/regularization_loss': 0.10572288,\n",
            " 'Loss/total_loss': 0.1678769,\n",
            " 'learning_rate': 0.016098194}\n",
            "INFO:tensorflow:Step 6600 per-step time 0.970s\n",
            "I0711 17:18:56.909178 140349244585856 model_lib_v2.py:700] Step 6600 per-step time 0.970s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.023749739,\n",
            " 'Loss/localization_loss': 0.0036555587,\n",
            " 'Loss/regularization_loss': 0.1046306,\n",
            " 'Loss/total_loss': 0.1320359,\n",
            " 'learning_rate': 0.015331091}\n",
            "I0711 17:18:56.909515 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.023749739,\n",
            " 'Loss/localization_loss': 0.0036555587,\n",
            " 'Loss/regularization_loss': 0.1046306,\n",
            " 'Loss/total_loss': 0.1320359,\n",
            " 'learning_rate': 0.015331091}\n",
            "INFO:tensorflow:Step 6700 per-step time 0.970s\n",
            "I0711 17:20:33.933339 140349244585856 model_lib_v2.py:700] Step 6700 per-step time 0.970s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.026588997,\n",
            " 'Loss/localization_loss': 0.0051926714,\n",
            " 'Loss/regularization_loss': 0.10358919,\n",
            " 'Loss/total_loss': 0.13537087,\n",
            " 'learning_rate': 0.014571187}\n",
            "I0711 17:20:33.933664 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.026588997,\n",
            " 'Loss/localization_loss': 0.0051926714,\n",
            " 'Loss/regularization_loss': 0.10358919,\n",
            " 'Loss/total_loss': 0.13537087,\n",
            " 'learning_rate': 0.014571187}\n",
            "INFO:tensorflow:Step 6800 per-step time 0.971s\n",
            "I0711 17:22:11.050925 140349244585856 model_lib_v2.py:700] Step 6800 per-step time 0.971s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.022381479,\n",
            " 'Loss/localization_loss': 0.0029201594,\n",
            " 'Loss/regularization_loss': 0.102613024,\n",
            " 'Loss/total_loss': 0.12791467,\n",
            " 'learning_rate': 0.013819658}\n",
            "I0711 17:22:11.051246 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.022381479,\n",
            " 'Loss/localization_loss': 0.0029201594,\n",
            " 'Loss/regularization_loss': 0.102613024,\n",
            " 'Loss/total_loss': 0.12791467,\n",
            " 'learning_rate': 0.013819658}\n",
            "INFO:tensorflow:Step 6900 per-step time 0.971s\n",
            "I0711 17:23:48.155001 140349244585856 model_lib_v2.py:700] Step 6900 per-step time 0.971s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.027075239,\n",
            " 'Loss/localization_loss': 0.005154314,\n",
            " 'Loss/regularization_loss': 0.10168014,\n",
            " 'Loss/total_loss': 0.13390969,\n",
            " 'learning_rate': 0.013077657}\n",
            "I0711 17:23:48.155282 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.027075239,\n",
            " 'Loss/localization_loss': 0.005154314,\n",
            " 'Loss/regularization_loss': 0.10168014,\n",
            " 'Loss/total_loss': 0.13390969,\n",
            " 'learning_rate': 0.013077657}\n",
            "INFO:tensorflow:Step 7000 per-step time 0.971s\n",
            "I0711 17:25:25.259130 140349244585856 model_lib_v2.py:700] Step 7000 per-step time 0.971s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.02393849,\n",
            " 'Loss/localization_loss': 0.003690188,\n",
            " 'Loss/regularization_loss': 0.10080314,\n",
            " 'Loss/total_loss': 0.12843181,\n",
            " 'learning_rate': 0.012346329}\n",
            "I0711 17:25:25.259448 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.02393849,\n",
            " 'Loss/localization_loss': 0.003690188,\n",
            " 'Loss/regularization_loss': 0.10080314,\n",
            " 'Loss/total_loss': 0.12843181,\n",
            " 'learning_rate': 0.012346329}\n",
            "INFO:tensorflow:Step 7100 per-step time 0.984s\n",
            "I0711 17:27:03.655982 140349244585856 model_lib_v2.py:700] Step 7100 per-step time 0.984s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.026192226,\n",
            " 'Loss/localization_loss': 0.0041257935,\n",
            " 'Loss/regularization_loss': 0.09999467,\n",
            " 'Loss/total_loss': 0.13031268,\n",
            " 'learning_rate': 0.011626803}\n",
            "I0711 17:27:03.656313 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.026192226,\n",
            " 'Loss/localization_loss': 0.0041257935,\n",
            " 'Loss/regularization_loss': 0.09999467,\n",
            " 'Loss/total_loss': 0.13031268,\n",
            " 'learning_rate': 0.011626803}\n",
            "INFO:tensorflow:Step 7200 per-step time 0.971s\n",
            "I0711 17:28:40.785091 140349244585856 model_lib_v2.py:700] Step 7200 per-step time 0.971s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.026090968,\n",
            " 'Loss/localization_loss': 0.0030659717,\n",
            " 'Loss/regularization_loss': 0.09923041,\n",
            " 'Loss/total_loss': 0.12838735,\n",
            " 'learning_rate': 0.010920188}\n",
            "I0711 17:28:40.785393 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.026090968,\n",
            " 'Loss/localization_loss': 0.0030659717,\n",
            " 'Loss/regularization_loss': 0.09923041,\n",
            " 'Loss/total_loss': 0.12838735,\n",
            " 'learning_rate': 0.010920188}\n",
            "INFO:tensorflow:Step 7300 per-step time 0.970s\n",
            "I0711 17:30:17.811265 140349244585856 model_lib_v2.py:700] Step 7300 per-step time 0.970s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.02446804,\n",
            " 'Loss/localization_loss': 0.0035618283,\n",
            " 'Loss/regularization_loss': 0.0984998,\n",
            " 'Loss/total_loss': 0.12652966,\n",
            " 'learning_rate': 0.010227573}\n",
            "I0711 17:30:17.811576 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.02446804,\n",
            " 'Loss/localization_loss': 0.0035618283,\n",
            " 'Loss/regularization_loss': 0.0984998,\n",
            " 'Loss/total_loss': 0.12652966,\n",
            " 'learning_rate': 0.010227573}\n",
            "INFO:tensorflow:Step 7400 per-step time 0.971s\n",
            "I0711 17:31:54.924150 140349244585856 model_lib_v2.py:700] Step 7400 per-step time 0.971s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.029605275,\n",
            " 'Loss/localization_loss': 0.00574287,\n",
            " 'Loss/regularization_loss': 0.09781272,\n",
            " 'Loss/total_loss': 0.13316086,\n",
            " 'learning_rate': 0.009550026}\n",
            "I0711 17:31:54.924463 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.029605275,\n",
            " 'Loss/localization_loss': 0.00574287,\n",
            " 'Loss/regularization_loss': 0.09781272,\n",
            " 'Loss/total_loss': 0.13316086,\n",
            " 'learning_rate': 0.009550026}\n",
            "INFO:tensorflow:Step 7500 per-step time 0.971s\n",
            "I0711 17:33:31.989468 140349244585856 model_lib_v2.py:700] Step 7500 per-step time 0.971s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.027400628,\n",
            " 'Loss/localization_loss': 0.01123172,\n",
            " 'Loss/regularization_loss': 0.097218245,\n",
            " 'Loss/total_loss': 0.1358506,\n",
            " 'learning_rate': 0.008888596}\n",
            "I0711 17:33:31.989800 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.027400628,\n",
            " 'Loss/localization_loss': 0.01123172,\n",
            " 'Loss/regularization_loss': 0.097218245,\n",
            " 'Loss/total_loss': 0.1358506,\n",
            " 'learning_rate': 0.008888596}\n",
            "INFO:tensorflow:Step 7600 per-step time 0.971s\n",
            "I0711 17:35:09.088269 140349244585856 model_lib_v2.py:700] Step 7600 per-step time 0.971s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.026920155,\n",
            " 'Loss/localization_loss': 0.0028532585,\n",
            " 'Loss/regularization_loss': 0.09664096,\n",
            " 'Loss/total_loss': 0.12641437,\n",
            " 'learning_rate': 0.008244291}\n",
            "I0711 17:35:09.088605 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.026920155,\n",
            " 'Loss/localization_loss': 0.0028532585,\n",
            " 'Loss/regularization_loss': 0.09664096,\n",
            " 'Loss/total_loss': 0.12641437,\n",
            " 'learning_rate': 0.008244291}\n",
            "INFO:tensorflow:Step 7700 per-step time 0.971s\n",
            "I0711 17:36:46.194869 140349244585856 model_lib_v2.py:700] Step 7700 per-step time 0.971s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.020967862,\n",
            " 'Loss/localization_loss': 0.0024856192,\n",
            " 'Loss/regularization_loss': 0.09609038,\n",
            " 'Loss/total_loss': 0.11954386,\n",
            " 'learning_rate': 0.007618121}\n",
            "I0711 17:36:46.195148 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.020967862,\n",
            " 'Loss/localization_loss': 0.0024856192,\n",
            " 'Loss/regularization_loss': 0.09609038,\n",
            " 'Loss/total_loss': 0.11954386,\n",
            " 'learning_rate': 0.007618121}\n",
            "INFO:tensorflow:Step 7800 per-step time 0.971s\n",
            "I0711 17:38:23.289965 140349244585856 model_lib_v2.py:700] Step 7800 per-step time 0.971s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.025433851,\n",
            " 'Loss/localization_loss': 0.0037111256,\n",
            " 'Loss/regularization_loss': 0.095585726,\n",
            " 'Loss/total_loss': 0.124730706,\n",
            " 'learning_rate': 0.0070110355}\n",
            "I0711 17:38:23.290262 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.025433851,\n",
            " 'Loss/localization_loss': 0.0037111256,\n",
            " 'Loss/regularization_loss': 0.095585726,\n",
            " 'Loss/total_loss': 0.124730706,\n",
            " 'learning_rate': 0.0070110355}\n",
            "INFO:tensorflow:Step 7900 per-step time 0.970s\n",
            "I0711 17:40:00.303166 140349244585856 model_lib_v2.py:700] Step 7900 per-step time 0.970s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.027496135,\n",
            " 'Loss/localization_loss': 0.0030283276,\n",
            " 'Loss/regularization_loss': 0.09511573,\n",
            " 'Loss/total_loss': 0.12564018,\n",
            " 'learning_rate': 0.0064239847}\n",
            "I0711 17:40:00.303540 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.027496135,\n",
            " 'Loss/localization_loss': 0.0030283276,\n",
            " 'Loss/regularization_loss': 0.09511573,\n",
            " 'Loss/total_loss': 0.12564018,\n",
            " 'learning_rate': 0.0064239847}\n",
            "INFO:tensorflow:Step 8000 per-step time 0.971s\n",
            "I0711 17:41:37.428134 140349244585856 model_lib_v2.py:700] Step 8000 per-step time 0.971s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.033888455,\n",
            " 'Loss/localization_loss': 0.009672873,\n",
            " 'Loss/regularization_loss': 0.09468938,\n",
            " 'Loss/total_loss': 0.13825071,\n",
            " 'learning_rate': 0.0058578644}\n",
            "I0711 17:41:37.428425 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.033888455,\n",
            " 'Loss/localization_loss': 0.009672873,\n",
            " 'Loss/regularization_loss': 0.09468938,\n",
            " 'Loss/total_loss': 0.13825071,\n",
            " 'learning_rate': 0.0058578644}\n",
            "INFO:tensorflow:Step 8100 per-step time 1.000s\n",
            "I0711 17:43:17.434131 140349244585856 model_lib_v2.py:700] Step 8100 per-step time 1.000s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.032687917,\n",
            " 'Loss/localization_loss': 0.0070867497,\n",
            " 'Loss/regularization_loss': 0.094299,\n",
            " 'Loss/total_loss': 0.13407367,\n",
            " 'learning_rate': 0.0053135487}\n",
            "I0711 17:43:17.434494 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.032687917,\n",
            " 'Loss/localization_loss': 0.0070867497,\n",
            " 'Loss/regularization_loss': 0.094299,\n",
            " 'Loss/total_loss': 0.13407367,\n",
            " 'learning_rate': 0.0053135487}\n",
            "INFO:tensorflow:Step 8200 per-step time 0.971s\n",
            "I0711 17:44:54.527086 140349244585856 model_lib_v2.py:700] Step 8200 per-step time 0.971s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.021341354,\n",
            " 'Loss/localization_loss': 0.0037353844,\n",
            " 'Loss/regularization_loss': 0.09394331,\n",
            " 'Loss/total_loss': 0.11902005,\n",
            " 'learning_rate': 0.0047918796}\n",
            "I0711 17:44:54.527376 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.021341354,\n",
            " 'Loss/localization_loss': 0.0037353844,\n",
            " 'Loss/regularization_loss': 0.09394331,\n",
            " 'Loss/total_loss': 0.11902005,\n",
            " 'learning_rate': 0.0047918796}\n",
            "INFO:tensorflow:Step 8300 per-step time 0.971s\n",
            "I0711 17:46:31.615243 140349244585856 model_lib_v2.py:700] Step 8300 per-step time 0.971s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.033424802,\n",
            " 'Loss/localization_loss': 0.006249827,\n",
            " 'Loss/regularization_loss': 0.0936221,\n",
            " 'Loss/total_loss': 0.13329673,\n",
            " 'learning_rate': 0.0042936574}\n",
            "I0711 17:46:31.615548 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.033424802,\n",
            " 'Loss/localization_loss': 0.006249827,\n",
            " 'Loss/regularization_loss': 0.0936221,\n",
            " 'Loss/total_loss': 0.13329673,\n",
            " 'learning_rate': 0.0042936574}\n",
            "INFO:tensorflow:Step 8400 per-step time 0.971s\n",
            "I0711 17:48:08.718930 140349244585856 model_lib_v2.py:700] Step 8400 per-step time 0.971s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.019908683,\n",
            " 'Loss/localization_loss': 0.0026090913,\n",
            " 'Loss/regularization_loss': 0.09333927,\n",
            " 'Loss/total_loss': 0.11585705,\n",
            " 'learning_rate': 0.0038196587}\n",
            "I0711 17:48:08.719233 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.019908683,\n",
            " 'Loss/localization_loss': 0.0026090913,\n",
            " 'Loss/regularization_loss': 0.09333927,\n",
            " 'Loss/total_loss': 0.11585705,\n",
            " 'learning_rate': 0.0038196587}\n",
            "INFO:tensorflow:Step 8500 per-step time 0.971s\n",
            "I0711 17:49:45.804558 140349244585856 model_lib_v2.py:700] Step 8500 per-step time 0.971s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.018187743,\n",
            " 'Loss/localization_loss': 0.0025065697,\n",
            " 'Loss/regularization_loss': 0.09308363,\n",
            " 'Loss/total_loss': 0.113777936,\n",
            " 'learning_rate': 0.0033706068}\n",
            "I0711 17:49:45.804851 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.018187743,\n",
            " 'Loss/localization_loss': 0.0025065697,\n",
            " 'Loss/regularization_loss': 0.09308363,\n",
            " 'Loss/total_loss': 0.113777936,\n",
            " 'learning_rate': 0.0033706068}\n",
            "INFO:tensorflow:Step 8600 per-step time 0.971s\n",
            "I0711 17:51:22.873561 140349244585856 model_lib_v2.py:700] Step 8600 per-step time 0.971s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.019850112,\n",
            " 'Loss/localization_loss': 0.0018835143,\n",
            " 'Loss/regularization_loss': 0.09285975,\n",
            " 'Loss/total_loss': 0.11459338,\n",
            " 'learning_rate': 0.0029471957}\n",
            "I0711 17:51:22.873887 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.019850112,\n",
            " 'Loss/localization_loss': 0.0018835143,\n",
            " 'Loss/regularization_loss': 0.09285975,\n",
            " 'Loss/total_loss': 0.11459338,\n",
            " 'learning_rate': 0.0029471957}\n",
            "INFO:tensorflow:Step 8700 per-step time 0.970s\n",
            "I0711 17:52:59.880275 140349244585856 model_lib_v2.py:700] Step 8700 per-step time 0.970s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.01630157,\n",
            " 'Loss/localization_loss': 0.0014768142,\n",
            " 'Loss/regularization_loss': 0.09266294,\n",
            " 'Loss/total_loss': 0.11044133,\n",
            " 'learning_rate': 0.0025500786}\n",
            "I0711 17:52:59.880593 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.01630157,\n",
            " 'Loss/localization_loss': 0.0014768142,\n",
            " 'Loss/regularization_loss': 0.09266294,\n",
            " 'Loss/total_loss': 0.11044133,\n",
            " 'learning_rate': 0.0025500786}\n",
            "INFO:tensorflow:Step 8800 per-step time 0.970s\n",
            "I0711 17:54:36.918600 140349244585856 model_lib_v2.py:700] Step 8800 per-step time 0.970s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.015234782,\n",
            " 'Loss/localization_loss': 0.0019106066,\n",
            " 'Loss/regularization_loss': 0.09249444,\n",
            " 'Loss/total_loss': 0.10963983,\n",
            " 'learning_rate': 0.0021798706}\n",
            "I0711 17:54:36.918894 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.015234782,\n",
            " 'Loss/localization_loss': 0.0019106066,\n",
            " 'Loss/regularization_loss': 0.09249444,\n",
            " 'Loss/total_loss': 0.10963983,\n",
            " 'learning_rate': 0.0021798706}\n",
            "INFO:tensorflow:Step 8900 per-step time 0.971s\n",
            "I0711 17:56:13.986788 140349244585856 model_lib_v2.py:700] Step 8900 per-step time 0.971s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.050074063,\n",
            " 'Loss/localization_loss': 0.012938766,\n",
            " 'Loss/regularization_loss': 0.09235031,\n",
            " 'Loss/total_loss': 0.15536314,\n",
            " 'learning_rate': 0.0018371355}\n",
            "I0711 17:56:13.987079 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.050074063,\n",
            " 'Loss/localization_loss': 0.012938766,\n",
            " 'Loss/regularization_loss': 0.09235031,\n",
            " 'Loss/total_loss': 0.15536314,\n",
            " 'learning_rate': 0.0018371355}\n",
            "INFO:tensorflow:Step 9000 per-step time 0.971s\n",
            "I0711 17:57:51.097226 140349244585856 model_lib_v2.py:700] Step 9000 per-step time 0.971s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.019587293,\n",
            " 'Loss/localization_loss': 0.0020384495,\n",
            " 'Loss/regularization_loss': 0.09222977,\n",
            " 'Loss/total_loss': 0.11385551,\n",
            " 'learning_rate': 0.0015224098}\n",
            "I0711 17:57:51.097528 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.019587293,\n",
            " 'Loss/localization_loss': 0.0020384495,\n",
            " 'Loss/regularization_loss': 0.09222977,\n",
            " 'Loss/total_loss': 0.11385551,\n",
            " 'learning_rate': 0.0015224098}\n",
            "INFO:tensorflow:Step 9100 per-step time 0.986s\n",
            "I0711 17:59:29.667667 140349244585856 model_lib_v2.py:700] Step 9100 per-step time 0.986s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.03614593,\n",
            " 'Loss/localization_loss': 0.005721212,\n",
            " 'Loss/regularization_loss': 0.092129976,\n",
            " 'Loss/total_loss': 0.13399711,\n",
            " 'learning_rate': 0.0012361717}\n",
            "I0711 17:59:29.667961 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.03614593,\n",
            " 'Loss/localization_loss': 0.005721212,\n",
            " 'Loss/regularization_loss': 0.092129976,\n",
            " 'Loss/total_loss': 0.13399711,\n",
            " 'learning_rate': 0.0012361717}\n",
            "INFO:tensorflow:Step 9200 per-step time 0.970s\n",
            "I0711 18:01:06.696662 140349244585856 model_lib_v2.py:700] Step 9200 per-step time 0.970s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.023201277,\n",
            " 'Loss/localization_loss': 0.004170124,\n",
            " 'Loss/regularization_loss': 0.09205034,\n",
            " 'Loss/total_loss': 0.119421735,\n",
            " 'learning_rate': 0.0009788703}\n",
            "I0711 18:01:06.696949 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.023201277,\n",
            " 'Loss/localization_loss': 0.004170124,\n",
            " 'Loss/regularization_loss': 0.09205034,\n",
            " 'Loss/total_loss': 0.119421735,\n",
            " 'learning_rate': 0.0009788703}\n",
            "INFO:tensorflow:Step 9300 per-step time 0.971s\n",
            "I0711 18:02:43.795227 140349244585856 model_lib_v2.py:700] Step 9300 per-step time 0.971s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.018692626,\n",
            " 'Loss/localization_loss': 0.005224893,\n",
            " 'Loss/regularization_loss': 0.09198777,\n",
            " 'Loss/total_loss': 0.115905285,\n",
            " 'learning_rate': 0.0007508957}\n",
            "I0711 18:02:43.795581 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.018692626,\n",
            " 'Loss/localization_loss': 0.005224893,\n",
            " 'Loss/regularization_loss': 0.09198777,\n",
            " 'Loss/total_loss': 0.115905285,\n",
            " 'learning_rate': 0.0007508957}\n",
            "INFO:tensorflow:Step 9400 per-step time 0.971s\n",
            "I0711 18:04:20.917649 140349244585856 model_lib_v2.py:700] Step 9400 per-step time 0.971s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.020518739,\n",
            " 'Loss/localization_loss': 0.0033603283,\n",
            " 'Loss/regularization_loss': 0.091940425,\n",
            " 'Loss/total_loss': 0.11581949,\n",
            " 'learning_rate': 0.0005526006}\n",
            "I0711 18:04:20.917945 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.020518739,\n",
            " 'Loss/localization_loss': 0.0033603283,\n",
            " 'Loss/regularization_loss': 0.091940425,\n",
            " 'Loss/total_loss': 0.11581949,\n",
            " 'learning_rate': 0.0005526006}\n",
            "INFO:tensorflow:Step 9500 per-step time 0.971s\n",
            "I0711 18:05:58.027735 140349244585856 model_lib_v2.py:700] Step 9500 per-step time 0.971s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.021144267,\n",
            " 'Loss/localization_loss': 0.004144082,\n",
            " 'Loss/regularization_loss': 0.09190599,\n",
            " 'Loss/total_loss': 0.11719434,\n",
            " 'learning_rate': 0.0003842938}\n",
            "I0711 18:05:58.028083 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.021144267,\n",
            " 'Loss/localization_loss': 0.004144082,\n",
            " 'Loss/regularization_loss': 0.09190599,\n",
            " 'Loss/total_loss': 0.11719434,\n",
            " 'learning_rate': 0.0003842938}\n",
            "INFO:tensorflow:Step 9600 per-step time 0.971s\n",
            "I0711 18:07:35.164421 140349244585856 model_lib_v2.py:700] Step 9600 per-step time 0.971s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.016191768,\n",
            " 'Loss/localization_loss': 0.0011375485,\n",
            " 'Loss/regularization_loss': 0.091882445,\n",
            " 'Loss/total_loss': 0.10921176,\n",
            " 'learning_rate': 0.00024623275}\n",
            "I0711 18:07:35.164746 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.016191768,\n",
            " 'Loss/localization_loss': 0.0011375485,\n",
            " 'Loss/regularization_loss': 0.091882445,\n",
            " 'Loss/total_loss': 0.10921176,\n",
            " 'learning_rate': 0.00024623275}\n",
            "INFO:tensorflow:Step 9700 per-step time 0.970s\n",
            "I0711 18:09:12.194883 140349244585856 model_lib_v2.py:700] Step 9700 per-step time 0.970s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.01794994,\n",
            " 'Loss/localization_loss': 0.0022036098,\n",
            " 'Loss/regularization_loss': 0.09186811,\n",
            " 'Loss/total_loss': 0.11202166,\n",
            " 'learning_rate': 0.00013863086}\n",
            "I0711 18:09:12.195244 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.01794994,\n",
            " 'Loss/localization_loss': 0.0022036098,\n",
            " 'Loss/regularization_loss': 0.09186811,\n",
            " 'Loss/total_loss': 0.11202166,\n",
            " 'learning_rate': 0.00013863086}\n",
            "INFO:tensorflow:Step 9800 per-step time 0.971s\n",
            "I0711 18:10:49.323102 140349244585856 model_lib_v2.py:700] Step 9800 per-step time 0.971s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.01947557,\n",
            " 'Loss/localization_loss': 0.0042772563,\n",
            " 'Loss/regularization_loss': 0.09186073,\n",
            " 'Loss/total_loss': 0.11561355,\n",
            " 'learning_rate': 6.165266e-05}\n",
            "I0711 18:10:49.323404 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.01947557,\n",
            " 'Loss/localization_loss': 0.0042772563,\n",
            " 'Loss/regularization_loss': 0.09186073,\n",
            " 'Loss/total_loss': 0.11561355,\n",
            " 'learning_rate': 6.165266e-05}\n",
            "INFO:tensorflow:Step 9900 per-step time 0.971s\n",
            "I0711 18:12:26.433085 140349244585856 model_lib_v2.py:700] Step 9900 per-step time 0.971s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.017290609,\n",
            " 'Loss/localization_loss': 0.0023733887,\n",
            " 'Loss/regularization_loss': 0.091857776,\n",
            " 'Loss/total_loss': 0.11152177,\n",
            " 'learning_rate': 1.541972e-05}\n",
            "I0711 18:12:26.433376 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.017290609,\n",
            " 'Loss/localization_loss': 0.0023733887,\n",
            " 'Loss/regularization_loss': 0.091857776,\n",
            " 'Loss/total_loss': 0.11152177,\n",
            " 'learning_rate': 1.541972e-05}\n",
            "INFO:tensorflow:Step 10000 per-step time 0.971s\n",
            "I0711 18:14:03.500886 140349244585856 model_lib_v2.py:700] Step 10000 per-step time 0.971s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.017715132,\n",
            " 'Loss/localization_loss': 0.0014132076,\n",
            " 'Loss/regularization_loss': 0.09185727,\n",
            " 'Loss/total_loss': 0.11098561,\n",
            " 'learning_rate': 0.0}\n",
            "I0711 18:14:03.501177 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.017715132,\n",
            " 'Loss/localization_loss': 0.0014132076,\n",
            " 'Loss/regularization_loss': 0.09185727,\n",
            " 'Loss/total_loss': 0.11098561,\n",
            " 'learning_rate': 0.0}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "EYmIuo9Nd3F3",
        "outputId": "ff93160d-3a7a-4f5d-94fa-c0ecc9396ff9"
      },
      "source": [
        "pwd"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/training_demo'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9vpOWvMvch92",
        "outputId": "766646b7-f817-41e0-d983-d2ae5a6d899c"
      },
      "source": [
        "!python exporter_main_v2.py --input_type image_tensor --pipeline_config_path /content/training_demo/models/my_ssd_resnet101_v1_fpn/pipeline.config --trained_checkpoint_dir /content/training_demo/models/my_ssd_resnet101_v1_fpn --output_directory /content/training_demo/exported_models/my_model"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-07-11 14:28:44.228200: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-07-11 14:28:46.272422: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "2021-07-11 14:28:46.273256: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
            "2021-07-11 14:28:46.286736: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-11 14:28:46.287310: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\n",
            "coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n",
            "2021-07-11 14:28:46.287335: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-07-11 14:28:46.289917: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
            "2021-07-11 14:28:46.289987: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
            "2021-07-11 14:28:46.291723: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
            "2021-07-11 14:28:46.292080: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
            "2021-07-11 14:28:46.294166: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-07-11 14:28:46.294802: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
            "2021-07-11 14:28:46.294976: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
            "2021-07-11 14:28:46.295066: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-11 14:28:46.295681: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-11 14:28:46.296192: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
            "2021-07-11 14:28:46.296525: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2021-07-11 14:28:46.296705: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "2021-07-11 14:28:46.296818: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-11 14:28:46.297356: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\n",
            "coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n",
            "2021-07-11 14:28:46.297381: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-07-11 14:28:46.297428: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
            "2021-07-11 14:28:46.297449: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
            "2021-07-11 14:28:46.297463: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
            "2021-07-11 14:28:46.297475: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
            "2021-07-11 14:28:46.297515: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-07-11 14:28:46.297532: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
            "2021-07-11 14:28:46.297545: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
            "2021-07-11 14:28:46.297598: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-11 14:28:46.298155: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-11 14:28:46.298668: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
            "2021-07-11 14:28:46.298709: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-07-11 14:28:46.966861: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-07-11 14:28:46.966912: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
            "2021-07-11 14:28:46.966922: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
            "2021-07-11 14:28:46.967156: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-11 14:28:46.967792: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-11 14:28:46.968331: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-11 14:28:46.968863: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2021-07-11 14:28:46.968905: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14957 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "WARNING:tensorflow:AutoGraph could not transform <bound method DetectionInferenceModule._preprocess_input of <object_detection.exporter_lib_v2.DetectionFromImageModule object at 0x7fa087aee5d0>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "W0711 14:28:47.054298 140329421457280 ag_logging.py:146] AutoGraph could not transform <bound method DetectionInferenceModule._preprocess_input of <object_detection.exporter_lib_v2.DetectionFromImageModule object at 0x7fa087aee5d0>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/exporter_lib_v2.py:111: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
            "Instead of:\n",
            "results = tf.map_fn(fn, elems, back_prop=False)\n",
            "Use:\n",
            "results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n",
            "W0711 14:28:47.054641 140329421457280 deprecation.py:604] From /usr/local/lib/python3.7/dist-packages/object_detection/exporter_lib_v2.py:111: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
            "Instead of:\n",
            "results = tf.map_fn(fn, elems, back_prop=False)\n",
            "Use:\n",
            "results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n",
            "WARNING:tensorflow:AutoGraph could not transform <function DetectionInferenceModule._preprocess_input.<locals>._decode_and_preprocess at 0x7fa0386a33b0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "W0711 14:28:47.073796 140329421457280 ag_logging.py:146] AutoGraph could not transform <function DetectionInferenceModule._preprocess_input.<locals>._decode_and_preprocess at 0x7fa0386a33b0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <bound method DetectionInferenceModule._run_inference_on_images of <object_detection.exporter_lib_v2.DetectionFromImageModule object at 0x7fa087aee5d0>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "W0711 14:28:47.111603 140329421457280 ag_logging.py:146] AutoGraph could not transform <bound method DetectionInferenceModule._run_inference_on_images of <object_detection.exporter_lib_v2.DetectionFromImageModule object at 0x7fa087aee5d0>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <bound method SSDResNetV1FpnKerasFeatureExtractor._extract_features of <object_detection.models.ssd_resnet_v1_fpn_keras_feature_extractor.SSDResNet101V1FpnKerasFeatureExtractor object at 0x7fa089581650>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "W0711 14:28:51.032678 140329421457280 ag_logging.py:146] AutoGraph could not transform <bound method SSDResNetV1FpnKerasFeatureExtractor._extract_features of <object_detection.models.ssd_resnet_v1_fpn_keras_feature_extractor.SSDResNet101V1FpnKerasFeatureExtractor object at 0x7fa089581650>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <bound method KerasFpnTopDownFeatureMaps.call of <object_detection.models.feature_map_generators.KerasFpnTopDownFeatureMaps object at 0x7fa021f86b90>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "W0711 14:28:51.650000 140329421457280 ag_logging.py:146] AutoGraph could not transform <bound method KerasFpnTopDownFeatureMaps.call of <object_detection.models.feature_map_generators.KerasFpnTopDownFeatureMaps object at 0x7fa021f86b90>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <bound method WeightSharedConvolutionalBoxPredictor._predict of <object_detection.predictors.convolutional_keras_box_predictor.WeightSharedConvolutionalBoxPredictor object at 0x7fa038790950>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "W0711 14:28:52.412020 140329421457280 ag_logging.py:146] AutoGraph could not transform <bound method WeightSharedConvolutionalBoxPredictor._predict of <object_detection.predictors.convolutional_keras_box_predictor.WeightSharedConvolutionalBoxPredictor object at 0x7fa038790950>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <bound method WeightSharedConvolutionalBoxHead._predict of <object_detection.predictors.heads.keras_box_head.WeightSharedConvolutionalBoxHead object at 0x7fa08701ac10>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "W0711 14:28:52.493912 140329421457280 ag_logging.py:146] AutoGraph could not transform <bound method WeightSharedConvolutionalBoxHead._predict of <object_detection.predictors.heads.keras_box_head.WeightSharedConvolutionalBoxHead object at 0x7fa08701ac10>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <bound method WeightSharedConvolutionalClassHead._predict of <object_detection.predictors.heads.keras_class_head.WeightSharedConvolutionalClassHead object at 0x7fa0880fd290>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "W0711 14:28:52.562242 140329421457280 ag_logging.py:146] AutoGraph could not transform <bound method WeightSharedConvolutionalClassHead._predict of <object_detection.predictors.heads.keras_class_head.WeightSharedConvolutionalClassHead object at 0x7fa0880fd290>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function DetectionInferenceModule._preprocess_input.<locals>._decode_and_preprocess at 0x7fa0214de560> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "W0711 14:28:53.766088 140329421457280 ag_logging.py:146] AutoGraph could not transform <function DetectionInferenceModule._preprocess_input.<locals>._decode_and_preprocess at 0x7fa0214de560> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7fa03873bc50>, because it is not built.\n",
            "W0711 14:28:59.919385 140329421457280 save_impl.py:78] Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7fa03873bc50>, because it is not built.\n",
            "2021-07-11 14:29:19.789103: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
            "WARNING:tensorflow:AutoGraph could not transform <function DetectionInferenceModule._preprocess_input.<locals>._decode_and_preprocess at 0x7fa00c6f3a70> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "W0711 14:29:20.064244 140329421457280 ag_logging.py:146] AutoGraph could not transform <function DetectionInferenceModule._preprocess_input.<locals>._decode_and_preprocess at 0x7fa00c6f3a70> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b263e50>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b263fd0>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b2675d0>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], True), {}).\n",
            "I0711 14:29:33.286212 140329421457280 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b263e50>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b263fd0>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b2675d0>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], True), {}).\n",
            "INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b2764d0>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b276a50>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b276c90>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], False), {}).\n",
            "I0711 14:29:33.286521 140329421457280 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b2764d0>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b276a50>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b276c90>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], False), {}).\n",
            "INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b2fb310>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b2fb910>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b2fbad0>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], True), {}).\n",
            "I0711 14:29:33.286714 140329421457280 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b2fb310>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b2fb910>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b2fbad0>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], True), {}).\n",
            "INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b2a8110>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b2a8690>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b2a88d0>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], False), {}).\n",
            "I0711 14:29:33.286844 140329421457280 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b2a8110>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b2a8690>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b2a88d0>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], False), {}).\n",
            "INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b263e50>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b263fd0>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b2675d0>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], True), {}).\n",
            "I0711 14:29:44.078882 140329421457280 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b263e50>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b263fd0>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b2675d0>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], True), {}).\n",
            "INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b2764d0>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b276a50>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b276c90>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], False), {}).\n",
            "I0711 14:29:44.079148 140329421457280 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b2764d0>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b276a50>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b276c90>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], False), {}).\n",
            "INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b2fb310>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b2fb910>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b2fbad0>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], True), {}).\n",
            "I0711 14:29:44.079300 140329421457280 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b2fb310>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b2fb910>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b2fbad0>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], True), {}).\n",
            "INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b2a8110>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b2a8690>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b2a88d0>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], False), {}).\n",
            "I0711 14:29:44.079422 140329421457280 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b2a8110>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b2a8690>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b2a88d0>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], False), {}).\n",
            "INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b2fb310>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b2fb910>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b2fbad0>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], True), {}).\n",
            "I0711 14:29:44.079592 140329421457280 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b2fb310>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b2fb910>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b2fbad0>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], True), {}).\n",
            "INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b2a8110>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b2a8690>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b2a88d0>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], False), {}).\n",
            "I0711 14:29:44.079713 140329421457280 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b2a8110>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b2a8690>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b2a88d0>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], False), {}).\n",
            "W0711 14:29:49.501631 140329421457280 save.py:241] Found untraced functions such as WeightSharedConvolutionalBoxPredictor_layer_call_fn, WeightSharedConvolutionalBoxPredictor_layer_call_and_return_conditional_losses, WeightSharedConvolutionalBoxHead_layer_call_fn, WeightSharedConvolutionalBoxHead_layer_call_and_return_conditional_losses, WeightSharedConvolutionalBoxPredictor_layer_call_fn while saving (showing 5 of 315). These functions will not be directly callable after loading.\n",
            "INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b263e50>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b263fd0>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b2675d0>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], True), {}).\n",
            "I0711 14:29:49.901180 140329421457280 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b263e50>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b263fd0>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b2675d0>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], True), {}).\n",
            "INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b2764d0>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b276a50>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b276c90>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], False), {}).\n",
            "I0711 14:29:49.901474 140329421457280 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b2764d0>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b276a50>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b276c90>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], False), {}).\n",
            "INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b2fb310>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b2fb910>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b2fbad0>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], True), {}).\n",
            "I0711 14:29:49.901682 140329421457280 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b2fb310>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b2fb910>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b2fbad0>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], True), {}).\n",
            "INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b2a8110>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b2a8690>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b2a88d0>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], False), {}).\n",
            "I0711 14:29:49.901813 140329421457280 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b2a8110>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b2a8690>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b2a88d0>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], False), {}).\n",
            "INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b263e50>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b263fd0>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b2675d0>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], True), {}).\n",
            "I0711 14:29:50.482307 140329421457280 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b263e50>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b263fd0>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b2675d0>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], True), {}).\n",
            "INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b2764d0>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b276a50>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b276c90>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], False), {}).\n",
            "I0711 14:29:50.482608 140329421457280 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b2764d0>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b276a50>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b276c90>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], False), {}).\n",
            "INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b2fb310>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b2fb910>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b2fbad0>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], True), {}).\n",
            "I0711 14:29:50.482775 140329421457280 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b2fb310>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b2fb910>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b2fbad0>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], True), {}).\n",
            "INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b2a8110>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b2a8690>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b2a88d0>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], False), {}).\n",
            "I0711 14:29:50.482894 140329421457280 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b2a8110>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b2a8690>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b2a88d0>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], False), {}).\n",
            "INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b2fb310>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b2fb910>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b2fbad0>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], True), {}).\n",
            "I0711 14:29:50.483013 140329421457280 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b2fb310>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b2fb910>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b2fbad0>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], True), {}).\n",
            "INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b2a8110>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b2a8690>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b2a88d0>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], False), {}).\n",
            "I0711 14:29:50.483120 140329421457280 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b2a8110>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b2a8690>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b2a88d0>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], False), {}).\n",
            "W0711 14:29:51.501244 140329421457280 save.py:241] Found untraced functions such as WeightSharedConvolutionalBoxPredictor_layer_call_fn, WeightSharedConvolutionalBoxPredictor_layer_call_and_return_conditional_losses, WeightSharedConvolutionalBoxHead_layer_call_fn, WeightSharedConvolutionalBoxHead_layer_call_and_return_conditional_losses, WeightSharedConvolutionalBoxPredictor_layer_call_fn while saving (showing 5 of 315). These functions will not be directly callable after loading.\n",
            "INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b263e50>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b263fd0>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b2675d0>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], True), {}).\n",
            "I0711 14:29:58.234127 140329421457280 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b263e50>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b263fd0>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b2675d0>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], True), {}).\n",
            "INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b2764d0>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b276a50>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b276c90>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], False), {}).\n",
            "I0711 14:29:58.234427 140329421457280 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b2764d0>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b276a50>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b276c90>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], False), {}).\n",
            "INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b2fb310>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b2fb910>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b2fbad0>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], True), {}).\n",
            "I0711 14:29:58.234802 140329421457280 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b2fb310>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b2fb910>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b2fbad0>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], True), {}).\n",
            "INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b2a8110>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b2a8690>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b2a88d0>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], False), {}).\n",
            "I0711 14:29:58.234968 140329421457280 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b2a8110>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b2a8690>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fa00b2a88d0>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], False), {}).\n",
            "INFO:tensorflow:Assets written to: /content/training_demo/exported_models/my_model/saved_model/assets\n",
            "I0711 14:30:00.183176 140329421457280 builder_impl.py:775] Assets written to: /content/training_demo/exported_models/my_model/saved_model/assets\n",
            "INFO:tensorflow:Writing pipeline config file to /content/training_demo/exported_models/my_model/pipeline.config\n",
            "I0711 14:30:01.387137 140329421457280 config_util.py:254] Writing pipeline config file to /content/training_demo/exported_models/my_model/pipeline.config\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "id": "PufE9qWLciAP",
        "outputId": "7488ae4f-0ebc-4e97-c9ba-5c27fa794b0b"
      },
      "source": [
        "\"\"\"\n",
        "Object Detection (On Image) From TF2 Saved Model\n",
        "=====================================\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'    # Suppress TensorFlow logging (1)\n",
        "import pathlib\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import argparse\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Enable GPU dynamic memory allocation\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "for gpu in gpus:\n",
        "    tf.config.experimental.set_memory_growth(gpu, True)\n",
        "\n",
        "# PROVIDE PATH TO IMAGE DIRECTORY\n",
        "IMAGE_PATHS = '/content/training_demo/images/train/img23.jpg'\n",
        "\n",
        "\n",
        "# PROVIDE PATH TO MODEL DIRECTORY\n",
        "PATH_TO_MODEL_DIR = '/content/training_demo/exported_models/my_model'\n",
        "\n",
        "# PROVIDE PATH TO LABEL MAP\n",
        "PATH_TO_LABELS = '/content/training_demo/annotations/label_map.pbtxt'\n",
        "\n",
        "# PROVIDE THE MINIMUM CONFIDENCE THRESHOLD\n",
        "MIN_CONF_THRESH = float(0.60)\n",
        "\n",
        "# LOAD THE MODEL\n",
        "\n",
        "import time\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "\n",
        "PATH_TO_SAVED_MODEL = PATH_TO_MODEL_DIR + \"/saved_model\"\n",
        "\n",
        "print('Loading model...', end='')\n",
        "start_time = time.time()\n",
        "\n",
        "# LOAD SAVED MODEL AND BUILD DETECTION FUNCTION\n",
        "detect_fn = tf.saved_model.load(PATH_TO_SAVED_MODEL)\n",
        "\n",
        "end_time = time.time()\n",
        "elapsed_time = end_time - start_time\n",
        "print('Done! Took {} seconds'.format(elapsed_time))\n",
        "\n",
        "# LOAD LABEL MAP DATA FOR PLOTTING\n",
        "\n",
        "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS,\n",
        "                                                                    use_display_name=True)\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')   # Suppress Matplotlib warnings\n",
        "\n",
        "def load_image_into_numpy_array(path):\n",
        "    \"\"\"Load an image from file into a numpy array.\n",
        "    Puts image into numpy array to feed into tensorflow graph.\n",
        "    Note that by convention we put it into a numpy array with shape\n",
        "    (height, width, channels), where channels=3 for RGB.\n",
        "    Args:\n",
        "      path: the file path to the image\n",
        "    Returns:\n",
        "      uint8 numpy array with shape (img_height, img_width, 3)\n",
        "    \"\"\"\n",
        "    return np.array(Image.open(path))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print('Running inference for {}... '.format(IMAGE_PATHS), end='')\n",
        "\n",
        "image = cv2.imread(IMAGE_PATHS)\n",
        "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "image_expanded = np.expand_dims(image_rgb, axis=0)\n",
        "\n",
        "# The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n",
        "input_tensor = tf.convert_to_tensor(image)\n",
        "# The model expects a batch of images, so add an axis with `tf.newaxis`.\n",
        "input_tensor = input_tensor[tf.newaxis, ...]\n",
        "\n",
        "# input_tensor = np.expand_dims(image_np, 0)\n",
        "detections = detect_fn(input_tensor)\n",
        "\n",
        "# All outputs are batches tensors.\n",
        "# Convert to numpy arrays, and take index [0] to remove the batch dimension.\n",
        "# We're only interested in the first num_detections.\n",
        "num_detections = int(detections.pop('num_detections'))\n",
        "detections = {key: value[0, :num_detections].numpy()\n",
        "               for key, value in detections.items()}\n",
        "detections['num_detections'] = num_detections\n",
        "\n",
        "# detection_classes should be ints.\n",
        "detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
        "\n",
        "image_with_detections = image.copy()\n",
        "\n",
        "# SET MIN_SCORE_THRESH BASED ON YOU MINIMUM THRESHOLD FOR DETECTIONS\n",
        "viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "      image_with_detections,\n",
        "      detections['detection_boxes'],\n",
        "      detections['detection_classes'],\n",
        "      detections['detection_scores'],\n",
        "      category_index,\n",
        "      use_normalized_coordinates=True,\n",
        "      max_boxes_to_draw=200,\n",
        "      min_score_thresh=0.5,\n",
        "      agnostic_mode=False)\n",
        "\n",
        "print('Done')\n",
        "# DISPLAYS OUTPUT IMAGE\n",
        "cv2_imshow(image_with_detections)\n",
        "# CLOSES WINDOW ONCE KEY IS PRESSED\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading model...Done! Took 26.998250246047974 seconds\n",
            "Running inference for /content/training_demo/images/train/img23.jpg... Done\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=275x183 at 0x7EFCC00C5250>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isR3eRTqciDF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMuTH3xEciFX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seeBYxXFciIU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}