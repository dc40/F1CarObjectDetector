{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TF Object Detection_v1.4",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "1Ju-7yAFx9uqWz8rmnPmarMuvrk1XziOb",
      "authorship_tag": "ABX9TyME0Vreywq55rtmVQB9WgQO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dc40/F1CarObjectDetector/blob/master/TF_Object_Detection_v1_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HALV-0Tqbkhi",
        "outputId": "ad85ebdc-899f-4256-ecb5-32dc929cdca3"
      },
      "source": [
        "!pip install tensorflow-gpu==2.4.1"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu==2.4.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/cc/a27e73cf8b23f2ce4bdd2b7089a42a7819ce6dd7366dceba406ddc5daa9c/tensorflow_gpu-2.4.1-cp37-cp37m-manylinux2010_x86_64.whl (394.3MB)\n",
            "\u001b[K     |████████████████████████████████| 394.3MB 40kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.4.1) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.4.1) (3.7.4.3)\n",
            "Collecting tensorflow-estimator<2.5.0,>=2.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/7e/622d9849abf3afb81e482ffc170758742e392ee129ce1540611199a59237/tensorflow_estimator-2.4.0-py2.py3-none-any.whl (462kB)\n",
            "\u001b[K     |████████████████████████████████| 471kB 53.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.4.1) (1.12)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.4.1) (1.6.3)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.4.1) (1.12.1)\n",
            "Collecting gast==0.3.3\n",
            "  Downloading https://files.pythonhosted.org/packages/d6/84/759f5dd23fec8ba71952d97bcc7e2c9d7d63bdc582421f3cd4be845f0c98/gast-0.3.3-py2.py3-none-any.whl\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.4.1) (1.1.0)\n",
            "Collecting grpcio~=1.32.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/06/54/1c8be62beafe7fb1548d2968e518ca040556b46b0275399d4f3186c56d79/grpcio-1.32.0-cp37-cp37m-manylinux2014_x86_64.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 58.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.4.1) (0.12.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.4.1) (0.2.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.4.1) (3.17.3)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.4.1) (2.5.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.4.1) (1.1.2)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.4.1) (3.3.0)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.4.1) (1.15.0)\n",
            "Collecting h5py~=2.10.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/c0/abde58b837e066bca19a3f7332d9d0493521d7dd6b48248451a9e3fe2214/h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 60.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.4.1) (0.36.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow-gpu==2.4.1) (1.8.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow-gpu==2.4.1) (57.0.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow-gpu==2.4.1) (0.4.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow-gpu==2.4.1) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow-gpu==2.4.1) (0.6.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow-gpu==2.4.1) (1.32.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow-gpu==2.4.1) (3.3.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow-gpu==2.4.1) (1.0.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow-gpu==2.4.1) (1.3.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow-gpu==2.4.1) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow-gpu==2.4.1) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow-gpu==2.4.1) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow-gpu==2.4.1) (2021.5.30)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow-gpu==2.4.1) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow-gpu==2.4.1) (4.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow-gpu==2.4.1) (0.2.8)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow-gpu==2.4.1) (4.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow-gpu==2.4.1) (3.1.1)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow-gpu==2.4.1) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow-gpu==2.4.1) (3.4.1)\n",
            "\u001b[31mERROR: tensorflow 2.5.0 has requirement gast==0.4.0, but you'll have gast 0.3.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.5.0 has requirement grpcio~=1.34.0, but you'll have grpcio 1.32.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.5.0 has requirement h5py~=3.1.0, but you'll have h5py 2.10.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.5.0 has requirement tensorflow-estimator<2.6.0,>=2.5.0rc0, but you'll have tensorflow-estimator 2.4.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorflow-estimator, gast, grpcio, h5py, tensorflow-gpu\n",
            "  Found existing installation: tensorflow-estimator 2.5.0\n",
            "    Uninstalling tensorflow-estimator-2.5.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.5.0\n",
            "  Found existing installation: gast 0.4.0\n",
            "    Uninstalling gast-0.4.0:\n",
            "      Successfully uninstalled gast-0.4.0\n",
            "  Found existing installation: grpcio 1.34.1\n",
            "    Uninstalling grpcio-1.34.1:\n",
            "      Successfully uninstalled grpcio-1.34.1\n",
            "  Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "Successfully installed gast-0.3.3 grpcio-1.32.0 h5py-2.10.0 tensorflow-estimator-2.4.0 tensorflow-gpu-2.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHvbssR6chQl",
        "outputId": "0e928825-4266-4e13-9968-9303157c7888"
      },
      "source": [
        "!git clone https://github.com/tensorflow/models.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'models'...\n",
            "remote: Enumerating objects: 58686, done.\u001b[K\n",
            "remote: Counting objects: 100% (412/412), done.\u001b[K\n",
            "remote: Compressing objects: 100% (189/189), done.\u001b[K\n",
            "remote: Total 58686 (delta 246), reused 375 (delta 221), pack-reused 58274\u001b[K\n",
            "Receiving objects: 100% (58686/58686), 573.40 MiB | 37.52 MiB/s, done.\n",
            "Resolving deltas: 100% (40719/40719), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "s_notlotchay",
        "outputId": "a6e197c0-7e4c-4df6-b3dd-785bf5c1e6ea"
      },
      "source": [
        "pwd"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mn2aAJo4chdS",
        "outputId": "6a9b631d-64b6-4090-87f3-324194db3b71"
      },
      "source": [
        "cd /content/models/research"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "sryJz2cichfp",
        "outputId": "105e973e-1b91-4083-a45c-405546696932"
      },
      "source": [
        "pwd"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/models/research'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2azurHIschhy"
      },
      "source": [
        "!protoc object_detection/protos/*.proto --python_out=."
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "faYosET4chkB",
        "outputId": "d902f986-e097-4512-ec5b-7335cd9dd406"
      },
      "source": [
        "!git clone https://github.com/cocodataset/cocoapi.git"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'cocoapi'...\n",
            "remote: Enumerating objects: 975, done.\u001b[K\n",
            "remote: Total 975 (delta 0), reused 0 (delta 0), pack-reused 975\u001b[K\n",
            "Receiving objects: 100% (975/975), 11.72 MiB | 17.73 MiB/s, done.\n",
            "Resolving deltas: 100% (576/576), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "umhNMRufchmS",
        "outputId": "4ba825ac-9bf0-4b6c-9051-52318e51367b"
      },
      "source": [
        "cd cocoapi/PythonAPI"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research/cocoapi/PythonAPI\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bir5TbNYchoU",
        "outputId": "10765d22-3f46-4c54-e6a2-c3916cb1e53f"
      },
      "source": [
        "!make"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "python setup.py build_ext --inplace\n",
            "running build_ext\n",
            "cythoning pycocotools/_mask.pyx to pycocotools/_mask.c\n",
            "/usr/local/lib/python3.7/dist-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /content/models/research/cocoapi/PythonAPI/pycocotools/_mask.pyx\n",
            "  tree = Parsing.p_module(s, pxd, full_module_name)\n",
            "building 'pycocotools._mask' extension\n",
            "creating build\n",
            "creating build/common\n",
            "creating build/temp.linux-x86_64-3.7\n",
            "creating build/temp.linux-x86_64-3.7/pycocotools\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.7/dist-packages/numpy/core/include -I../common -I/usr/include/python3.7m -c ../common/maskApi.c -o build/temp.linux-x86_64-3.7/../common/maskApi.o -Wno-cpp -Wno-unused-function -std=c99\n",
            "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleDecode\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K../common/maskApi.c:46:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "       \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K( k=0; k<R[i].cnts[j]; k++ ) *(M++)=v; v=!v; }}\n",
            "       \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:46:49:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’\n",
            "       for( k=0; k<R[i].cnts[j]; k++ ) *(M++)=v; \u001b[01;36m\u001b[Kv\u001b[m\u001b[K=!v; }}\n",
            "                                                 \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleFrPoly\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K../common/maskApi.c:166:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "   \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K(j=0; j<k; j++) x[j]=(int)(scale*xy[j*2+0]+.5); x[k]=x[0];\n",
            "   \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:166:54:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’\n",
            "   for(j=0; j<k; j++) x[j]=(int)(scale*xy[j*2+0]+.5); \u001b[01;36m\u001b[Kx\u001b[m\u001b[K[k]=x[0];\n",
            "                                                      \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:167:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "   \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K(j=0; j<k; j++) y[j]=(int)(scale*xy[j*2+1]+.5); y[k]=y[0];\n",
            "   \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:167:54:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’\n",
            "   for(j=0; j<k; j++) y[j]=(int)(scale*xy[j*2+1]+.5); \u001b[01;36m\u001b[Ky\u001b[m\u001b[K[k]=y[0];\n",
            "                                                      \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleToString\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K../common/maskApi.c:212:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "       \u001b[01;35m\u001b[Kif\u001b[m\u001b[K(more) c |= 0x20; c+=48; s[p++]=c;\n",
            "       \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:212:27:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’\n",
            "       if(more) c |= 0x20; \u001b[01;36m\u001b[Kc\u001b[m\u001b[K+=48; s[p++]=c;\n",
            "                           \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleFrString\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K../common/maskApi.c:220:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kwhile\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "   \u001b[01;35m\u001b[Kwhile\u001b[m\u001b[K( s[m] ) m++; cnts=malloc(sizeof(uint)*m); m=0;\n",
            "   \u001b[01;35m\u001b[K^~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:220:22:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kwhile\u001b[m\u001b[K’\n",
            "   while( s[m] ) m++; \u001b[01;36m\u001b[Kcnts\u001b[m\u001b[K=malloc(sizeof(uint)*m); m=0;\n",
            "                      \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:228:5:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "     \u001b[01;35m\u001b[Kif\u001b[m\u001b[K(m>2) x+=(long) cnts[m-2]; cnts[m++]=(uint) x;\n",
            "     \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:228:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’\n",
            "     if(m>2) x+=(long) cnts[m-2]; \u001b[01;36m\u001b[Kcnts\u001b[m\u001b[K[m++]=(uint) x;\n",
            "                                  \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleToBbox\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K../common/maskApi.c:141:31:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kxp\u001b[m\u001b[K’ may be used uninitialized in this function [\u001b[01;35m\u001b[K-Wmaybe-uninitialized\u001b[m\u001b[K]\n",
            "       if(j%2==0) xp=x; else if\u001b[01;35m\u001b[K(\u001b[m\u001b[Kxp<x) { ys=0; ye=h-1; }\n",
            "                               \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.7/dist-packages/numpy/core/include -I../common -I/usr/include/python3.7m -c pycocotools/_mask.c -o build/temp.linux-x86_64-3.7/pycocotools/_mask.o -Wno-cpp -Wno-unused-function -std=c99\n",
            "creating build/lib.linux-x86_64-3.7\n",
            "creating build/lib.linux-x86_64-3.7/pycocotools\n",
            "x86_64-linux-gnu-gcc -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.7/../common/maskApi.o build/temp.linux-x86_64-3.7/pycocotools/_mask.o -o build/lib.linux-x86_64-3.7/pycocotools/_mask.cpython-37m-x86_64-linux-gnu.so\n",
            "copying build/lib.linux-x86_64-3.7/pycocotools/_mask.cpython-37m-x86_64-linux-gnu.so -> pycocotools\n",
            "rm -rf build\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7rq3QE2chs9"
      },
      "source": [
        "cp -r pycocotools /content/models/research"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WqDlptn-chxe",
        "outputId": "f3fc5185-1d11-45f2-a214-9d2458f98d21"
      },
      "source": [
        "cd .."
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research/cocoapi\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AjkhcxYkch0J",
        "outputId": "9ae0093c-dcea-49d9-f4c8-61bb3f903571"
      },
      "source": [
        "cd .."
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCTjXExach2q"
      },
      "source": [
        "cp object_detection/packages/tf2/setup.py ."
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqwPm5BAch4-",
        "outputId": "d5d779bd-4be4-4a0e-dfd9-fbf95f7f5b45"
      },
      "source": [
        "!python -m pip install ."
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing /content/models/research\n",
            "Collecting avro-python3\n",
            "  Downloading https://files.pythonhosted.org/packages/cc/97/7a6970380ca8db9139a3cc0b0e3e0dd3e4bc584fb3644e1d06e71e1a55f0/avro-python3-1.10.2.tar.gz\n",
            "Collecting apache-beam\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/28/f0/83e04f7a693695f4ce3765fce1e573abbbf32153a309829651de056f8924/apache_beam-2.31.0-cp37-cp37m-manylinux2010_x86_64.whl (9.7MB)\n",
            "\u001b[K     |████████████████████████████████| 9.7MB 20.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (7.1.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (4.2.6)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (3.2.2)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.29.23)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.5.5)\n",
            "Collecting tf-slim\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/97/b0f4a64df018ca018cc035d44f2ef08f91e2e8aa67271f6f19633a015ff7/tf_slim-1.1.0-py2.py3-none-any.whl (352kB)\n",
            "\u001b[K     |████████████████████████████████| 358kB 40.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.15.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.0.2)\n",
            "Collecting lvis\n",
            "  Downloading https://files.pythonhosted.org/packages/72/b6/1992240ab48310b5360bfdd1d53163f43bb97d90dc5dc723c67d41c38e78/lvis-0.5.3-py3-none-any.whl\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.4.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.1.5)\n",
            "Collecting tf-models-official\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/96/08/81bbc275e8e9c6d1e03dd26daec3a67f45e6322804cbce3d51f93eae1961/tf_models_official-2.5.0-py2.py3-none-any.whl (1.6MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6MB 39.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: pymongo<4.0.0,>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (3.11.4)\n",
            "Collecting future<1.0.0,>=0.18.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/0b/38b06fd9b92dc2b68d58b75f900e97884c45bedd2ff83203d933cf5851c9/future-0.18.2.tar.gz (829kB)\n",
            "\u001b[K     |████████████████████████████████| 829kB 51.3MB/s \n",
            "\u001b[?25hCollecting dill<0.3.2,>=0.3.1.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c7/11/345f3173809cea7f1a193bfbf02403fff250a3360e0e118a1630985e547d/dill-0.3.1.1.tar.gz (151kB)\n",
            "\u001b[K     |████████████████████████████████| 153kB 63.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.3.0)\n",
            "Requirement already satisfied: oauth2client<5,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (4.1.3)\n",
            "Requirement already satisfied: grpcio<2,>=1.29.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.32.0)\n",
            "Requirement already satisfied: typing-extensions<3.8.0,>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (3.7.4.3)\n",
            "Requirement already satisfied: pytz>=2018.3 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (2018.9)\n",
            "Requirement already satisfied: pyarrow<5.0.0,>=0.15.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (3.0.0)\n",
            "Requirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.7)\n",
            "Collecting fastavro<2,>=0.21.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/92/10ee74edb0a39f4a7af1cf271b3ac725c54f5c243c26fa5059cd794d15d7/fastavro-1.4.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3MB 49.6MB/s \n",
            "\u001b[?25hCollecting hdfs<3.0.0,>=2.1.0\n",
            "  Downloading https://files.pythonhosted.org/packages/08/f7/4c3fad73123a24d7394b6f40d1ec9c1cbf2e921cfea1797216ffd0a51fb1/hdfs-2.6.0-py3-none-any.whl\n",
            "Requirement already satisfied: httplib2<0.20.0,>=0.8 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (0.17.4)\n",
            "Requirement already satisfied: numpy<1.21.0,>=1.14.3 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.19.5)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (2.8.1)\n",
            "Collecting requests<3.0.0,>=2.24.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/c1/24814557f1d22c56d50280771a17307e6bf87b70727d975fd6b2ce6b014a/requests-2.25.1-py2.py3-none-any.whl (61kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 9.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf<4,>=3.12.2 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (3.17.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->object-detection==0.1) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->object-detection==0.1) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->object-detection==0.1) (0.10.0)\n",
            "Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from tf-slim->object-detection==0.1) (0.12.0)\n",
            "Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.7/dist-packages (from pycocotools->object-detection==0.1) (57.0.0)\n",
            "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (4.1.2.30)\n",
            "Requirement already satisfied: tensorflow>=2.5.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (2.5.0)\n",
            "Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (1.12.8)\n",
            "Collecting seqeval\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9d/2d/233c79d5b4e5ab1dbf111242299153f3caddddbb691219f363ad55ce783d/seqeval-1.2.2.tar.gz (43kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 8.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: gin-config in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (0.4.0)\n",
            "Collecting tensorflow-addons\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/66/4b/e893d194e626c24b3df2253066aa418f46a432fdb68250cde14bf9bb0700/tensorflow_addons-0.13.0-cp37-cp37m-manylinux2010_x86_64.whl (679kB)\n",
            "\u001b[K     |████████████████████████████████| 686kB 43.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (0.12.0)\n",
            "Collecting tensorflow-model-optimization>=0.4.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/78/8f/f6969dc64709c5c5e22cfd7057a83adbc927e6855a431b234168222cbf03/tensorflow_model_optimization-0.6.0-py2.py3-none-any.whl (211kB)\n",
            "\u001b[K     |████████████████████████████████| 215kB 64.9MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ac/aa/1437691b0c7c83086ebb79ce2da16e00bef024f24fec2a5161c35476f499/sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 41.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (4.0.1)\n",
            "Collecting pyyaml>=5.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7a/a5/393c087efdc78091afa2af9f1378762f9821c9c1d7a22c5753fb5ac5f97a/PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636kB)\n",
            "\u001b[K     |████████████████████████████████| 645kB 41.9MB/s \n",
            "\u001b[?25hCollecting sacrebleu\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/57/0c7ca4e31a126189dab99c19951910bd081dea5bbd25f24b77107750eae7/sacrebleu-1.5.1-py3-none-any.whl (54kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 10.5MB/s \n",
            "\u001b[?25hCollecting py-cpuinfo>=3.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e6/ba/77120e44cbe9719152415b97d5bfb29f4053ee987d6cb63f55ce7d50fadc/py-cpuinfo-8.0.0.tar.gz (99kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 11.2MB/s \n",
            "\u001b[?25hCollecting opencv-python-headless\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/53/48036b28d46c1ed45ec655ae7ef6caab45e4452834d63817fdef64f333a3/opencv_python_headless-4.5.3.56-cp37-cp37m-manylinux2014_x86_64.whl (37.1MB)\n",
            "\u001b[K     |████████████████████████████████| 37.2MB 142kB/s \n",
            "\u001b[?25hRequirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (1.5.12)\n",
            "Requirement already satisfied: google-cloud-bigquery>=0.31.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (1.21.0)\n",
            "Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (5.4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.7/dist-packages (from oauth2client<5,>=2.0.1->apache-beam->object-detection==0.1) (0.2.8)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from oauth2client<5,>=2.0.1->apache-beam->object-detection==0.1) (0.4.8)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from oauth2client<5,>=2.0.1->apache-beam->object-detection==0.1) (4.7.2)\n",
            "Requirement already satisfied: docopt in /usr/local/lib/python3.7/dist-packages (from hdfs<3.0.0,>=2.1.0->apache-beam->object-detection==0.1) (0.6.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (2021.5.30)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (3.0.4)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (3.3.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (1.12)\n",
            "Requirement already satisfied: tensorboard~=2.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (2.5.0)\n",
            "Collecting tensorflow-estimator<2.6.0,>=2.5.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ec/78/b27f73e923becc6e79e18fe112cf75e3200d1ee35b0dba8fa46181bce56c/tensorflow_estimator-2.5.0-py2.py3-none-any.whl (462kB)\n",
            "\u001b[K     |████████████████████████████████| 471kB 66.1MB/s \n",
            "\u001b[?25hCollecting gast==0.4.0\n",
            "  Downloading https://files.pythonhosted.org/packages/b6/48/583c032b79ae5b3daa02225a675aeb673e58d2cb698e78510feceb11958c/gast-0.4.0-py3-none-any.whl\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (1.1.2)\n",
            "Collecting h5py~=3.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9d/74/9eae2bedd8201ab464308f42c601a12d79727a1c87f0c867fdefb212c6cf/h5py-3.1.0-cp37-cp37m-manylinux1_x86_64.whl (4.0MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0MB 59.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (0.2.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (0.36.2)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (1.12.1)\n",
            "Requirement already satisfied: keras-nightly~=2.5.0.dev in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (2.5.0.dev2021032900)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (0.0.4)\n",
            "Requirement already satisfied: google-api-core<2dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (1.26.3)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (3.0.1)\n",
            "Requirement already satisfied: google-auth>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (1.32.1)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval->tf-models-official->object-detection==0.1) (0.22.2.post1)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons->tf-models-official->object-detection==0.1) (2.7.1)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official->object-detection==0.1) (0.1.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (4.41.1)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: importlib-resources; python_version < \"3.9\" in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (5.2.0)\n",
            "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (21.2.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (2.3)\n",
            "Collecting portalocker==2.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/89/a6/3814b7107e0788040870e8825eebf214d72166adf656ba7d4bf14759a06a/portalocker-2.0.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official->object-detection==0.1) (5.0.2)\n",
            "Requirement already satisfied: google-cloud-core<2.0dev,>=1.0.3 in /usr/local/lib/python3.7/dist-packages (from google-cloud-bigquery>=0.31.0->tf-models-official->object-detection==0.1) (1.0.3)\n",
            "Requirement already satisfied: google-resumable-media!=0.4.0,<0.5.0dev,>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from google-cloud-bigquery>=0.31.0->tf-models-official->object-detection==0.1) (0.4.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (1.8.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (3.3.4)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (0.4.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (1.0.1)\n",
            "Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (1.5.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (1.53.0)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (20.9)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (4.2.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official->object-detection==0.1) (1.0.1)\n",
            "Requirement already satisfied: zipp>=3.1.0; python_version < \"3.10\" in /usr/local/lib/python3.7/dist-packages (from importlib-resources; python_version < \"3.9\"->tensorflow-datasets->tf-models-official->object-detection==0.1) (3.4.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official->object-detection==0.1) (1.3)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (4.6.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (1.3.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (3.1.1)\n",
            "Building wheels for collected packages: object-detection, avro-python3, future, dill, seqeval, py-cpuinfo\n",
            "  Building wheel for object-detection (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for object-detection: filename=object_detection-0.1-cp37-none-any.whl size=1658497 sha256=8e9827aa3066205ada67ff4d2ccd0c9c839ea90ad4cc06afd1660e79d323e953\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-0mm_0g5h/wheels/94/49/4b/39b051683087a22ef7e80ec52152a27249d1a644ccf4e442ea\n",
            "  Building wheel for avro-python3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for avro-python3: filename=avro_python3-1.10.2-cp37-none-any.whl size=44011 sha256=462074ba3488664b6c5e44d8a38cbea69be5450f4463b66ab725b58af52029f6\n",
            "  Stored in directory: /root/.cache/pip/wheels/ee/ee/18/c466221ca6900e3efce2f4ea9c329288808679aecdcb2838d3\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for future: filename=future-0.18.2-cp37-none-any.whl size=491070 sha256=df5e6c08bd8009338b6acfa4912584a5f8f52c8a6cbb67cbc7f478daa04bbf32\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/99/a0/81daf51dcd359a9377b110a8a886b3895921802d2fc1b2397e\n",
            "  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dill: filename=dill-0.3.1.1-cp37-none-any.whl size=78545 sha256=82b58e7d19c63dd81b69b66b0fcaa3919dc32702e9c6b77a7e0b107e00c87f6f\n",
            "  Stored in directory: /root/.cache/pip/wheels/59/b1/91/f02e76c732915c4015ab4010f3015469866c1eb9b14058d8e7\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-cp37-none-any.whl size=16184 sha256=9dc64c4b69f5a48b5e314d5bc36cac2c5c69f394d84baec10d45ec17b3204233\n",
            "  Stored in directory: /root/.cache/pip/wheels/52/df/1b/45d75646c37428f7e626214704a0e35bd3cfc32eda37e59e5f\n",
            "  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py-cpuinfo: filename=py_cpuinfo-8.0.0-cp37-none-any.whl size=22258 sha256=a7ed6b45acf8e233ca872c5f106cb0bd8608b044eaf90ee2e1ead2f02a23c0e5\n",
            "  Stored in directory: /root/.cache/pip/wheels/2e/15/f5/aa2a056d223903b52cf4870134e3a01df0c723816835dd08db\n",
            "Successfully built object-detection avro-python3 future dill seqeval py-cpuinfo\n",
            "\u001b[31mERROR: tensorflow 2.5.0 has requirement grpcio~=1.34.0, but you'll have grpcio 1.32.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-gpu 2.4.1 has requirement gast==0.3.3, but you'll have gast 0.4.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-gpu 2.4.1 has requirement h5py~=2.10.0, but you'll have h5py 3.1.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-gpu 2.4.1 has requirement tensorflow-estimator<2.5.0,>=2.4.0, but you'll have tensorflow-estimator 2.5.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: multiprocess 0.70.12.2 has requirement dill>=0.3.4, but you'll have dill 0.3.1.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement requests~=2.23.0, but you'll have requests 2.25.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: apache-beam 2.31.0 has requirement avro-python3!=1.9.2,<1.10.0,>=1.8.1, but you'll have avro-python3 1.10.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: avro-python3, future, dill, fastavro, requests, hdfs, apache-beam, tf-slim, lvis, seqeval, tensorflow-addons, tensorflow-model-optimization, sentencepiece, pyyaml, portalocker, sacrebleu, py-cpuinfo, opencv-python-headless, tf-models-official, object-detection, tensorflow-estimator, gast, h5py\n",
            "  Found existing installation: future 0.16.0\n",
            "    Uninstalling future-0.16.0:\n",
            "      Successfully uninstalled future-0.16.0\n",
            "  Found existing installation: dill 0.3.4\n",
            "    Uninstalling dill-0.3.4:\n",
            "      Successfully uninstalled dill-0.3.4\n",
            "  Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Found existing installation: tensorflow-estimator 2.4.0\n",
            "    Uninstalling tensorflow-estimator-2.4.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.4.0\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: h5py 2.10.0\n",
            "    Uninstalling h5py-2.10.0:\n",
            "      Successfully uninstalled h5py-2.10.0\n",
            "Successfully installed apache-beam-2.31.0 avro-python3-1.10.2 dill-0.3.1.1 fastavro-1.4.2 future-0.18.2 gast-0.4.0 h5py-3.1.0 hdfs-2.6.0 lvis-0.5.3 object-detection-0.1 opencv-python-headless-4.5.3.56 portalocker-2.0.0 py-cpuinfo-8.0.0 pyyaml-5.4.1 requests-2.25.1 sacrebleu-1.5.1 sentencepiece-0.1.96 seqeval-1.2.2 tensorflow-addons-0.13.0 tensorflow-estimator-2.5.0 tensorflow-model-optimization-0.6.0 tf-models-official-2.5.0 tf-slim-1.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7rcc5JIch7U",
        "outputId": "51323dde-94b1-45bf-c417-5ef15791773f"
      },
      "source": [
        "!python object_detection/builders/model_builder_tf2_test.py"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-07-12 17:20:38.946875: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "Running tests under Python 3.7.10: /usr/bin/python3\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
            "2021-07-12 17:20:41.380961: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "2021-07-12 17:20:41.381833: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
            "2021-07-12 17:20:41.431261: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-12 17:20:41.431878: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\n",
            "coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n",
            "2021-07-12 17:20:41.431918: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-07-12 17:20:41.522758: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
            "2021-07-12 17:20:41.522842: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
            "2021-07-12 17:20:41.630379: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
            "2021-07-12 17:20:41.655273: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
            "2021-07-12 17:20:41.841338: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-07-12 17:20:41.863829: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
            "2021-07-12 17:20:41.868542: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
            "2021-07-12 17:20:41.868707: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-12 17:20:41.869359: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-12 17:20:41.869915: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
            "2021-07-12 17:20:41.870437: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2021-07-12 17:20:41.870679: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "2021-07-12 17:20:41.870819: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-12 17:20:41.871400: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\n",
            "coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n",
            "2021-07-12 17:20:41.871444: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-07-12 17:20:41.871481: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
            "2021-07-12 17:20:41.871504: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
            "2021-07-12 17:20:41.871521: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
            "2021-07-12 17:20:41.871534: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
            "2021-07-12 17:20:41.871547: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-07-12 17:20:41.871562: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
            "2021-07-12 17:20:41.871577: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
            "2021-07-12 17:20:41.871634: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-12 17:20:41.872175: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-12 17:20:41.872681: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
            "2021-07-12 17:20:41.872724: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-07-12 17:20:42.435440: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-07-12 17:20:42.435495: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
            "2021-07-12 17:20:42.435504: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
            "2021-07-12 17:20:42.435721: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-12 17:20:42.436310: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-12 17:20:42.436857: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-12 17:20:42.437351: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2021-07-12 17:20:42.437390: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14957 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "W0712 17:20:42.735357 140017015310208 model_builder.py:1088] Building experimental DeepMAC meta-arch. Some features may be omitted.\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 1.79s\n",
            "I0712 17:20:43.167224 140017015310208 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 1.79s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.58s\n",
            "I0712 17:20:43.750934 140017015310208 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.58s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.37s\n",
            "I0712 17:20:44.121229 140017015310208 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.37s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.34s\n",
            "I0712 17:20:44.458936 140017015310208 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.34s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
            "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
            "W0712 17:20:44.461688 140017015310208 mobilenet_v2.py:286] `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "9412608/9406464 [==============================] - 0s 0us/step\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 1.12s\n",
            "I0712 17:20:45.576610 140017015310208 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 1.12s\n",
            "[  FAILED  ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "I0712 17:20:45.579437 140017015310208 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.03s\n",
            "I0712 17:20:45.607734 140017015310208 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.03s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.02s\n",
            "I0712 17:20:45.628632 140017015310208 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.02s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s\n",
            "I0712 17:20:45.649804 140017015310208 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.14s\n",
            "I0712 17:20:45.790952 140017015310208 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.14s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.14s\n",
            "I0712 17:20:45.927122 140017015310208 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.14s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.14s\n",
            "I0712 17:20:46.068664 140017015310208 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.14s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.14s\n",
            "I0712 17:20:46.211125 140017015310208 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.14s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.15s\n",
            "I0712 17:20:46.357387 140017015310208 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.15s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.04s\n",
            "I0712 17:20:46.400995 140017015310208 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.04s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "I0712 17:20:46.686704 140017015310208 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b0\n",
            "I0712 17:20:46.686860 140017015310208 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 64\n",
            "I0712 17:20:46.686931 140017015310208 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 3\n",
            "I0712 17:20:46.692650 140017015310208 efficientnet_model.py:147] round_filter input=32 output=32\n",
            "I0712 17:20:46.708131 140017015310208 efficientnet_model.py:147] round_filter input=32 output=32\n",
            "I0712 17:20:46.708251 140017015310208 efficientnet_model.py:147] round_filter input=16 output=16\n",
            "I0712 17:20:46.763823 140017015310208 efficientnet_model.py:147] round_filter input=16 output=16\n",
            "I0712 17:20:46.763978 140017015310208 efficientnet_model.py:147] round_filter input=24 output=24\n",
            "I0712 17:20:46.899382 140017015310208 efficientnet_model.py:147] round_filter input=24 output=24\n",
            "I0712 17:20:46.899553 140017015310208 efficientnet_model.py:147] round_filter input=40 output=40\n",
            "I0712 17:20:47.036037 140017015310208 efficientnet_model.py:147] round_filter input=40 output=40\n",
            "I0712 17:20:47.036195 140017015310208 efficientnet_model.py:147] round_filter input=80 output=80\n",
            "I0712 17:20:47.243302 140017015310208 efficientnet_model.py:147] round_filter input=80 output=80\n",
            "I0712 17:20:47.243494 140017015310208 efficientnet_model.py:147] round_filter input=112 output=112\n",
            "I0712 17:20:47.453172 140017015310208 efficientnet_model.py:147] round_filter input=112 output=112\n",
            "I0712 17:20:47.453353 140017015310208 efficientnet_model.py:147] round_filter input=192 output=192\n",
            "I0712 17:20:47.848184 140017015310208 efficientnet_model.py:147] round_filter input=192 output=192\n",
            "I0712 17:20:47.848345 140017015310208 efficientnet_model.py:147] round_filter input=320 output=320\n",
            "I0712 17:20:47.913672 140017015310208 efficientnet_model.py:147] round_filter input=1280 output=1280\n",
            "I0712 17:20:47.940305 140017015310208 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0712 17:20:48.011065 140017015310208 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b1\n",
            "I0712 17:20:48.011226 140017015310208 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 88\n",
            "I0712 17:20:48.011285 140017015310208 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 4\n",
            "I0712 17:20:48.015553 140017015310208 efficientnet_model.py:147] round_filter input=32 output=32\n",
            "I0712 17:20:48.029563 140017015310208 efficientnet_model.py:147] round_filter input=32 output=32\n",
            "I0712 17:20:48.029662 140017015310208 efficientnet_model.py:147] round_filter input=16 output=16\n",
            "I0712 17:20:48.140356 140017015310208 efficientnet_model.py:147] round_filter input=16 output=16\n",
            "I0712 17:20:48.140528 140017015310208 efficientnet_model.py:147] round_filter input=24 output=24\n",
            "I0712 17:20:48.342043 140017015310208 efficientnet_model.py:147] round_filter input=24 output=24\n",
            "I0712 17:20:48.342206 140017015310208 efficientnet_model.py:147] round_filter input=40 output=40\n",
            "I0712 17:20:48.550581 140017015310208 efficientnet_model.py:147] round_filter input=40 output=40\n",
            "I0712 17:20:48.550770 140017015310208 efficientnet_model.py:147] round_filter input=80 output=80\n",
            "I0712 17:20:48.826904 140017015310208 efficientnet_model.py:147] round_filter input=80 output=80\n",
            "I0712 17:20:48.827070 140017015310208 efficientnet_model.py:147] round_filter input=112 output=112\n",
            "I0712 17:20:49.101807 140017015310208 efficientnet_model.py:147] round_filter input=112 output=112\n",
            "I0712 17:20:49.101966 140017015310208 efficientnet_model.py:147] round_filter input=192 output=192\n",
            "I0712 17:20:49.448297 140017015310208 efficientnet_model.py:147] round_filter input=192 output=192\n",
            "I0712 17:20:49.448500 140017015310208 efficientnet_model.py:147] round_filter input=320 output=320\n",
            "I0712 17:20:49.584802 140017015310208 efficientnet_model.py:147] round_filter input=1280 output=1280\n",
            "I0712 17:20:49.611061 140017015310208 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0712 17:20:49.690848 140017015310208 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b2\n",
            "I0712 17:20:49.691011 140017015310208 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 112\n",
            "I0712 17:20:49.691066 140017015310208 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 5\n",
            "I0712 17:20:49.695398 140017015310208 efficientnet_model.py:147] round_filter input=32 output=32\n",
            "I0712 17:20:49.710564 140017015310208 efficientnet_model.py:147] round_filter input=32 output=32\n",
            "I0712 17:20:49.710678 140017015310208 efficientnet_model.py:147] round_filter input=16 output=16\n",
            "I0712 17:20:49.820352 140017015310208 efficientnet_model.py:147] round_filter input=16 output=16\n",
            "I0712 17:20:49.820523 140017015310208 efficientnet_model.py:147] round_filter input=24 output=24\n",
            "I0712 17:20:50.027092 140017015310208 efficientnet_model.py:147] round_filter input=24 output=24\n",
            "I0712 17:20:50.027264 140017015310208 efficientnet_model.py:147] round_filter input=40 output=48\n",
            "I0712 17:20:50.237052 140017015310208 efficientnet_model.py:147] round_filter input=40 output=48\n",
            "I0712 17:20:50.237230 140017015310208 efficientnet_model.py:147] round_filter input=80 output=88\n",
            "I0712 17:20:50.518828 140017015310208 efficientnet_model.py:147] round_filter input=80 output=88\n",
            "I0712 17:20:50.519007 140017015310208 efficientnet_model.py:147] round_filter input=112 output=120\n",
            "I0712 17:20:50.942928 140017015310208 efficientnet_model.py:147] round_filter input=112 output=120\n",
            "I0712 17:20:50.943116 140017015310208 efficientnet_model.py:147] round_filter input=192 output=208\n",
            "I0712 17:20:51.318602 140017015310208 efficientnet_model.py:147] round_filter input=192 output=208\n",
            "I0712 17:20:51.318792 140017015310208 efficientnet_model.py:147] round_filter input=320 output=352\n",
            "I0712 17:20:51.471385 140017015310208 efficientnet_model.py:147] round_filter input=1280 output=1408\n",
            "I0712 17:20:51.500429 140017015310208 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0712 17:20:51.589794 140017015310208 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b3\n",
            "I0712 17:20:51.589979 140017015310208 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 160\n",
            "I0712 17:20:51.590059 140017015310208 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 6\n",
            "I0712 17:20:51.595439 140017015310208 efficientnet_model.py:147] round_filter input=32 output=40\n",
            "I0712 17:20:51.614094 140017015310208 efficientnet_model.py:147] round_filter input=32 output=40\n",
            "I0712 17:20:51.614250 140017015310208 efficientnet_model.py:147] round_filter input=16 output=24\n",
            "I0712 17:20:51.740579 140017015310208 efficientnet_model.py:147] round_filter input=16 output=24\n",
            "I0712 17:20:51.740763 140017015310208 efficientnet_model.py:147] round_filter input=24 output=32\n",
            "I0712 17:20:51.970631 140017015310208 efficientnet_model.py:147] round_filter input=24 output=32\n",
            "I0712 17:20:51.970820 140017015310208 efficientnet_model.py:147] round_filter input=40 output=48\n",
            "I0712 17:20:52.195227 140017015310208 efficientnet_model.py:147] round_filter input=40 output=48\n",
            "I0712 17:20:52.195411 140017015310208 efficientnet_model.py:147] round_filter input=80 output=96\n",
            "I0712 17:20:52.566263 140017015310208 efficientnet_model.py:147] round_filter input=80 output=96\n",
            "I0712 17:20:52.566484 140017015310208 efficientnet_model.py:147] round_filter input=112 output=136\n",
            "I0712 17:20:52.926285 140017015310208 efficientnet_model.py:147] round_filter input=112 output=136\n",
            "I0712 17:20:52.926491 140017015310208 efficientnet_model.py:147] round_filter input=192 output=232\n",
            "I0712 17:20:53.350966 140017015310208 efficientnet_model.py:147] round_filter input=192 output=232\n",
            "I0712 17:20:53.351159 140017015310208 efficientnet_model.py:147] round_filter input=320 output=384\n",
            "I0712 17:20:53.490457 140017015310208 efficientnet_model.py:147] round_filter input=1280 output=1536\n",
            "I0712 17:20:53.515563 140017015310208 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0712 17:20:53.596025 140017015310208 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b4\n",
            "I0712 17:20:53.596193 140017015310208 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 224\n",
            "I0712 17:20:53.596264 140017015310208 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 7\n",
            "I0712 17:20:53.600542 140017015310208 efficientnet_model.py:147] round_filter input=32 output=48\n",
            "I0712 17:20:53.615035 140017015310208 efficientnet_model.py:147] round_filter input=32 output=48\n",
            "I0712 17:20:53.615161 140017015310208 efficientnet_model.py:147] round_filter input=16 output=24\n",
            "I0712 17:20:53.728594 140017015310208 efficientnet_model.py:147] round_filter input=16 output=24\n",
            "I0712 17:20:53.728760 140017015310208 efficientnet_model.py:147] round_filter input=24 output=32\n",
            "I0712 17:20:53.999879 140017015310208 efficientnet_model.py:147] round_filter input=24 output=32\n",
            "I0712 17:20:54.000053 140017015310208 efficientnet_model.py:147] round_filter input=40 output=56\n",
            "I0712 17:20:54.277969 140017015310208 efficientnet_model.py:147] round_filter input=40 output=56\n",
            "I0712 17:20:54.278142 140017015310208 efficientnet_model.py:147] round_filter input=80 output=112\n",
            "I0712 17:20:54.890356 140017015310208 efficientnet_model.py:147] round_filter input=80 output=112\n",
            "I0712 17:20:54.890570 140017015310208 efficientnet_model.py:147] round_filter input=112 output=160\n",
            "I0712 17:20:55.304032 140017015310208 efficientnet_model.py:147] round_filter input=112 output=160\n",
            "I0712 17:20:55.304220 140017015310208 efficientnet_model.py:147] round_filter input=192 output=272\n",
            "I0712 17:20:55.859290 140017015310208 efficientnet_model.py:147] round_filter input=192 output=272\n",
            "I0712 17:20:55.859489 140017015310208 efficientnet_model.py:147] round_filter input=320 output=448\n",
            "I0712 17:20:55.995830 140017015310208 efficientnet_model.py:147] round_filter input=1280 output=1792\n",
            "I0712 17:20:56.020449 140017015310208 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0712 17:20:56.109629 140017015310208 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b5\n",
            "I0712 17:20:56.109802 140017015310208 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 288\n",
            "I0712 17:20:56.109883 140017015310208 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 7\n",
            "I0712 17:20:56.114114 140017015310208 efficientnet_model.py:147] round_filter input=32 output=48\n",
            "I0712 17:20:56.127947 140017015310208 efficientnet_model.py:147] round_filter input=32 output=48\n",
            "I0712 17:20:56.128063 140017015310208 efficientnet_model.py:147] round_filter input=16 output=24\n",
            "I0712 17:20:56.291180 140017015310208 efficientnet_model.py:147] round_filter input=16 output=24\n",
            "I0712 17:20:56.291361 140017015310208 efficientnet_model.py:147] round_filter input=24 output=40\n",
            "I0712 17:20:56.631551 140017015310208 efficientnet_model.py:147] round_filter input=24 output=40\n",
            "I0712 17:20:56.631719 140017015310208 efficientnet_model.py:147] round_filter input=40 output=64\n",
            "I0712 17:20:56.972236 140017015310208 efficientnet_model.py:147] round_filter input=40 output=64\n",
            "I0712 17:20:56.972458 140017015310208 efficientnet_model.py:147] round_filter input=80 output=128\n",
            "I0712 17:20:57.465292 140017015310208 efficientnet_model.py:147] round_filter input=80 output=128\n",
            "I0712 17:20:57.465503 140017015310208 efficientnet_model.py:147] round_filter input=112 output=176\n",
            "I0712 17:20:57.953481 140017015310208 efficientnet_model.py:147] round_filter input=112 output=176\n",
            "I0712 17:20:57.953677 140017015310208 efficientnet_model.py:147] round_filter input=192 output=304\n",
            "I0712 17:20:58.592164 140017015310208 efficientnet_model.py:147] round_filter input=192 output=304\n",
            "I0712 17:20:58.592356 140017015310208 efficientnet_model.py:147] round_filter input=320 output=512\n",
            "I0712 17:20:58.977706 140017015310208 efficientnet_model.py:147] round_filter input=1280 output=2048\n",
            "I0712 17:20:59.006897 140017015310208 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0712 17:20:59.107956 140017015310208 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b6\n",
            "I0712 17:20:59.108135 140017015310208 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 384\n",
            "I0712 17:20:59.108209 140017015310208 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 8\n",
            "I0712 17:20:59.112513 140017015310208 efficientnet_model.py:147] round_filter input=32 output=56\n",
            "I0712 17:20:59.127320 140017015310208 efficientnet_model.py:147] round_filter input=32 output=56\n",
            "I0712 17:20:59.127493 140017015310208 efficientnet_model.py:147] round_filter input=16 output=32\n",
            "I0712 17:20:59.315322 140017015310208 efficientnet_model.py:147] round_filter input=16 output=32\n",
            "I0712 17:20:59.315532 140017015310208 efficientnet_model.py:147] round_filter input=24 output=40\n",
            "I0712 17:20:59.745227 140017015310208 efficientnet_model.py:147] round_filter input=24 output=40\n",
            "I0712 17:20:59.745413 140017015310208 efficientnet_model.py:147] round_filter input=40 output=72\n",
            "I0712 17:21:00.171665 140017015310208 efficientnet_model.py:147] round_filter input=40 output=72\n",
            "I0712 17:21:00.171840 140017015310208 efficientnet_model.py:147] round_filter input=80 output=144\n",
            "I0712 17:21:00.726646 140017015310208 efficientnet_model.py:147] round_filter input=80 output=144\n",
            "I0712 17:21:00.726823 140017015310208 efficientnet_model.py:147] round_filter input=112 output=200\n",
            "I0712 17:21:01.300805 140017015310208 efficientnet_model.py:147] round_filter input=112 output=200\n",
            "I0712 17:21:01.300991 140017015310208 efficientnet_model.py:147] round_filter input=192 output=344\n",
            "I0712 17:21:02.067077 140017015310208 efficientnet_model.py:147] round_filter input=192 output=344\n",
            "I0712 17:21:02.067269 140017015310208 efficientnet_model.py:147] round_filter input=320 output=576\n",
            "I0712 17:21:02.272321 140017015310208 efficientnet_model.py:147] round_filter input=1280 output=2304\n",
            "I0712 17:21:02.297292 140017015310208 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0712 17:21:02.412763 140017015310208 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b7\n",
            "I0712 17:21:02.412925 140017015310208 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 384\n",
            "I0712 17:21:02.412995 140017015310208 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 8\n",
            "I0712 17:21:02.417390 140017015310208 efficientnet_model.py:147] round_filter input=32 output=64\n",
            "I0712 17:21:02.431911 140017015310208 efficientnet_model.py:147] round_filter input=32 output=64\n",
            "I0712 17:21:02.432021 140017015310208 efficientnet_model.py:147] round_filter input=16 output=32\n",
            "I0712 17:21:02.659220 140017015310208 efficientnet_model.py:147] round_filter input=16 output=32\n",
            "I0712 17:21:02.659414 140017015310208 efficientnet_model.py:147] round_filter input=24 output=48\n",
            "I0712 17:21:03.402262 140017015310208 efficientnet_model.py:147] round_filter input=24 output=48\n",
            "I0712 17:21:03.402468 140017015310208 efficientnet_model.py:147] round_filter input=40 output=80\n",
            "I0712 17:21:03.879626 140017015310208 efficientnet_model.py:147] round_filter input=40 output=80\n",
            "I0712 17:21:03.879805 140017015310208 efficientnet_model.py:147] round_filter input=80 output=160\n",
            "I0712 17:21:04.568807 140017015310208 efficientnet_model.py:147] round_filter input=80 output=160\n",
            "I0712 17:21:04.569000 140017015310208 efficientnet_model.py:147] round_filter input=112 output=224\n",
            "I0712 17:21:05.252621 140017015310208 efficientnet_model.py:147] round_filter input=112 output=224\n",
            "I0712 17:21:05.252788 140017015310208 efficientnet_model.py:147] round_filter input=192 output=384\n",
            "I0712 17:21:06.156572 140017015310208 efficientnet_model.py:147] round_filter input=192 output=384\n",
            "I0712 17:21:06.156747 140017015310208 efficientnet_model.py:147] round_filter input=320 output=640\n",
            "I0712 17:21:06.433020 140017015310208 efficientnet_model.py:147] round_filter input=1280 output=2560\n",
            "I0712 17:21:06.466360 140017015310208 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 20.19s\n",
            "I0712 17:21:06.593755 140017015310208 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 20.19s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
            "I0712 17:21:06.600065 140017015310208 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "I0712 17:21:06.601640 140017015310208 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "I0712 17:21:06.602066 140017015310208 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "I0712 17:21:06.603413 140017015310208 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "[ RUN      ] ModelBuilderTF2Test.test_session\n",
            "[  SKIPPED ] ModelBuilderTF2Test.test_session\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "I0712 17:21:06.604656 140017015310208 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "I0712 17:21:06.605021 140017015310208 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "I0712 17:21:06.605893 140017015310208 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "======================================================================\n",
            "ERROR: test_create_center_net_model_mobilenet (__main__.ModelBuilderTF2Test)\n",
            "ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
            "Test building a CenterNet model using bilinear interpolation.\n",
            "----------------------------------------------------------------------\n",
            "Traceback (most recent call last):\n",
            "  File \"object_detection/builders/model_builder_tf2_test.py\", line 497, in test_create_center_net_model_mobilenet\n",
            "    model = model_builder.build(config, is_training=True)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/object_detection/builders/model_builder.py\", line 1227, in build\n",
            "    add_summaries)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/object_detection/builders/model_builder.py\", line 1078, in _build_center_net_model\n",
            "    center_net_config.feature_extractor, is_training)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/object_detection/builders/model_builder.py\", line 1192, in _build_center_net_feature_extractor\n",
            "    **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/object_detection/models/center_net_mobilenet_v2_fpn_feature_extractor.py\", line 156, in mobilenet_v2_fpn\n",
            "    weights='imagenet' if depth_multiplier == 1.0 else None)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/object_detection/models/keras_models/mobilenet_v2.py\", line 333, in mobilenet_v2\n",
            "    **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/applications/mobilenet_v2.py\", line 407, in MobileNetV2\n",
            "    model.load_weights(weights_path)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\", line 2234, in load_weights\n",
            "    hdf5_format.load_weights_from_hdf5_group(f, self.layers)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/saving/hdf5_format.py\", line 662, in load_weights_from_hdf5_group\n",
            "    original_keras_version = f.attrs['keras_version'].decode('utf8')\n",
            "AttributeError: 'str' object has no attribute 'decode'\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "Ran 24 tests in 25.232s\n",
            "\n",
            "FAILED (errors=1, skipped=1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BNLNEuv3d2xf",
        "outputId": "ba60028e-a9aa-4288-b068-e96ac2adce42"
      },
      "source": [
        "cd /content/training/pre-trained-models"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/training/pre-trained-models\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H3hWZ26Yd20B",
        "outputId": "6f8f0818-15da-439f-e5f9-0f92bc2cd30c"
      },
      "source": [
        "!wget http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_resnet101_v1_fpn_640x640_coco17_tpu-8.tar.gz"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-07-12 17:21:36--  http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_resnet101_v1_fpn_640x640_coco17_tpu-8.tar.gz\n",
            "Resolving download.tensorflow.org (download.tensorflow.org)... 108.177.119.128, 2a00:1450:4013:c00::80\n",
            "Connecting to download.tensorflow.org (download.tensorflow.org)|108.177.119.128|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 386527459 (369M) [application/x-tar]\n",
            "Saving to: ‘ssd_resnet101_v1_fpn_640x640_coco17_tpu-8.tar.gz’\n",
            "\n",
            "ssd_resnet101_v1_fp 100%[===================>] 368.62M  89.5MB/s    in 4.1s    \n",
            "\n",
            "2021-07-12 17:21:41 (89.5 MB/s) - ‘ssd_resnet101_v1_fpn_640x640_coco17_tpu-8.tar.gz’ saved [386527459/386527459]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3zXdQNOxd22H",
        "outputId": "55a781a0-1c20-4ca1-f114-000102adaddc"
      },
      "source": [
        "!tar -xvf ssd_resnet101_v1_fpn_640x640_coco17_tpu-8.tar.gz"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/\n",
            "ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/checkpoint/\n",
            "ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/checkpoint/ckpt-0.data-00000-of-00001\n",
            "ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/checkpoint/checkpoint\n",
            "ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/checkpoint/ckpt-0.index\n",
            "ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/pipeline.config\n",
            "ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/saved_model/\n",
            "ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/saved_model/saved_model.pb\n",
            "ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/saved_model/assets/\n",
            "ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/saved_model/variables/\n",
            "ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/saved_model/variables/variables.data-00000-of-00001\n",
            "ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/saved_model/variables/variables.index\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Kj0oG29md24h",
        "outputId": "a426196a-7f1b-4cf8-b459-80135dc73925"
      },
      "source": [
        "pwd"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/training/pre-trained-models'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3g9poaYd26k",
        "outputId": "6892b1a0-d360-497e-b21f-99f1319cf48c"
      },
      "source": [
        "cd /content/training"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4RVOp7i7d288",
        "outputId": "115a18b7-32a5-4154-88db-a60d00214d55"
      },
      "source": [
        "ls"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mannotations\u001b[0m/         export_tflite_graph_tf2.py  model_main_tf2.py\n",
            "\u001b[01;34mexported_models\u001b[0m/     generate_tfrecord.py        \u001b[01;34mmodels\u001b[0m/\n",
            "exporter_main_v2.py  \u001b[01;34mimages\u001b[0m/                     \u001b[01;34mpre-trained-models\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xuVybrOGd2_M",
        "outputId": "ffe619de-1505-48bc-b295-eb11b116ecc9"
      },
      "source": [
        "# Create train data:\n",
        "!python generate_tfrecord.py -x /content/training/images/train -l /content/training/annotations/label_map.pbtxt -o /content/training/annotations/train.record\n",
        "\n",
        "# Create test data:\n",
        "!python generate_tfrecord.py -x /content/training/images/test -l /content/training/annotations/label_map.pbtxt -o /content/training/annotations/test.record"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Successfully created the TFRecord file: /content/training/annotations/train.record\n",
            "Successfully created the TFRecord file: /content/training/annotations/test.record\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "XgI_HP6jd3BN",
        "outputId": "45c39d42-0302-4e19-d8aa-a51302556754"
      },
      "source": [
        "pwd"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/training'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JA7gTPphd3Dd",
        "outputId": "05716308-788b-42d9-ef72-412ee9fa0006"
      },
      "source": [
        "!python model_main_tf2.py --model_dir=/content/training/models/my_ssd_resnet101_v1_fpn --pipeline_config_path=/content/training/models/my_ssd_resnet101_v1_fpn/pipeline.config"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-07-12 17:25:13.849349: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-07-12 17:25:16.143655: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "2021-07-12 17:25:16.144569: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
            "2021-07-12 17:25:16.159510: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-12 17:25:16.160087: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\n",
            "coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n",
            "2021-07-12 17:25:16.160118: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-07-12 17:25:16.169383: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
            "2021-07-12 17:25:16.169497: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
            "2021-07-12 17:25:16.171176: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
            "2021-07-12 17:25:16.171544: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
            "2021-07-12 17:25:16.175159: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-07-12 17:25:16.175778: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
            "2021-07-12 17:25:16.175966: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
            "2021-07-12 17:25:16.176065: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-12 17:25:16.176700: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-12 17:25:16.177215: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
            "2021-07-12 17:25:16.177585: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2021-07-12 17:25:16.177761: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "2021-07-12 17:25:16.177863: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-12 17:25:16.178402: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\n",
            "coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n",
            "2021-07-12 17:25:16.178439: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-07-12 17:25:16.178476: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
            "2021-07-12 17:25:16.178506: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
            "2021-07-12 17:25:16.178528: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
            "2021-07-12 17:25:16.178549: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
            "2021-07-12 17:25:16.178570: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-07-12 17:25:16.178590: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
            "2021-07-12 17:25:16.178610: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
            "2021-07-12 17:25:16.178678: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-12 17:25:16.179236: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-12 17:25:16.179754: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
            "2021-07-12 17:25:16.179797: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-07-12 17:25:16.707453: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-07-12 17:25:16.707525: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
            "2021-07-12 17:25:16.707537: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
            "2021-07-12 17:25:16.707746: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-12 17:25:16.708352: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-12 17:25:16.709077: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-12 17:25:16.709700: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2021-07-12 17:25:16.709748: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14957 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "I0712 17:25:16.711450 139931247974272 mirrored_strategy.py:350] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "INFO:tensorflow:Maybe overwriting train_steps: None\n",
            "I0712 17:25:16.715583 139931247974272 config_util.py:552] Maybe overwriting train_steps: None\n",
            "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
            "I0712 17:25:16.715740 139931247974272 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py:558: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "W0712 17:25:16.831718 139931247974272 deprecation.py:339] From /usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py:558: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/training/annotations/train.record']\n",
            "I0712 17:25:16.835760 139931247974272 dataset_builder.py:163] Reading unweighted datasets: ['/content/training/annotations/train.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/training/annotations/train.record']\n",
            "I0712 17:25:16.835932 139931247974272 dataset_builder.py:80] Reading record datasets for input file: ['/content/training/annotations/train.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I0712 17:25:16.836013 139931247974272 dataset_builder.py:81] Number of filenames to read: 1\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W0712 17:25:16.836081 139931247974272 dataset_builder.py:88] num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.\n",
            "W0712 17:25:16.837878 139931247974272 deprecation.py:339] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W0712 17:25:16.853363 139931247974272 deprecation.py:339] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "WARNING:tensorflow:AutoGraph could not transform <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f43c017e750>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "W0712 17:25:16.887964 139931247974272 ag_logging.py:146] AutoGraph could not transform <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f43c017e750>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function build at 0x7f43c8f63440> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "W0712 17:25:17.128952 139931247974272 ag_logging.py:146] AutoGraph could not transform <function build at 0x7f43c8f63440> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function build at 0x7f43c9197290> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "W0712 17:25:17.198973 139931247974272 ag_logging.py:146] AutoGraph could not transform <function build at 0x7f43c9197290> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function transform_input_data at 0x7f43c8f770e0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "W0712 17:25:17.238277 139931247974272 ag_logging.py:146] AutoGraph could not transform <function transform_input_data at 0x7f43c8f770e0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:201: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "W0712 17:25:17.244073 139931247974272 deprecation.py:339] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:201: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:201: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "W0712 17:25:17.313668 139931247974272 deprecation.py:339] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:201: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/inputs.py:284: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0712 17:25:17.381119 139931247974272 deprecation.py:339] From /usr/local/lib/python3.7/dist-packages/object_detection/inputs.py:284: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:AutoGraph could not transform <function pad_input_data_to_static_shapes at 0x7f43c8f77170> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "W0712 17:25:17.641881 139931247974272 ag_logging.py:146] AutoGraph could not transform <function pad_input_data_to_static_shapes at 0x7f43c8f77170> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function _get_features_dict at 0x7f43c8f773b0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "W0712 17:25:17.867863 139931247974272 ag_logging.py:146] AutoGraph could not transform <function _get_features_dict at 0x7f43c8f773b0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function _get_labels_dict at 0x7f43c8f77290> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "W0712 17:25:17.886239 139931247974272 ag_logging.py:146] AutoGraph could not transform <function _get_labels_dict at 0x7f43c8f77290> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "2021-07-12 17:25:17.980452: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
            "2021-07-12 17:25:17.984336: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2000185000 Hz\n",
            "WARNING:tensorflow:AutoGraph could not transform <function call_for_each_replica at 0x7f43f9676680> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "W0712 17:25:18.957106 139931247974272 ag_logging.py:146] AutoGraph could not transform <function call_for_each_replica at 0x7f43f9676680> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/backend.py:434: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n",
            "WARNING:tensorflow:AutoGraph could not transform <function unstack_batch at 0x7f43c8f0d9e0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "W0712 17:25:19.009735 139927339067136 ag_logging.py:146] AutoGraph could not transform <function unstack_batch at 0x7f43c8f0d9e0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function _compute_losses_and_predictions_dicts at 0x7f43dc5ca170> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "W0712 17:25:19.025002 139927339067136 ag_logging.py:146] AutoGraph could not transform <function _compute_losses_and_predictions_dicts at 0x7f43dc5ca170> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <bound method SSDResNetV1FpnKerasFeatureExtractor._extract_features of <object_detection.models.ssd_resnet_v1_fpn_keras_feature_extractor.SSDResNet101V1FpnKerasFeatureExtractor object at 0x7f43c8cca2d0>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "W0712 17:25:21.069887 139927339067136 ag_logging.py:146] AutoGraph could not transform <bound method SSDResNetV1FpnKerasFeatureExtractor._extract_features of <object_detection.models.ssd_resnet_v1_fpn_keras_feature_extractor.SSDResNet101V1FpnKerasFeatureExtractor object at 0x7f43c8cca2d0>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <bound method KerasFpnTopDownFeatureMaps.call of <object_detection.models.feature_map_generators.KerasFpnTopDownFeatureMaps object at 0x7f4363919890>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "W0712 17:25:21.906309 139927339067136 ag_logging.py:146] AutoGraph could not transform <bound method KerasFpnTopDownFeatureMaps.call of <object_detection.models.feature_map_generators.KerasFpnTopDownFeatureMaps object at 0x7f4363919890>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <bound method WeightSharedConvolutionalBoxPredictor._predict of <object_detection.predictors.convolutional_keras_box_predictor.WeightSharedConvolutionalBoxPredictor object at 0x7f43c0174850>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "W0712 17:25:22.557190 139927339067136 ag_logging.py:146] AutoGraph could not transform <bound method WeightSharedConvolutionalBoxPredictor._predict of <object_detection.predictors.convolutional_keras_box_predictor.WeightSharedConvolutionalBoxPredictor object at 0x7f43c0174850>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <bound method WeightSharedConvolutionalBoxHead._predict of <object_detection.predictors.heads.keras_box_head.WeightSharedConvolutionalBoxHead object at 0x7f43c016d490>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "W0712 17:25:22.632671 139927339067136 ag_logging.py:146] AutoGraph could not transform <bound method WeightSharedConvolutionalBoxHead._predict of <object_detection.predictors.heads.keras_box_head.WeightSharedConvolutionalBoxHead object at 0x7f43c016d490>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <bound method WeightSharedConvolutionalClassHead._predict of <object_detection.predictors.heads.keras_class_head.WeightSharedConvolutionalClassHead object at 0x7f43c8f56810>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "W0712 17:25:22.693002 139927339067136 ag_logging.py:146] AutoGraph could not transform <bound method WeightSharedConvolutionalClassHead._predict of <object_detection.predictors.heads.keras_class_head.WeightSharedConvolutionalClassHead object at 0x7f43c8f56810>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "2021-07-12 17:25:32.323239: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
            "2021-07-12 17:25:33.474660: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
            "2021-07-12 17:25:33.493959: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0712 17:25:51.191856 139931247974272 cross_device_ops.py:565] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0712 17:25:51.192934 139931247974272 cross_device_ops.py:565] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0712 17:25:51.194746 139931247974272 cross_device_ops.py:565] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0712 17:25:51.195486 139931247974272 cross_device_ops.py:565] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0712 17:25:51.197307 139931247974272 cross_device_ops.py:565] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0712 17:25:51.198052 139931247974272 cross_device_ops.py:565] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0712 17:25:51.200191 139931247974272 cross_device_ops.py:565] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0712 17:25:51.200947 139931247974272 cross_device_ops.py:565] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0712 17:25:51.202372 139931247974272 cross_device_ops.py:565] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0712 17:25:51.203109 139931247974272 cross_device_ops.py:565] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "WARNING:tensorflow:AutoGraph could not transform <function train_loop.<locals>.train_step_fn at 0x7f4362e9fcb0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "W0712 17:25:51.959760 139930499458816 ag_logging.py:146] AutoGraph could not transform <function train_loop.<locals>.train_step_fn at 0x7f4362e9fcb0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:605: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n",
            "W0712 17:25:51.976638 139930499458816 deprecation.py:537] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:605: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n",
            "INFO:tensorflow:Step 100 per-step time 1.467s\n",
            "I0712 17:28:18.558258 139931247974272 model_lib_v2.py:700] Step 100 per-step time 1.467s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.19487944,\n",
            " 'Loss/localization_loss': 0.10432734,\n",
            " 'Loss/regularization_loss': 0.2822838,\n",
            " 'Loss/total_loss': 0.58149064,\n",
            " 'learning_rate': 0.014666351}\n",
            "I0712 17:28:18.558666 139931247974272 model_lib_v2.py:701] {'Loss/classification_loss': 0.19487944,\n",
            " 'Loss/localization_loss': 0.10432734,\n",
            " 'Loss/regularization_loss': 0.2822838,\n",
            " 'Loss/total_loss': 0.58149064,\n",
            " 'learning_rate': 0.014666351}\n",
            "INFO:tensorflow:Step 200 per-step time 0.968s\n",
            "I0712 17:29:55.399747 139931247974272 model_lib_v2.py:700] Step 200 per-step time 0.968s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.15409032,\n",
            " 'Loss/localization_loss': 0.10998071,\n",
            " 'Loss/regularization_loss': 0.28172413,\n",
            " 'Loss/total_loss': 0.54579514,\n",
            " 'learning_rate': 0.0159997}\n",
            "I0712 17:29:55.400087 139931247974272 model_lib_v2.py:701] {'Loss/classification_loss': 0.15409032,\n",
            " 'Loss/localization_loss': 0.10998071,\n",
            " 'Loss/regularization_loss': 0.28172413,\n",
            " 'Loss/total_loss': 0.54579514,\n",
            " 'learning_rate': 0.0159997}\n",
            "INFO:tensorflow:Step 300 per-step time 0.970s\n",
            "I0712 17:31:32.446858 139931247974272 model_lib_v2.py:700] Step 300 per-step time 0.970s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.10637011,\n",
            " 'Loss/localization_loss': 0.06289806,\n",
            " 'Loss/regularization_loss': 0.2801907,\n",
            " 'Loss/total_loss': 0.44945887,\n",
            " 'learning_rate': 0.01733305}\n",
            "I0712 17:31:32.447172 139931247974272 model_lib_v2.py:701] {'Loss/classification_loss': 0.10637011,\n",
            " 'Loss/localization_loss': 0.06289806,\n",
            " 'Loss/regularization_loss': 0.2801907,\n",
            " 'Loss/total_loss': 0.44945887,\n",
            " 'learning_rate': 0.01733305}\n",
            "INFO:tensorflow:Step 400 per-step time 0.970s\n",
            "I0712 17:33:09.482241 139931247974272 model_lib_v2.py:700] Step 400 per-step time 0.970s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.09031474,\n",
            " 'Loss/localization_loss': 0.050563235,\n",
            " 'Loss/regularization_loss': 0.278198,\n",
            " 'Loss/total_loss': 0.41907597,\n",
            " 'learning_rate': 0.0186664}\n",
            "I0712 17:33:09.482542 139931247974272 model_lib_v2.py:701] {'Loss/classification_loss': 0.09031474,\n",
            " 'Loss/localization_loss': 0.050563235,\n",
            " 'Loss/regularization_loss': 0.278198,\n",
            " 'Loss/total_loss': 0.41907597,\n",
            " 'learning_rate': 0.0186664}\n",
            "INFO:tensorflow:Step 500 per-step time 0.968s\n",
            "I0712 17:34:46.327721 139931247974272 model_lib_v2.py:700] Step 500 per-step time 0.968s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.08913129,\n",
            " 'Loss/localization_loss': 0.053923655,\n",
            " 'Loss/regularization_loss': 0.27570817,\n",
            " 'Loss/total_loss': 0.4187631,\n",
            " 'learning_rate': 0.01999975}\n",
            "I0712 17:34:46.327998 139931247974272 model_lib_v2.py:701] {'Loss/classification_loss': 0.08913129,\n",
            " 'Loss/localization_loss': 0.053923655,\n",
            " 'Loss/regularization_loss': 0.27570817,\n",
            " 'Loss/total_loss': 0.4187631,\n",
            " 'learning_rate': 0.01999975}\n",
            "INFO:tensorflow:Step 600 per-step time 0.970s\n",
            "I0712 17:36:23.283837 139931247974272 model_lib_v2.py:700] Step 600 per-step time 0.970s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.09972141,\n",
            " 'Loss/localization_loss': 0.03987433,\n",
            " 'Loss/regularization_loss': 0.27329984,\n",
            " 'Loss/total_loss': 0.4128956,\n",
            " 'learning_rate': 0.0213331}\n",
            "I0712 17:36:23.284154 139931247974272 model_lib_v2.py:701] {'Loss/classification_loss': 0.09972141,\n",
            " 'Loss/localization_loss': 0.03987433,\n",
            " 'Loss/regularization_loss': 0.27329984,\n",
            " 'Loss/total_loss': 0.4128956,\n",
            " 'learning_rate': 0.0213331}\n",
            "INFO:tensorflow:Step 700 per-step time 0.968s\n",
            "I0712 17:38:00.039101 139931247974272 model_lib_v2.py:700] Step 700 per-step time 0.968s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.0821458,\n",
            " 'Loss/localization_loss': 0.03658622,\n",
            " 'Loss/regularization_loss': 0.2704473,\n",
            " 'Loss/total_loss': 0.38917935,\n",
            " 'learning_rate': 0.02266645}\n",
            "I0712 17:38:00.039433 139931247974272 model_lib_v2.py:701] {'Loss/classification_loss': 0.0821458,\n",
            " 'Loss/localization_loss': 0.03658622,\n",
            " 'Loss/regularization_loss': 0.2704473,\n",
            " 'Loss/total_loss': 0.38917935,\n",
            " 'learning_rate': 0.02266645}\n",
            "INFO:tensorflow:Step 800 per-step time 0.968s\n",
            "I0712 17:39:36.824009 139931247974272 model_lib_v2.py:700] Step 800 per-step time 0.968s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.0743729,\n",
            " 'Loss/localization_loss': 0.027529165,\n",
            " 'Loss/regularization_loss': 0.26722842,\n",
            " 'Loss/total_loss': 0.3691305,\n",
            " 'learning_rate': 0.023999799}\n",
            "I0712 17:39:36.824308 139931247974272 model_lib_v2.py:701] {'Loss/classification_loss': 0.0743729,\n",
            " 'Loss/localization_loss': 0.027529165,\n",
            " 'Loss/regularization_loss': 0.26722842,\n",
            " 'Loss/total_loss': 0.3691305,\n",
            " 'learning_rate': 0.023999799}\n",
            "INFO:tensorflow:Step 900 per-step time 0.970s\n",
            "I0712 17:41:13.824693 139931247974272 model_lib_v2.py:700] Step 900 per-step time 0.970s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.08975541,\n",
            " 'Loss/localization_loss': 0.031031024,\n",
            " 'Loss/regularization_loss': 0.26384208,\n",
            " 'Loss/total_loss': 0.3846285,\n",
            " 'learning_rate': 0.025333151}\n",
            "I0712 17:41:13.824991 139931247974272 model_lib_v2.py:701] {'Loss/classification_loss': 0.08975541,\n",
            " 'Loss/localization_loss': 0.031031024,\n",
            " 'Loss/regularization_loss': 0.26384208,\n",
            " 'Loss/total_loss': 0.3846285,\n",
            " 'learning_rate': 0.025333151}\n",
            "INFO:tensorflow:Step 1000 per-step time 0.969s\n",
            "I0712 17:42:50.751055 139931247974272 model_lib_v2.py:700] Step 1000 per-step time 0.969s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.10570084,\n",
            " 'Loss/localization_loss': 0.02755266,\n",
            " 'Loss/regularization_loss': 0.26050806,\n",
            " 'Loss/total_loss': 0.39376158,\n",
            " 'learning_rate': 0.0266665}\n",
            "I0712 17:42:50.751333 139931247974272 model_lib_v2.py:701] {'Loss/classification_loss': 0.10570084,\n",
            " 'Loss/localization_loss': 0.02755266,\n",
            " 'Loss/regularization_loss': 0.26050806,\n",
            " 'Loss/total_loss': 0.39376158,\n",
            " 'learning_rate': 0.0266665}\n",
            "INFO:tensorflow:Step 1100 per-step time 0.981s\n",
            "I0712 17:44:28.893482 139931247974272 model_lib_v2.py:700] Step 1100 per-step time 0.981s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.067361355,\n",
            " 'Loss/localization_loss': 0.024274739,\n",
            " 'Loss/regularization_loss': 0.25755176,\n",
            " 'Loss/total_loss': 0.34918785,\n",
            " 'learning_rate': 0.02799985}\n",
            "I0712 17:44:28.893791 139931247974272 model_lib_v2.py:701] {'Loss/classification_loss': 0.067361355,\n",
            " 'Loss/localization_loss': 0.024274739,\n",
            " 'Loss/regularization_loss': 0.25755176,\n",
            " 'Loss/total_loss': 0.34918785,\n",
            " 'learning_rate': 0.02799985}\n",
            "INFO:tensorflow:Step 1200 per-step time 0.971s\n",
            "I0712 17:46:05.956672 139931247974272 model_lib_v2.py:700] Step 1200 per-step time 0.971s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.061216183,\n",
            " 'Loss/localization_loss': 0.014747936,\n",
            " 'Loss/regularization_loss': 0.25421682,\n",
            " 'Loss/total_loss': 0.33018094,\n",
            " 'learning_rate': 0.0293332}\n",
            "I0712 17:46:05.956964 139931247974272 model_lib_v2.py:701] {'Loss/classification_loss': 0.061216183,\n",
            " 'Loss/localization_loss': 0.014747936,\n",
            " 'Loss/regularization_loss': 0.25421682,\n",
            " 'Loss/total_loss': 0.33018094,\n",
            " 'learning_rate': 0.0293332}\n",
            "INFO:tensorflow:Step 1300 per-step time 0.969s\n",
            "I0712 17:47:42.822927 139931247974272 model_lib_v2.py:700] Step 1300 per-step time 0.969s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07006093,\n",
            " 'Loss/localization_loss': 0.025282538,\n",
            " 'Loss/regularization_loss': 0.25065508,\n",
            " 'Loss/total_loss': 0.34599856,\n",
            " 'learning_rate': 0.03066655}\n",
            "I0712 17:47:42.823223 139931247974272 model_lib_v2.py:701] {'Loss/classification_loss': 0.07006093,\n",
            " 'Loss/localization_loss': 0.025282538,\n",
            " 'Loss/regularization_loss': 0.25065508,\n",
            " 'Loss/total_loss': 0.34599856,\n",
            " 'learning_rate': 0.03066655}\n",
            "INFO:tensorflow:Step 1400 per-step time 0.971s\n",
            "I0712 17:49:19.945531 139931247974272 model_lib_v2.py:700] Step 1400 per-step time 0.971s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07791488,\n",
            " 'Loss/localization_loss': 0.030830402,\n",
            " 'Loss/regularization_loss': 0.24665031,\n",
            " 'Loss/total_loss': 0.3553956,\n",
            " 'learning_rate': 0.0319999}\n",
            "I0712 17:49:19.945816 139931247974272 model_lib_v2.py:701] {'Loss/classification_loss': 0.07791488,\n",
            " 'Loss/localization_loss': 0.030830402,\n",
            " 'Loss/regularization_loss': 0.24665031,\n",
            " 'Loss/total_loss': 0.3553956,\n",
            " 'learning_rate': 0.0319999}\n",
            "INFO:tensorflow:Step 1500 per-step time 0.968s\n",
            "I0712 17:50:56.778222 139931247974272 model_lib_v2.py:700] Step 1500 per-step time 0.968s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.064899795,\n",
            " 'Loss/localization_loss': 0.024933863,\n",
            " 'Loss/regularization_loss': 0.24278232,\n",
            " 'Loss/total_loss': 0.33261597,\n",
            " 'learning_rate': 0.03333325}\n",
            "I0712 17:50:56.778522 139931247974272 model_lib_v2.py:701] {'Loss/classification_loss': 0.064899795,\n",
            " 'Loss/localization_loss': 0.024933863,\n",
            " 'Loss/regularization_loss': 0.24278232,\n",
            " 'Loss/total_loss': 0.33261597,\n",
            " 'learning_rate': 0.03333325}\n",
            "INFO:tensorflow:Step 1600 per-step time 0.970s\n",
            "I0712 17:52:33.791474 139931247974272 model_lib_v2.py:700] Step 1600 per-step time 0.970s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.053337473,\n",
            " 'Loss/localization_loss': 0.01484085,\n",
            " 'Loss/regularization_loss': 0.23877998,\n",
            " 'Loss/total_loss': 0.30695832,\n",
            " 'learning_rate': 0.034666598}\n",
            "I0712 17:52:33.791786 139931247974272 model_lib_v2.py:701] {'Loss/classification_loss': 0.053337473,\n",
            " 'Loss/localization_loss': 0.01484085,\n",
            " 'Loss/regularization_loss': 0.23877998,\n",
            " 'Loss/total_loss': 0.30695832,\n",
            " 'learning_rate': 0.034666598}\n",
            "INFO:tensorflow:Step 1700 per-step time 0.968s\n",
            "I0712 17:54:10.593098 139931247974272 model_lib_v2.py:700] Step 1700 per-step time 0.968s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.06398252,\n",
            " 'Loss/localization_loss': 0.022576714,\n",
            " 'Loss/regularization_loss': 0.23562688,\n",
            " 'Loss/total_loss': 0.3221861,\n",
            " 'learning_rate': 0.03599995}\n",
            "I0712 17:54:10.593397 139931247974272 model_lib_v2.py:701] {'Loss/classification_loss': 0.06398252,\n",
            " 'Loss/localization_loss': 0.022576714,\n",
            " 'Loss/regularization_loss': 0.23562688,\n",
            " 'Loss/total_loss': 0.3221861,\n",
            " 'learning_rate': 0.03599995}\n",
            "INFO:tensorflow:Step 1800 per-step time 0.967s\n",
            "I0712 17:55:47.313071 139931247974272 model_lib_v2.py:700] Step 1800 per-step time 0.967s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.10611763,\n",
            " 'Loss/localization_loss': 0.0741134,\n",
            " 'Loss/regularization_loss': 0.23641689,\n",
            " 'Loss/total_loss': 0.4166479,\n",
            " 'learning_rate': 0.037333302}\n",
            "I0712 17:55:47.313361 139931247974272 model_lib_v2.py:701] {'Loss/classification_loss': 0.10611763,\n",
            " 'Loss/localization_loss': 0.0741134,\n",
            " 'Loss/regularization_loss': 0.23641689,\n",
            " 'Loss/total_loss': 0.4166479,\n",
            " 'learning_rate': 0.037333302}\n",
            "INFO:tensorflow:Step 1900 per-step time 0.970s\n",
            "I0712 17:57:24.338813 139931247974272 model_lib_v2.py:700] Step 1900 per-step time 0.970s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.15062203,\n",
            " 'Loss/localization_loss': 0.07787569,\n",
            " 'Loss/regularization_loss': 0.25780255,\n",
            " 'Loss/total_loss': 0.48630026,\n",
            " 'learning_rate': 0.03866665}\n",
            "I0712 17:57:24.339123 139931247974272 model_lib_v2.py:701] {'Loss/classification_loss': 0.15062203,\n",
            " 'Loss/localization_loss': 0.07787569,\n",
            " 'Loss/regularization_loss': 0.25780255,\n",
            " 'Loss/total_loss': 0.48630026,\n",
            " 'learning_rate': 0.03866665}\n",
            "INFO:tensorflow:Step 2000 per-step time 0.969s\n",
            "I0712 17:59:01.287865 139931247974272 model_lib_v2.py:700] Step 2000 per-step time 0.969s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07235736,\n",
            " 'Loss/localization_loss': 0.03415937,\n",
            " 'Loss/regularization_loss': 0.25819156,\n",
            " 'Loss/total_loss': 0.36470827,\n",
            " 'learning_rate': 0.04}\n",
            "I0712 17:59:01.288146 139931247974272 model_lib_v2.py:701] {'Loss/classification_loss': 0.07235736,\n",
            " 'Loss/localization_loss': 0.03415937,\n",
            " 'Loss/regularization_loss': 0.25819156,\n",
            " 'Loss/total_loss': 0.36470827,\n",
            " 'learning_rate': 0.04}\n",
            "INFO:tensorflow:Step 2100 per-step time 0.983s\n",
            "I0712 18:00:39.579984 139931247974272 model_lib_v2.py:700] Step 2100 per-step time 0.983s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.08274403,\n",
            " 'Loss/localization_loss': 0.033520512,\n",
            " 'Loss/regularization_loss': 0.25377625,\n",
            " 'Loss/total_loss': 0.3700408,\n",
            " 'learning_rate': 0.039753765}\n",
            "I0712 18:00:39.580310 139931247974272 model_lib_v2.py:701] {'Loss/classification_loss': 0.08274403,\n",
            " 'Loss/localization_loss': 0.033520512,\n",
            " 'Loss/regularization_loss': 0.25377625,\n",
            " 'Loss/total_loss': 0.3700408,\n",
            " 'learning_rate': 0.039753765}\n",
            "INFO:tensorflow:Step 2200 per-step time 0.969s\n",
            "I0712 18:02:16.440555 139931247974272 model_lib_v2.py:700] Step 2200 per-step time 0.969s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.06578636,\n",
            " 'Loss/localization_loss': 0.027649771,\n",
            " 'Loss/regularization_loss': 0.24828656,\n",
            " 'Loss/total_loss': 0.3417227,\n",
            " 'learning_rate': 0.039021127}\n",
            "I0712 18:02:16.440839 139931247974272 model_lib_v2.py:701] {'Loss/classification_loss': 0.06578636,\n",
            " 'Loss/localization_loss': 0.027649771,\n",
            " 'Loss/regularization_loss': 0.24828656,\n",
            " 'Loss/total_loss': 0.3417227,\n",
            " 'learning_rate': 0.039021127}\n",
            "INFO:tensorflow:Step 2300 per-step time 0.969s\n",
            "I0712 18:03:53.313855 139931247974272 model_lib_v2.py:700] Step 2300 per-step time 0.969s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.074683055,\n",
            " 'Loss/localization_loss': 0.030001786,\n",
            " 'Loss/regularization_loss': 0.24263945,\n",
            " 'Loss/total_loss': 0.3473243,\n",
            " 'learning_rate': 0.037820127}\n",
            "I0712 18:03:53.314175 139931247974272 model_lib_v2.py:701] {'Loss/classification_loss': 0.074683055,\n",
            " 'Loss/localization_loss': 0.030001786,\n",
            " 'Loss/regularization_loss': 0.24263945,\n",
            " 'Loss/total_loss': 0.3473243,\n",
            " 'learning_rate': 0.037820127}\n",
            "INFO:tensorflow:Step 2400 per-step time 0.972s\n",
            "I0712 18:05:30.472015 139931247974272 model_lib_v2.py:700] Step 2400 per-step time 0.972s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.05258143,\n",
            " 'Loss/localization_loss': 0.013088426,\n",
            " 'Loss/regularization_loss': 0.23775508,\n",
            " 'Loss/total_loss': 0.30342492,\n",
            " 'learning_rate': 0.03618034}\n",
            "I0712 18:05:30.472332 139931247974272 model_lib_v2.py:701] {'Loss/classification_loss': 0.05258143,\n",
            " 'Loss/localization_loss': 0.013088426,\n",
            " 'Loss/regularization_loss': 0.23775508,\n",
            " 'Loss/total_loss': 0.30342492,\n",
            " 'learning_rate': 0.03618034}\n",
            "INFO:tensorflow:Step 2500 per-step time 0.969s\n",
            "I0712 18:07:07.394111 139931247974272 model_lib_v2.py:700] Step 2500 per-step time 0.969s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.055139385,\n",
            " 'Loss/localization_loss': 0.016196351,\n",
            " 'Loss/regularization_loss': 0.23256755,\n",
            " 'Loss/total_loss': 0.30390328,\n",
            " 'learning_rate': 0.034142137}\n",
            "I0712 18:07:07.394428 139931247974272 model_lib_v2.py:701] {'Loss/classification_loss': 0.055139385,\n",
            " 'Loss/localization_loss': 0.016196351,\n",
            " 'Loss/regularization_loss': 0.23256755,\n",
            " 'Loss/total_loss': 0.30390328,\n",
            " 'learning_rate': 0.034142137}\n",
            "INFO:tensorflow:Step 2600 per-step time 0.968s\n",
            "I0712 18:08:44.206219 139931247974272 model_lib_v2.py:700] Step 2600 per-step time 0.968s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.09371229,\n",
            " 'Loss/localization_loss': 0.025179999,\n",
            " 'Loss/regularization_loss': 0.22762373,\n",
            " 'Loss/total_loss': 0.346516,\n",
            " 'learning_rate': 0.031755704}\n",
            "I0712 18:08:44.206558 139931247974272 model_lib_v2.py:701] {'Loss/classification_loss': 0.09371229,\n",
            " 'Loss/localization_loss': 0.025179999,\n",
            " 'Loss/regularization_loss': 0.22762373,\n",
            " 'Loss/total_loss': 0.346516,\n",
            " 'learning_rate': 0.031755704}\n",
            "INFO:tensorflow:Step 2700 per-step time 0.971s\n",
            "I0712 18:10:21.279988 139931247974272 model_lib_v2.py:700] Step 2700 per-step time 0.971s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.059367,\n",
            " 'Loss/localization_loss': 0.012423789,\n",
            " 'Loss/regularization_loss': 0.22297367,\n",
            " 'Loss/total_loss': 0.29476446,\n",
            " 'learning_rate': 0.029079808}\n",
            "I0712 18:10:21.280272 139931247974272 model_lib_v2.py:701] {'Loss/classification_loss': 0.059367,\n",
            " 'Loss/localization_loss': 0.012423789,\n",
            " 'Loss/regularization_loss': 0.22297367,\n",
            " 'Loss/total_loss': 0.29476446,\n",
            " 'learning_rate': 0.029079808}\n",
            "INFO:tensorflow:Step 2800 per-step time 0.969s\n",
            "I0712 18:11:58.147026 139931247974272 model_lib_v2.py:700] Step 2800 per-step time 0.969s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.038031954,\n",
            " 'Loss/localization_loss': 0.009436225,\n",
            " 'Loss/regularization_loss': 0.2188735,\n",
            " 'Loss/total_loss': 0.2663417,\n",
            " 'learning_rate': 0.026180338}\n",
            "I0712 18:11:58.147302 139931247974272 model_lib_v2.py:701] {'Loss/classification_loss': 0.038031954,\n",
            " 'Loss/localization_loss': 0.009436225,\n",
            " 'Loss/regularization_loss': 0.2188735,\n",
            " 'Loss/total_loss': 0.2663417,\n",
            " 'learning_rate': 0.026180338}\n",
            "INFO:tensorflow:Step 2900 per-step time 0.970s\n",
            "I0712 18:13:35.187211 139931247974272 model_lib_v2.py:700] Step 2900 per-step time 0.970s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.047537766,\n",
            " 'Loss/localization_loss': 0.010190843,\n",
            " 'Loss/regularization_loss': 0.21513976,\n",
            " 'Loss/total_loss': 0.27286837,\n",
            " 'learning_rate': 0.02312869}\n",
            "I0712 18:13:35.187625 139931247974272 model_lib_v2.py:701] {'Loss/classification_loss': 0.047537766,\n",
            " 'Loss/localization_loss': 0.010190843,\n",
            " 'Loss/regularization_loss': 0.21513976,\n",
            " 'Loss/total_loss': 0.27286837,\n",
            " 'learning_rate': 0.02312869}\n",
            "INFO:tensorflow:Step 3000 per-step time 0.972s\n",
            "I0712 18:15:12.419974 139931247974272 model_lib_v2.py:700] Step 3000 per-step time 0.972s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.06937073,\n",
            " 'Loss/localization_loss': 0.011803622,\n",
            " 'Loss/regularization_loss': 0.21182053,\n",
            " 'Loss/total_loss': 0.2929949,\n",
            " 'learning_rate': 0.019999998}\n",
            "I0712 18:15:12.420260 139931247974272 model_lib_v2.py:701] {'Loss/classification_loss': 0.06937073,\n",
            " 'Loss/localization_loss': 0.011803622,\n",
            " 'Loss/regularization_loss': 0.21182053,\n",
            " 'Loss/total_loss': 0.2929949,\n",
            " 'learning_rate': 0.019999998}\n",
            "INFO:tensorflow:Step 3100 per-step time 0.982s\n",
            "I0712 18:16:50.663615 139931247974272 model_lib_v2.py:700] Step 3100 per-step time 0.982s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.067772776,\n",
            " 'Loss/localization_loss': 0.020015867,\n",
            " 'Loss/regularization_loss': 0.20897871,\n",
            " 'Loss/total_loss': 0.29676735,\n",
            " 'learning_rate': 0.01687131}\n",
            "I0712 18:16:50.663896 139931247974272 model_lib_v2.py:701] {'Loss/classification_loss': 0.067772776,\n",
            " 'Loss/localization_loss': 0.020015867,\n",
            " 'Loss/regularization_loss': 0.20897871,\n",
            " 'Loss/total_loss': 0.29676735,\n",
            " 'learning_rate': 0.01687131}\n",
            "INFO:tensorflow:Step 3200 per-step time 0.970s\n",
            "I0712 18:18:27.690794 139931247974272 model_lib_v2.py:700] Step 3200 per-step time 0.970s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.028611876,\n",
            " 'Loss/localization_loss': 0.0041381163,\n",
            " 'Loss/regularization_loss': 0.20659582,\n",
            " 'Loss/total_loss': 0.23934582,\n",
            " 'learning_rate': 0.013819658}\n",
            "I0712 18:18:27.691104 139931247974272 model_lib_v2.py:701] {'Loss/classification_loss': 0.028611876,\n",
            " 'Loss/localization_loss': 0.0041381163,\n",
            " 'Loss/regularization_loss': 0.20659582,\n",
            " 'Loss/total_loss': 0.23934582,\n",
            " 'learning_rate': 0.013819658}\n",
            "INFO:tensorflow:Step 3300 per-step time 0.970s\n",
            "I0712 18:20:04.671751 139931247974272 model_lib_v2.py:700] Step 3300 per-step time 0.970s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.043447033,\n",
            " 'Loss/localization_loss': 0.010083333,\n",
            " 'Loss/regularization_loss': 0.20466429,\n",
            " 'Loss/total_loss': 0.25819466,\n",
            " 'learning_rate': 0.010920188}\n",
            "I0712 18:20:04.672072 139931247974272 model_lib_v2.py:701] {'Loss/classification_loss': 0.043447033,\n",
            " 'Loss/localization_loss': 0.010083333,\n",
            " 'Loss/regularization_loss': 0.20466429,\n",
            " 'Loss/total_loss': 0.25819466,\n",
            " 'learning_rate': 0.010920188}\n",
            "INFO:tensorflow:Step 3400 per-step time 0.970s\n",
            "I0712 18:21:41.679119 139931247974272 model_lib_v2.py:700] Step 3400 per-step time 0.970s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.034842607,\n",
            " 'Loss/localization_loss': 0.009437109,\n",
            " 'Loss/regularization_loss': 0.2031501,\n",
            " 'Loss/total_loss': 0.24742982,\n",
            " 'learning_rate': 0.008244291}\n",
            "I0712 18:21:41.679406 139931247974272 model_lib_v2.py:701] {'Loss/classification_loss': 0.034842607,\n",
            " 'Loss/localization_loss': 0.009437109,\n",
            " 'Loss/regularization_loss': 0.2031501,\n",
            " 'Loss/total_loss': 0.24742982,\n",
            " 'learning_rate': 0.008244291}\n",
            "INFO:tensorflow:Step 3500 per-step time 0.973s\n",
            "I0712 18:23:18.961232 139931247974272 model_lib_v2.py:700] Step 3500 per-step time 0.973s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.034601845,\n",
            " 'Loss/localization_loss': 0.0038385878,\n",
            " 'Loss/regularization_loss': 0.2020198,\n",
            " 'Loss/total_loss': 0.24046023,\n",
            " 'learning_rate': 0.0058578644}\n",
            "I0712 18:23:18.961582 139931247974272 model_lib_v2.py:701] {'Loss/classification_loss': 0.034601845,\n",
            " 'Loss/localization_loss': 0.0038385878,\n",
            " 'Loss/regularization_loss': 0.2020198,\n",
            " 'Loss/total_loss': 0.24046023,\n",
            " 'learning_rate': 0.0058578644}\n",
            "INFO:tensorflow:Step 3600 per-step time 0.968s\n",
            "I0712 18:24:55.792040 139931247974272 model_lib_v2.py:700] Step 3600 per-step time 0.968s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.029480942,\n",
            " 'Loss/localization_loss': 0.0052576275,\n",
            " 'Loss/regularization_loss': 0.20124288,\n",
            " 'Loss/total_loss': 0.23598145,\n",
            " 'learning_rate': 0.0038196587}\n",
            "I0712 18:24:55.792314 139931247974272 model_lib_v2.py:701] {'Loss/classification_loss': 0.029480942,\n",
            " 'Loss/localization_loss': 0.0052576275,\n",
            " 'Loss/regularization_loss': 0.20124288,\n",
            " 'Loss/total_loss': 0.23598145,\n",
            " 'learning_rate': 0.0038196587}\n",
            "INFO:tensorflow:Step 3700 per-step time 0.969s\n",
            "I0712 18:26:32.709900 139931247974272 model_lib_v2.py:700] Step 3700 per-step time 0.969s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.03349359,\n",
            " 'Loss/localization_loss': 0.006881074,\n",
            " 'Loss/regularization_loss': 0.20075226,\n",
            " 'Loss/total_loss': 0.24112692,\n",
            " 'learning_rate': 0.0021798706}\n",
            "I0712 18:26:32.710190 139931247974272 model_lib_v2.py:701] {'Loss/classification_loss': 0.03349359,\n",
            " 'Loss/localization_loss': 0.006881074,\n",
            " 'Loss/regularization_loss': 0.20075226,\n",
            " 'Loss/total_loss': 0.24112692,\n",
            " 'learning_rate': 0.0021798706}\n",
            "INFO:tensorflow:Step 3800 per-step time 0.970s\n",
            "I0712 18:28:09.703153 139931247974272 model_lib_v2.py:700] Step 3800 per-step time 0.970s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.04683536,\n",
            " 'Loss/localization_loss': 0.012865003,\n",
            " 'Loss/regularization_loss': 0.20049094,\n",
            " 'Loss/total_loss': 0.2601913,\n",
            " 'learning_rate': 0.0009788703}\n",
            "I0712 18:28:09.703473 139931247974272 model_lib_v2.py:701] {'Loss/classification_loss': 0.04683536,\n",
            " 'Loss/localization_loss': 0.012865003,\n",
            " 'Loss/regularization_loss': 0.20049094,\n",
            " 'Loss/total_loss': 0.2601913,\n",
            " 'learning_rate': 0.0009788703}\n",
            "INFO:tensorflow:Step 3900 per-step time 0.969s\n",
            "I0712 18:29:46.640215 139931247974272 model_lib_v2.py:700] Step 3900 per-step time 0.969s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.0342312,\n",
            " 'Loss/localization_loss': 0.0051693735,\n",
            " 'Loss/regularization_loss': 0.20038795,\n",
            " 'Loss/total_loss': 0.23978853,\n",
            " 'learning_rate': 0.00024623275}\n",
            "I0712 18:29:46.640533 139931247974272 model_lib_v2.py:701] {'Loss/classification_loss': 0.0342312,\n",
            " 'Loss/localization_loss': 0.0051693735,\n",
            " 'Loss/regularization_loss': 0.20038795,\n",
            " 'Loss/total_loss': 0.23978853,\n",
            " 'learning_rate': 0.00024623275}\n",
            "INFO:tensorflow:Step 4000 per-step time 0.972s\n",
            "I0712 18:31:23.831473 139931247974272 model_lib_v2.py:700] Step 4000 per-step time 0.972s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.024708703,\n",
            " 'Loss/localization_loss': 0.0029747523,\n",
            " 'Loss/regularization_loss': 0.20037012,\n",
            " 'Loss/total_loss': 0.22805357,\n",
            " 'learning_rate': 0.0}\n",
            "I0712 18:31:23.831757 139931247974272 model_lib_v2.py:701] {'Loss/classification_loss': 0.024708703,\n",
            " 'Loss/localization_loss': 0.0029747523,\n",
            " 'Loss/regularization_loss': 0.20037012,\n",
            " 'Loss/total_loss': 0.22805357,\n",
            " 'learning_rate': 0.0}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "EYmIuo9Nd3F3",
        "outputId": "ecf6c695-266a-4457-c0d5-1ec2fa2e38e6"
      },
      "source": [
        "pwd"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/training'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9vpOWvMvch92",
        "outputId": "984c776c-fdbe-41c0-d08b-2e5a7d83f94e"
      },
      "source": [
        "!python exporter_main_v2.py --input_type image_tensor --pipeline_config_path /content/training/models/my_ssd_resnet101_v1_fpn/pipeline.config --trained_checkpoint_dir /content/training/models/my_ssd_resnet101_v1_fpn --output_directory /content/training/exported_models/my_model"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-07-12 18:35:09.093198: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-07-12 18:35:11.271568: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "2021-07-12 18:35:11.272548: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
            "2021-07-12 18:35:11.294331: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-12 18:35:11.294921: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\n",
            "coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n",
            "2021-07-12 18:35:11.294951: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-07-12 18:35:11.300014: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
            "2021-07-12 18:35:11.300077: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
            "2021-07-12 18:35:11.302139: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
            "2021-07-12 18:35:11.302484: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
            "2021-07-12 18:35:11.304624: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-07-12 18:35:11.310235: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
            "2021-07-12 18:35:11.310428: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
            "2021-07-12 18:35:11.310537: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-12 18:35:11.311091: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-12 18:35:11.311615: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
            "2021-07-12 18:35:11.311900: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2021-07-12 18:35:11.312069: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "2021-07-12 18:35:11.312168: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-12 18:35:11.312705: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\n",
            "coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n",
            "2021-07-12 18:35:11.312729: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-07-12 18:35:11.312749: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
            "2021-07-12 18:35:11.312763: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
            "2021-07-12 18:35:11.312780: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
            "2021-07-12 18:35:11.312801: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
            "2021-07-12 18:35:11.312825: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-07-12 18:35:11.312839: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
            "2021-07-12 18:35:11.312852: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
            "2021-07-12 18:35:11.312904: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-12 18:35:11.313450: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-12 18:35:11.313957: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
            "2021-07-12 18:35:11.314028: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-07-12 18:35:11.864959: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-07-12 18:35:11.865012: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
            "2021-07-12 18:35:11.865020: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
            "2021-07-12 18:35:11.865211: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-12 18:35:11.865851: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-12 18:35:11.866395: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-12 18:35:11.866913: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2021-07-12 18:35:11.866954: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14957 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "WARNING:tensorflow:AutoGraph could not transform <bound method DetectionInferenceModule._preprocess_input of <object_detection.exporter_lib_v2.DetectionFromImageModule object at 0x7f74e0380ad0>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "W0712 18:35:11.953650 140142163011456 ag_logging.py:146] AutoGraph could not transform <bound method DetectionInferenceModule._preprocess_input of <object_detection.exporter_lib_v2.DetectionFromImageModule object at 0x7f74e0380ad0>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/exporter_lib_v2.py:111: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
            "Instead of:\n",
            "results = tf.map_fn(fn, elems, back_prop=False)\n",
            "Use:\n",
            "results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n",
            "W0712 18:35:11.953988 140142163011456 deprecation.py:604] From /usr/local/lib/python3.7/dist-packages/object_detection/exporter_lib_v2.py:111: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
            "Instead of:\n",
            "results = tf.map_fn(fn, elems, back_prop=False)\n",
            "Use:\n",
            "results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n",
            "WARNING:tensorflow:AutoGraph could not transform <function DetectionInferenceModule._preprocess_input.<locals>._decode_and_preprocess at 0x7f74e03f93b0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "W0712 18:35:11.972956 140142163011456 ag_logging.py:146] AutoGraph could not transform <function DetectionInferenceModule._preprocess_input.<locals>._decode_and_preprocess at 0x7f74e03f93b0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <bound method DetectionInferenceModule._run_inference_on_images of <object_detection.exporter_lib_v2.DetectionFromImageModule object at 0x7f74e0380ad0>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "W0712 18:35:12.009789 140142163011456 ag_logging.py:146] AutoGraph could not transform <bound method DetectionInferenceModule._run_inference_on_images of <object_detection.exporter_lib_v2.DetectionFromImageModule object at 0x7f74e0380ad0>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <bound method SSDResNetV1FpnKerasFeatureExtractor._extract_features of <object_detection.models.ssd_resnet_v1_fpn_keras_feature_extractor.SSDResNet101V1FpnKerasFeatureExtractor object at 0x7f74ed8cef10>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "W0712 18:35:15.929299 140142163011456 ag_logging.py:146] AutoGraph could not transform <bound method SSDResNetV1FpnKerasFeatureExtractor._extract_features of <object_detection.models.ssd_resnet_v1_fpn_keras_feature_extractor.SSDResNet101V1FpnKerasFeatureExtractor object at 0x7f74ed8cef10>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <bound method KerasFpnTopDownFeatureMaps.call of <object_detection.models.feature_map_generators.KerasFpnTopDownFeatureMaps object at 0x7f74a011e390>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "W0712 18:35:16.625321 140142163011456 ag_logging.py:146] AutoGraph could not transform <bound method KerasFpnTopDownFeatureMaps.call of <object_detection.models.feature_map_generators.KerasFpnTopDownFeatureMaps object at 0x7f74a011e390>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <bound method WeightSharedConvolutionalBoxPredictor._predict of <object_detection.predictors.convolutional_keras_box_predictor.WeightSharedConvolutionalBoxPredictor object at 0x7f74ee354b90>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "W0712 18:35:17.423409 140142163011456 ag_logging.py:146] AutoGraph could not transform <bound method WeightSharedConvolutionalBoxPredictor._predict of <object_detection.predictors.convolutional_keras_box_predictor.WeightSharedConvolutionalBoxPredictor object at 0x7f74ee354b90>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <bound method WeightSharedConvolutionalBoxHead._predict of <object_detection.predictors.heads.keras_box_head.WeightSharedConvolutionalBoxHead object at 0x7f74eeb85050>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "W0712 18:35:17.505753 140142163011456 ag_logging.py:146] AutoGraph could not transform <bound method WeightSharedConvolutionalBoxHead._predict of <object_detection.predictors.heads.keras_box_head.WeightSharedConvolutionalBoxHead object at 0x7f74eeb85050>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <bound method WeightSharedConvolutionalClassHead._predict of <object_detection.predictors.heads.keras_class_head.WeightSharedConvolutionalClassHead object at 0x7f74efddeb50>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "W0712 18:35:17.577770 140142163011456 ag_logging.py:146] AutoGraph could not transform <bound method WeightSharedConvolutionalClassHead._predict of <object_detection.predictors.heads.keras_class_head.WeightSharedConvolutionalClassHead object at 0x7f74efddeb50>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function DetectionInferenceModule._preprocess_input.<locals>._decode_and_preprocess at 0x7f7479d3e050> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "W0712 18:35:18.688716 140142163011456 ag_logging.py:146] AutoGraph could not transform <function DetectionInferenceModule._preprocess_input.<locals>._decode_and_preprocess at 0x7f7479d3e050> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7f74e04bbe90>, because it is not built.\n",
            "W0712 18:35:21.987692 140142163011456 save_impl.py:78] Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7f74e04bbe90>, because it is not built.\n",
            "2021-07-12 18:35:41.585001: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
            "WARNING:tensorflow:AutoGraph could not transform <function DetectionInferenceModule._preprocess_input.<locals>._decode_and_preprocess at 0x7f7472f27a70> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "W0712 18:35:41.852159 140142163011456 ag_logging.py:146] AutoGraph could not transform <function DetectionInferenceModule._preprocess_input.<locals>._decode_and_preprocess at 0x7f7472f27a70> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471ad3b10>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471ad3b90>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471adb310>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], False), {}).\n",
            "I0712 18:35:54.933903 140142163011456 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471ad3b10>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471ad3b90>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471adb310>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], False), {}).\n",
            "INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471b3d1d0>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471b3d110>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471b3ab50>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], True), {}).\n",
            "I0712 18:35:54.934222 140142163011456 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471b3d1d0>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471b3d110>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471b3ab50>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], True), {}).\n",
            "INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471aa5f90>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471aa84d0>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471aa8710>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], False), {}).\n",
            "I0712 18:35:54.934453 140142163011456 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471aa5f90>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471aa84d0>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471aa8710>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], False), {}).\n",
            "INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471a93850>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471a93dd0>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471a93fd0>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], True), {}).\n",
            "I0712 18:35:54.934650 140142163011456 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471a93850>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471a93dd0>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471a93fd0>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], True), {}).\n",
            "INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471aa5f90>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471aa84d0>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471aa8710>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], False), {}).\n",
            "I0712 18:36:05.668483 140142163011456 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471aa5f90>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471aa84d0>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471aa8710>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], False), {}).\n",
            "INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471a93850>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471a93dd0>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471a93fd0>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], True), {}).\n",
            "I0712 18:36:05.668771 140142163011456 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471a93850>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471a93dd0>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471a93fd0>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], True), {}).\n",
            "INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471ad3b10>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471ad3b90>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471adb310>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], False), {}).\n",
            "I0712 18:36:05.668979 140142163011456 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471ad3b10>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471ad3b90>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471adb310>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], False), {}).\n",
            "INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471b3d1d0>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471b3d110>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471b3ab50>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], True), {}).\n",
            "I0712 18:36:05.669150 140142163011456 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471b3d1d0>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471b3d110>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471b3ab50>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], True), {}).\n",
            "INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471ad3b10>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471ad3b90>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471adb310>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], False), {}).\n",
            "I0712 18:36:05.669335 140142163011456 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471ad3b10>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471ad3b90>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471adb310>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], False), {}).\n",
            "INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471b3d1d0>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471b3d110>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471b3ab50>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], True), {}).\n",
            "I0712 18:36:05.669517 140142163011456 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471b3d1d0>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471b3d110>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471b3ab50>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], True), {}).\n",
            "W0712 18:36:11.141929 140142163011456 save.py:241] Found untraced functions such as WeightSharedConvolutionalBoxPredictor_layer_call_and_return_conditional_losses, WeightSharedConvolutionalBoxPredictor_layer_call_fn, WeightSharedConvolutionalBoxHead_layer_call_and_return_conditional_losses, WeightSharedConvolutionalBoxHead_layer_call_fn, WeightSharedConvolutionalBoxPredictor_layer_call_fn while saving (showing 5 of 315). These functions will not be directly callable after loading.\n",
            "INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471ad3b10>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471ad3b90>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471adb310>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], False), {}).\n",
            "I0712 18:36:11.532845 140142163011456 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471ad3b10>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471ad3b90>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471adb310>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], False), {}).\n",
            "INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471b3d1d0>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471b3d110>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471b3ab50>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], True), {}).\n",
            "I0712 18:36:11.533141 140142163011456 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471b3d1d0>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471b3d110>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471b3ab50>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], True), {}).\n",
            "INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471aa5f90>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471aa84d0>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471aa8710>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], False), {}).\n",
            "I0712 18:36:11.533305 140142163011456 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471aa5f90>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471aa84d0>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471aa8710>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], False), {}).\n",
            "INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471a93850>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471a93dd0>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471a93fd0>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], True), {}).\n",
            "I0712 18:36:11.533436 140142163011456 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471a93850>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471a93dd0>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471a93fd0>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], True), {}).\n",
            "INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471aa5f90>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471aa84d0>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471aa8710>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], False), {}).\n",
            "I0712 18:36:12.108216 140142163011456 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471aa5f90>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471aa84d0>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471aa8710>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], False), {}).\n",
            "INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471a93850>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471a93dd0>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471a93fd0>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], True), {}).\n",
            "I0712 18:36:12.108546 140142163011456 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471a93850>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471a93dd0>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471a93fd0>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], True), {}).\n",
            "INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471ad3b10>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471ad3b90>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471adb310>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], False), {}).\n",
            "I0712 18:36:12.108713 140142163011456 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471ad3b10>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471ad3b90>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471adb310>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], False), {}).\n",
            "INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471b3d1d0>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471b3d110>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471b3ab50>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], True), {}).\n",
            "I0712 18:36:12.108834 140142163011456 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471b3d1d0>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471b3d110>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471b3ab50>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], True), {}).\n",
            "INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471ad3b10>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471ad3b90>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471adb310>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], False), {}).\n",
            "I0712 18:36:12.108958 140142163011456 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471ad3b10>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471ad3b90>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471adb310>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], False), {}).\n",
            "INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471b3d1d0>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471b3d110>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471b3ab50>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], True), {}).\n",
            "I0712 18:36:12.109065 140142163011456 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471b3d1d0>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471b3d110>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471b3ab50>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], True), {}).\n",
            "W0712 18:36:13.131189 140142163011456 save.py:241] Found untraced functions such as WeightSharedConvolutionalBoxPredictor_layer_call_and_return_conditional_losses, WeightSharedConvolutionalBoxPredictor_layer_call_fn, WeightSharedConvolutionalBoxHead_layer_call_and_return_conditional_losses, WeightSharedConvolutionalBoxHead_layer_call_fn, WeightSharedConvolutionalBoxPredictor_layer_call_fn while saving (showing 5 of 315). These functions will not be directly callable after loading.\n",
            "INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471ad3b10>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471ad3b90>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471adb310>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], False), {}).\n",
            "I0712 18:36:19.921688 140142163011456 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471ad3b10>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471ad3b90>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471adb310>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], False), {}).\n",
            "INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471b3d1d0>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471b3d110>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471b3ab50>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], True), {}).\n",
            "I0712 18:36:19.922004 140142163011456 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471b3d1d0>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471b3d110>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471b3ab50>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], True), {}).\n",
            "INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471aa5f90>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471aa84d0>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471aa8710>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], False), {}).\n",
            "I0712 18:36:19.922367 140142163011456 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471aa5f90>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471aa84d0>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471aa8710>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], False), {}).\n",
            "INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471a93850>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471a93dd0>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471a93fd0>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], True), {}).\n",
            "I0712 18:36:19.922553 140142163011456 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471a93850>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471a93dd0>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f7471a93fd0>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], True), {}).\n",
            "INFO:tensorflow:Assets written to: /content/training/exported_models/my_model/saved_model/assets\n",
            "I0712 18:36:21.832226 140142163011456 builder_impl.py:775] Assets written to: /content/training/exported_models/my_model/saved_model/assets\n",
            "INFO:tensorflow:Writing pipeline config file to /content/training/exported_models/my_model/pipeline.config\n",
            "I0712 18:36:22.998118 140142163011456 config_util.py:254] Writing pipeline config file to /content/training/exported_models/my_model/pipeline.config\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "PufE9qWLciAP",
        "outputId": "69b6d671-2d7f-4572-96fb-e80191f42339"
      },
      "source": [
        "\"\"\"\n",
        "Object Detection (On Image) From TF2 Saved Model\n",
        "=====================================\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'    # Suppress TensorFlow logging (1)\n",
        "import pathlib\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import argparse\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Enable GPU dynamic memory allocation\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "for gpu in gpus:\n",
        "    tf.config.experimental.set_memory_growth(gpu, True)\n",
        "\n",
        "# PROVIDE PATH TO IMAGE DIRECTORY\n",
        "IMAGE_PATHS = '/content/training/images/train/img78.jpg'\n",
        "\n",
        "\n",
        "# PROVIDE PATH TO MODEL DIRECTORY\n",
        "PATH_TO_MODEL_DIR = '/content/training/exported_models/my_model'\n",
        "\n",
        "# PROVIDE PATH TO LABEL MAP\n",
        "PATH_TO_LABELS = '/content/training/annotations/label_map.pbtxt'\n",
        "\n",
        "# PROVIDE THE MINIMUM CONFIDENCE THRESHOLD\n",
        "MIN_CONF_THRESH = float(0.60)\n",
        "\n",
        "# LOAD THE MODEL\n",
        "\n",
        "import time\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "\n",
        "PATH_TO_SAVED_MODEL = PATH_TO_MODEL_DIR + \"/saved_model\"\n",
        "\n",
        "print('Loading model...', end='')\n",
        "start_time = time.time()\n",
        "\n",
        "# LOAD SAVED MODEL AND BUILD DETECTION FUNCTION\n",
        "detect_fn = tf.saved_model.load(PATH_TO_SAVED_MODEL)\n",
        "\n",
        "end_time = time.time()\n",
        "elapsed_time = end_time - start_time\n",
        "print('Done! Took {} seconds'.format(elapsed_time))\n",
        "\n",
        "# LOAD LABEL MAP DATA FOR PLOTTING\n",
        "\n",
        "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS,\n",
        "                                                                    use_display_name=True)\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')   # Suppress Matplotlib warnings\n",
        "\n",
        "def load_image_into_numpy_array(path):\n",
        "    \"\"\"Load an image from file into a numpy array.\n",
        "    Puts image into numpy array to feed into tensorflow graph.\n",
        "    Note that by convention we put it into a numpy array with shape\n",
        "    (height, width, channels), where channels=3 for RGB.\n",
        "    Args:\n",
        "      path: the file path to the image\n",
        "    Returns:\n",
        "      uint8 numpy array with shape (img_height, img_width, 3)\n",
        "    \"\"\"\n",
        "    return np.array(Image.open(path))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print('Running inference for {}... '.format(IMAGE_PATHS), end='')\n",
        "\n",
        "image = cv2.imread(IMAGE_PATHS)\n",
        "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "image_expanded = np.expand_dims(image_rgb, axis=0)\n",
        "\n",
        "# The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n",
        "input_tensor = tf.convert_to_tensor(image)\n",
        "# The model expects a batch of images, so add an axis with `tf.newaxis`.\n",
        "input_tensor = input_tensor[tf.newaxis, ...]\n",
        "\n",
        "# input_tensor = np.expand_dims(image_np, 0)\n",
        "detections = detect_fn(input_tensor)\n",
        "\n",
        "# All outputs are batches tensors.\n",
        "# Convert to numpy arrays, and take index [0] to remove the batch dimension.\n",
        "# We're only interested in the first num_detections.\n",
        "num_detections = int(detections.pop('num_detections'))\n",
        "detections = {key: value[0, :num_detections].numpy()\n",
        "               for key, value in detections.items()}\n",
        "detections['num_detections'] = num_detections\n",
        "\n",
        "# detection_classes should be ints.\n",
        "detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
        "\n",
        "image_with_detections = image.copy()\n",
        "\n",
        "# SET MIN_SCORE_THRESH BASED ON YOU MINIMUM THRESHOLD FOR DETECTIONS\n",
        "viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "      image_with_detections,\n",
        "      detections['detection_boxes'],\n",
        "      detections['detection_classes'],\n",
        "      detections['detection_scores'],\n",
        "      category_index,\n",
        "      use_normalized_coordinates=True,\n",
        "      max_boxes_to_draw=200,\n",
        "      min_score_thresh=0.5,\n",
        "      agnostic_mode=False)\n",
        "\n",
        "print('Done')\n",
        "# DISPLAYS OUTPUT IMAGE\n",
        "cv2_imshow(image_with_detections)\n",
        "# CLOSES WINDOW ONCE KEY IS PRESSED\n"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading model...Done! Took 21.618231534957886 seconds\n",
            "Running inference for /content/training/images/train/img78.jpg... WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7f78456720e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Done\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=300x164 at 0x7F7846085410>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isR3eRTqciDF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMuTH3xEciFX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seeBYxXFciIU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}