{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TF Object Detection_v1.4",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "1Ju-7yAFx9uqWz8rmnPmarMuvrk1XziOb",
      "authorship_tag": "ABX9TyNHW6yuhYiAue3UpZAia/3H",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dc40/F1CarObjectDetector/blob/master/TF_Object_Detection_v1_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HALV-0Tqbkhi",
        "outputId": "1eb0c780-f605-4edc-e2f5-6ae0c20ee3b1"
      },
      "source": [
        "!pip install tensorflow-gpu==2.4.1"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu==2.4.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/cc/a27e73cf8b23f2ce4bdd2b7089a42a7819ce6dd7366dceba406ddc5daa9c/tensorflow_gpu-2.4.1-cp37-cp37m-manylinux2010_x86_64.whl (394.3MB)\n",
            "\u001b[K     |████████████████████████████████| 394.3MB 41kB/s \n",
            "\u001b[?25hRequirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.4.1) (3.3.0)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.4.1) (1.15.0)\n",
            "Collecting gast==0.3.3\n",
            "  Downloading https://files.pythonhosted.org/packages/d6/84/759f5dd23fec8ba71952d97bcc7e2c9d7d63bdc582421f3cd4be845f0c98/gast-0.3.3-py2.py3-none-any.whl\n",
            "Collecting h5py~=2.10.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/c0/abde58b837e066bca19a3f7332d9d0493521d7dd6b48248451a9e3fe2214/h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 60.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.4.1) (1.6.3)\n",
            "Collecting tensorflow-estimator<2.5.0,>=2.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/7e/622d9849abf3afb81e482ffc170758742e392ee129ce1540611199a59237/tensorflow_estimator-2.4.0-py2.py3-none-any.whl (462kB)\n",
            "\u001b[K     |████████████████████████████████| 471kB 66.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.4.1) (1.19.5)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.4.1) (0.36.2)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.4.1) (0.12.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.4.1) (1.1.2)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.4.1) (3.7.4.3)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.4.1) (2.5.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.4.1) (1.12)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.4.1) (1.12.1)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.4.1) (3.17.3)\n",
            "Collecting grpcio~=1.32.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/06/54/1c8be62beafe7fb1548d2968e518ca040556b46b0275399d4f3186c56d79/grpcio-1.32.0-cp37-cp37m-manylinux2014_x86_64.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 63.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.4.1) (1.1.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.4.1) (0.2.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow-gpu==2.4.1) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow-gpu==2.4.1) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow-gpu==2.4.1) (1.8.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow-gpu==2.4.1) (3.3.4)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow-gpu==2.4.1) (57.0.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow-gpu==2.4.1) (1.32.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow-gpu==2.4.1) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow-gpu==2.4.1) (0.4.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow-gpu==2.4.1) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow-gpu==2.4.1) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow-gpu==2.4.1) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow-gpu==2.4.1) (3.0.4)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow-gpu==2.4.1) (4.6.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow-gpu==2.4.1) (4.2.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow-gpu==2.4.1) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow-gpu==2.4.1) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow-gpu==2.4.1) (1.3.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow-gpu==2.4.1) (3.4.1)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow-gpu==2.4.1) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow-gpu==2.4.1) (3.1.1)\n",
            "\u001b[31mERROR: tensorflow 2.5.0 has requirement gast==0.4.0, but you'll have gast 0.3.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.5.0 has requirement grpcio~=1.34.0, but you'll have grpcio 1.32.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.5.0 has requirement h5py~=3.1.0, but you'll have h5py 2.10.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.5.0 has requirement tensorflow-estimator<2.6.0,>=2.5.0rc0, but you'll have tensorflow-estimator 2.4.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: gast, h5py, tensorflow-estimator, grpcio, tensorflow-gpu\n",
            "  Found existing installation: gast 0.4.0\n",
            "    Uninstalling gast-0.4.0:\n",
            "      Successfully uninstalled gast-0.4.0\n",
            "  Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "  Found existing installation: tensorflow-estimator 2.5.0\n",
            "    Uninstalling tensorflow-estimator-2.5.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.5.0\n",
            "  Found existing installation: grpcio 1.34.1\n",
            "    Uninstalling grpcio-1.34.1:\n",
            "      Successfully uninstalled grpcio-1.34.1\n",
            "Successfully installed gast-0.3.3 grpcio-1.32.0 h5py-2.10.0 tensorflow-estimator-2.4.0 tensorflow-gpu-2.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHvbssR6chQl",
        "outputId": "de9e71a0-06aa-4d1f-a39e-140c094da368"
      },
      "source": [
        "!git clone https://github.com/tensorflow/models.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'models'...\n",
            "remote: Enumerating objects: 58658, done.\u001b[K\n",
            "remote: Counting objects: 100% (384/384), done.\u001b[K\n",
            "remote: Compressing objects: 100% (163/163), done.\u001b[K\n",
            "remote: Total 58658 (delta 233), reused 359 (delta 219), pack-reused 58274\u001b[K\n",
            "Receiving objects: 100% (58658/58658), 573.39 MiB | 31.25 MiB/s, done.\n",
            "Resolving deltas: 100% (40706/40706), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "s_notlotchay",
        "outputId": "729ca508-f635-47fe-a17b-82806a64e0d5"
      },
      "source": [
        "pwd"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mn2aAJo4chdS",
        "outputId": "63c16b7f-ac02-4f30-96ad-f9fd9afaf180"
      },
      "source": [
        "cd /content/models/research"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "sryJz2cichfp",
        "outputId": "503bb4e6-9c67-4d7f-e366-08f833d65c68"
      },
      "source": [
        "pwd"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/models/research'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2azurHIschhy"
      },
      "source": [
        "!protoc object_detection/protos/*.proto --python_out=."
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "faYosET4chkB",
        "outputId": "0b647937-f364-4a67-d18a-0bd385680a53"
      },
      "source": [
        "!git clone https://github.com/cocodataset/cocoapi.git"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'cocoapi'...\n",
            "remote: Enumerating objects: 975, done.\u001b[K\n",
            "remote: Total 975 (delta 0), reused 0 (delta 0), pack-reused 975\u001b[K\n",
            "Receiving objects: 100% (975/975), 11.72 MiB | 30.32 MiB/s, done.\n",
            "Resolving deltas: 100% (576/576), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "umhNMRufchmS",
        "outputId": "47147583-ae66-4e07-a146-95c46505f3bd"
      },
      "source": [
        "cd cocoapi/PythonAPI"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research/cocoapi/PythonAPI\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bir5TbNYchoU",
        "outputId": "a48ab50c-ca30-48e4-e144-d39b6cefced7"
      },
      "source": [
        "!make"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "python setup.py build_ext --inplace\n",
            "running build_ext\n",
            "cythoning pycocotools/_mask.pyx to pycocotools/_mask.c\n",
            "/usr/local/lib/python3.7/dist-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /content/models/research/cocoapi/PythonAPI/pycocotools/_mask.pyx\n",
            "  tree = Parsing.p_module(s, pxd, full_module_name)\n",
            "building 'pycocotools._mask' extension\n",
            "creating build\n",
            "creating build/common\n",
            "creating build/temp.linux-x86_64-3.7\n",
            "creating build/temp.linux-x86_64-3.7/pycocotools\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.7/dist-packages/numpy/core/include -I../common -I/usr/include/python3.7m -c ../common/maskApi.c -o build/temp.linux-x86_64-3.7/../common/maskApi.o -Wno-cpp -Wno-unused-function -std=c99\n",
            "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleDecode\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K../common/maskApi.c:46:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "       \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K( k=0; k<R[i].cnts[j]; k++ ) *(M++)=v; v=!v; }}\n",
            "       \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:46:49:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’\n",
            "       for( k=0; k<R[i].cnts[j]; k++ ) *(M++)=v; \u001b[01;36m\u001b[Kv\u001b[m\u001b[K=!v; }}\n",
            "                                                 \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleFrPoly\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K../common/maskApi.c:166:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "   \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K(j=0; j<k; j++) x[j]=(int)(scale*xy[j*2+0]+.5); x[k]=x[0];\n",
            "   \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:166:54:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’\n",
            "   for(j=0; j<k; j++) x[j]=(int)(scale*xy[j*2+0]+.5); \u001b[01;36m\u001b[Kx\u001b[m\u001b[K[k]=x[0];\n",
            "                                                      \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:167:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "   \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K(j=0; j<k; j++) y[j]=(int)(scale*xy[j*2+1]+.5); y[k]=y[0];\n",
            "   \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:167:54:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’\n",
            "   for(j=0; j<k; j++) y[j]=(int)(scale*xy[j*2+1]+.5); \u001b[01;36m\u001b[Ky\u001b[m\u001b[K[k]=y[0];\n",
            "                                                      \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleToString\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K../common/maskApi.c:212:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "       \u001b[01;35m\u001b[Kif\u001b[m\u001b[K(more) c |= 0x20; c+=48; s[p++]=c;\n",
            "       \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:212:27:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’\n",
            "       if(more) c |= 0x20; \u001b[01;36m\u001b[Kc\u001b[m\u001b[K+=48; s[p++]=c;\n",
            "                           \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleFrString\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K../common/maskApi.c:220:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kwhile\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "   \u001b[01;35m\u001b[Kwhile\u001b[m\u001b[K( s[m] ) m++; cnts=malloc(sizeof(uint)*m); m=0;\n",
            "   \u001b[01;35m\u001b[K^~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:220:22:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kwhile\u001b[m\u001b[K’\n",
            "   while( s[m] ) m++; \u001b[01;36m\u001b[Kcnts\u001b[m\u001b[K=malloc(sizeof(uint)*m); m=0;\n",
            "                      \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:228:5:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "     \u001b[01;35m\u001b[Kif\u001b[m\u001b[K(m>2) x+=(long) cnts[m-2]; cnts[m++]=(uint) x;\n",
            "     \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:228:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’\n",
            "     if(m>2) x+=(long) cnts[m-2]; \u001b[01;36m\u001b[Kcnts\u001b[m\u001b[K[m++]=(uint) x;\n",
            "                                  \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleToBbox\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K../common/maskApi.c:141:31:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kxp\u001b[m\u001b[K’ may be used uninitialized in this function [\u001b[01;35m\u001b[K-Wmaybe-uninitialized\u001b[m\u001b[K]\n",
            "       if(j%2==0) xp=x; else if\u001b[01;35m\u001b[K(\u001b[m\u001b[Kxp<x) { ys=0; ye=h-1; }\n",
            "                               \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.7/dist-packages/numpy/core/include -I../common -I/usr/include/python3.7m -c pycocotools/_mask.c -o build/temp.linux-x86_64-3.7/pycocotools/_mask.o -Wno-cpp -Wno-unused-function -std=c99\n",
            "creating build/lib.linux-x86_64-3.7\n",
            "creating build/lib.linux-x86_64-3.7/pycocotools\n",
            "x86_64-linux-gnu-gcc -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.7/../common/maskApi.o build/temp.linux-x86_64-3.7/pycocotools/_mask.o -o build/lib.linux-x86_64-3.7/pycocotools/_mask.cpython-37m-x86_64-linux-gnu.so\n",
            "copying build/lib.linux-x86_64-3.7/pycocotools/_mask.cpython-37m-x86_64-linux-gnu.so -> pycocotools\n",
            "rm -rf build\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7rq3QE2chs9"
      },
      "source": [
        "cp -r pycocotools /content/models/research"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WqDlptn-chxe",
        "outputId": "c298e913-9433-48ba-ee49-d5cc4984c33b"
      },
      "source": [
        "cd .."
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research/cocoapi\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AjkhcxYkch0J",
        "outputId": "ff2aa1bc-b6bd-4f2d-f597-f8565ba9d5fe"
      },
      "source": [
        "cd .."
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCTjXExach2q"
      },
      "source": [
        "cp object_detection/packages/tf2/setup.py ."
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqwPm5BAch4-",
        "outputId": "3485c57a-5db9-414c-fb24-0c17debc6a47"
      },
      "source": [
        "!python -m pip install ."
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing /content/models/research\n",
            "Collecting avro-python3\n",
            "  Downloading https://files.pythonhosted.org/packages/cc/97/7a6970380ca8db9139a3cc0b0e3e0dd3e4bc584fb3644e1d06e71e1a55f0/avro-python3-1.10.2.tar.gz\n",
            "Collecting apache-beam\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/28/f0/83e04f7a693695f4ce3765fce1e573abbbf32153a309829651de056f8924/apache_beam-2.31.0-cp37-cp37m-manylinux2010_x86_64.whl (9.7MB)\n",
            "\u001b[K     |████████████████████████████████| 9.7MB 11.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (7.1.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (4.2.6)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (3.2.2)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.29.23)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.5.5)\n",
            "Collecting tf-slim\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/97/b0f4a64df018ca018cc035d44f2ef08f91e2e8aa67271f6f19633a015ff7/tf_slim-1.1.0-py2.py3-none-any.whl (352kB)\n",
            "\u001b[K     |████████████████████████████████| 358kB 51.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.15.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.0.2)\n",
            "Collecting lvis\n",
            "  Downloading https://files.pythonhosted.org/packages/72/b6/1992240ab48310b5360bfdd1d53163f43bb97d90dc5dc723c67d41c38e78/lvis-0.5.3-py3-none-any.whl\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.4.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.1.5)\n",
            "Collecting tf-models-official\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/96/08/81bbc275e8e9c6d1e03dd26daec3a67f45e6322804cbce3d51f93eae1961/tf_models_official-2.5.0-py2.py3-none-any.whl (1.6MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6MB 35.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio<2,>=1.29.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.32.0)\n",
            "Requirement already satisfied: httplib2<0.20.0,>=0.8 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (0.17.4)\n",
            "Collecting dill<0.3.2,>=0.3.1.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c7/11/345f3173809cea7f1a193bfbf02403fff250a3360e0e118a1630985e547d/dill-0.3.1.1.tar.gz (151kB)\n",
            "\u001b[K     |████████████████████████████████| 153kB 56.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<1.21.0,>=1.14.3 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.19.5)\n",
            "Requirement already satisfied: oauth2client<5,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (4.1.3)\n",
            "Requirement already satisfied: pyarrow<5.0.0,>=0.15.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (3.0.0)\n",
            "Requirement already satisfied: pytz>=2018.3 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (2018.9)\n",
            "Requirement already satisfied: typing-extensions<3.8.0,>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (3.7.4.3)\n",
            "Requirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.3.0)\n",
            "Collecting future<1.0.0,>=0.18.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/0b/38b06fd9b92dc2b68d58b75f900e97884c45bedd2ff83203d933cf5851c9/future-0.18.2.tar.gz (829kB)\n",
            "\u001b[K     |████████████████████████████████| 829kB 47.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: pymongo<4.0.0,>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (3.11.4)\n",
            "Collecting hdfs<3.0.0,>=2.1.0\n",
            "  Downloading https://files.pythonhosted.org/packages/08/f7/4c3fad73123a24d7394b6f40d1ec9c1cbf2e921cfea1797216ffd0a51fb1/hdfs-2.6.0-py3-none-any.whl\n",
            "Requirement already satisfied: python-dateutil<3,>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (2.8.1)\n",
            "Collecting fastavro<2,>=0.21.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/92/10ee74edb0a39f4a7af1cf271b3ac725c54f5c243c26fa5059cd794d15d7/fastavro-1.4.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3MB 60.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.7)\n",
            "Collecting requests<3.0.0,>=2.24.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/c1/24814557f1d22c56d50280771a17307e6bf87b70727d975fd6b2ce6b014a/requests-2.25.1-py2.py3-none-any.whl (61kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 8.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf<4,>=3.12.2 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (3.17.3)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->object-detection==0.1) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->object-detection==0.1) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->object-detection==0.1) (1.3.1)\n",
            "Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from tf-slim->object-detection==0.1) (0.12.0)\n",
            "Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.7/dist-packages (from pycocotools->object-detection==0.1) (57.0.0)\n",
            "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (4.1.2.30)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (4.0.1)\n",
            "Collecting pyyaml>=5.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7a/a5/393c087efdc78091afa2af9f1378762f9821c9c1d7a22c5753fb5ac5f97a/PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636kB)\n",
            "\u001b[K     |████████████████████████████████| 645kB 60.3MB/s \n",
            "\u001b[?25hCollecting tensorflow-addons\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/66/4b/e893d194e626c24b3df2253066aa418f46a432fdb68250cde14bf9bb0700/tensorflow_addons-0.13.0-cp37-cp37m-manylinux2010_x86_64.whl (679kB)\n",
            "\u001b[K     |████████████████████████████████| 686kB 61.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (0.12.0)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ac/aa/1437691b0c7c83086ebb79ce2da16e00bef024f24fec2a5161c35476f499/sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 60.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow>=2.5.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (2.5.0)\n",
            "Collecting seqeval\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9d/2d/233c79d5b4e5ab1dbf111242299153f3caddddbb691219f363ad55ce783d/seqeval-1.2.2.tar.gz (43kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 8.6MB/s \n",
            "\u001b[?25hCollecting py-cpuinfo>=3.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e6/ba/77120e44cbe9719152415b97d5bfb29f4053ee987d6cb63f55ce7d50fadc/py-cpuinfo-8.0.0.tar.gz (99kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 13.7MB/s \n",
            "\u001b[?25hCollecting sacrebleu\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/57/0c7ca4e31a126189dab99c19951910bd081dea5bbd25f24b77107750eae7/sacrebleu-1.5.1-py3-none-any.whl (54kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 9.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: gin-config in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (0.4.0)\n",
            "Collecting tensorflow-model-optimization>=0.4.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/78/8f/f6969dc64709c5c5e22cfd7057a83adbc927e6855a431b234168222cbf03/tensorflow_model_optimization-0.6.0-py2.py3-none-any.whl (211kB)\n",
            "\u001b[K     |████████████████████████████████| 215kB 64.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (5.4.8)\n",
            "Collecting opencv-python-headless\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/53/48036b28d46c1ed45ec655ae7ef6caab45e4452834d63817fdef64f333a3/opencv_python_headless-4.5.3.56-cp37-cp37m-manylinux2014_x86_64.whl (37.1MB)\n",
            "\u001b[K     |████████████████████████████████| 37.2MB 140kB/s \n",
            "\u001b[?25hRequirement already satisfied: google-cloud-bigquery>=0.31.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (1.21.0)\n",
            "Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (1.5.12)\n",
            "Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (1.12.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.7/dist-packages (from oauth2client<5,>=2.0.1->apache-beam->object-detection==0.1) (0.2.8)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from oauth2client<5,>=2.0.1->apache-beam->object-detection==0.1) (4.7.2)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from oauth2client<5,>=2.0.1->apache-beam->object-detection==0.1) (0.4.8)\n",
            "Requirement already satisfied: docopt in /usr/local/lib/python3.7/dist-packages (from hdfs<3.0.0,>=2.1.0->apache-beam->object-detection==0.1) (0.6.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (3.0.4)\n",
            "Requirement already satisfied: importlib-resources; python_version < \"3.9\" in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (5.2.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (0.1.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (4.41.1)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (2.3)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (21.2.0)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons->tf-models-official->object-detection==0.1) (2.7.1)\n",
            "Collecting h5py~=3.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9d/74/9eae2bedd8201ab464308f42c601a12d79727a1c87f0c867fdefb212c6cf/h5py-3.1.0-cp37-cp37m-manylinux1_x86_64.whl (4.0MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0MB 55.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-nightly~=2.5.0.dev in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (2.5.0.dev2021032900)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (1.6.3)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (1.12.1)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (1.1.2)\n",
            "Requirement already satisfied: tensorboard~=2.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (2.5.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (1.12)\n",
            "Collecting gast==0.4.0\n",
            "  Downloading https://files.pythonhosted.org/packages/b6/48/583c032b79ae5b3daa02225a675aeb673e58d2cb698e78510feceb11958c/gast-0.4.0-py3-none-any.whl\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (0.36.2)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (0.2.0)\n",
            "Collecting tensorflow-estimator<2.6.0,>=2.5.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ec/78/b27f73e923becc6e79e18fe112cf75e3200d1ee35b0dba8fa46181bce56c/tensorflow_estimator-2.5.0-py2.py3-none-any.whl (462kB)\n",
            "\u001b[K     |████████████████████████████████| 471kB 57.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (3.3.0)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval->tf-models-official->object-detection==0.1) (0.22.2.post1)\n",
            "Collecting portalocker==2.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/89/a6/3814b7107e0788040870e8825eebf214d72166adf656ba7d4bf14759a06a/portalocker-2.0.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: google-resumable-media!=0.4.0,<0.5.0dev,>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from google-cloud-bigquery>=0.31.0->tf-models-official->object-detection==0.1) (0.4.1)\n",
            "Requirement already satisfied: google-cloud-core<2.0dev,>=1.0.3 in /usr/local/lib/python3.7/dist-packages (from google-cloud-bigquery>=0.31.0->tf-models-official->object-detection==0.1) (1.0.3)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official->object-detection==0.1) (5.0.2)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (0.0.4)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (3.0.1)\n",
            "Requirement already satisfied: google-auth>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (1.32.1)\n",
            "Requirement already satisfied: google-api-core<2dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (1.26.3)\n",
            "Requirement already satisfied: zipp>=3.1.0; python_version < \"3.10\" in /usr/local/lib/python3.7/dist-packages (from importlib-resources; python_version < \"3.9\"->tensorflow-datasets->tf-models-official->object-detection==0.1) (3.4.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-metadata->tensorflow-datasets->tf-models-official->object-detection==0.1) (1.53.0)\n",
            "Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (1.5.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (3.3.4)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (1.8.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (0.4.4)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official->object-detection==0.1) (1.0.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official->object-detection==0.1) (1.3)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (4.2.2)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (20.9)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (4.6.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (1.3.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (3.1.1)\n",
            "Building wheels for collected packages: object-detection, avro-python3, dill, future, seqeval, py-cpuinfo\n",
            "  Building wheel for object-detection (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for object-detection: filename=object_detection-0.1-cp37-none-any.whl size=1658497 sha256=a20e9717908c18e0c7f0cb2cfbb8276a44e0f4e1071552e2693430abbe687883\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-5_p2vpk2/wheels/94/49/4b/39b051683087a22ef7e80ec52152a27249d1a644ccf4e442ea\n",
            "  Building wheel for avro-python3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for avro-python3: filename=avro_python3-1.10.2-cp37-none-any.whl size=44011 sha256=1e7b42434246656325ad091587a65ad7095328fe2921fac5fca8f0fefe963498\n",
            "  Stored in directory: /root/.cache/pip/wheels/ee/ee/18/c466221ca6900e3efce2f4ea9c329288808679aecdcb2838d3\n",
            "  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dill: filename=dill-0.3.1.1-cp37-none-any.whl size=78545 sha256=a3831552f59c778dd5272aa388d95b8e20f6e1ba8507336c313be713d998c745\n",
            "  Stored in directory: /root/.cache/pip/wheels/59/b1/91/f02e76c732915c4015ab4010f3015469866c1eb9b14058d8e7\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for future: filename=future-0.18.2-cp37-none-any.whl size=491070 sha256=5525a6b62b9a02dce0318ff08efdbe91c6c1e9eff159c5d72ad7c81e81d13550\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/99/a0/81daf51dcd359a9377b110a8a886b3895921802d2fc1b2397e\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-cp37-none-any.whl size=16184 sha256=69826ad19fcde4f2293b8e09dd636dc5b6dd078817035edead1c9af96bbec31c\n",
            "  Stored in directory: /root/.cache/pip/wheels/52/df/1b/45d75646c37428f7e626214704a0e35bd3cfc32eda37e59e5f\n",
            "  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py-cpuinfo: filename=py_cpuinfo-8.0.0-cp37-none-any.whl size=22258 sha256=aad10b129c6e010de869ca7f53110ac53ebbfb545744732bb20f04d7e4fd1e19\n",
            "  Stored in directory: /root/.cache/pip/wheels/2e/15/f5/aa2a056d223903b52cf4870134e3a01df0c723816835dd08db\n",
            "Successfully built object-detection avro-python3 dill future seqeval py-cpuinfo\n",
            "\u001b[31mERROR: tensorflow 2.5.0 has requirement grpcio~=1.34.0, but you'll have grpcio 1.32.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-gpu 2.4.1 has requirement gast==0.3.3, but you'll have gast 0.4.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-gpu 2.4.1 has requirement h5py~=2.10.0, but you'll have h5py 3.1.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-gpu 2.4.1 has requirement tensorflow-estimator<2.5.0,>=2.4.0, but you'll have tensorflow-estimator 2.5.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: multiprocess 0.70.12.2 has requirement dill>=0.3.4, but you'll have dill 0.3.1.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement requests~=2.23.0, but you'll have requests 2.25.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: apache-beam 2.31.0 has requirement avro-python3!=1.9.2,<1.10.0,>=1.8.1, but you'll have avro-python3 1.10.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: avro-python3, dill, future, requests, hdfs, fastavro, apache-beam, tf-slim, lvis, pyyaml, tensorflow-addons, sentencepiece, seqeval, py-cpuinfo, portalocker, sacrebleu, tensorflow-model-optimization, opencv-python-headless, tf-models-official, object-detection, h5py, gast, tensorflow-estimator\n",
            "  Found existing installation: dill 0.3.4\n",
            "    Uninstalling dill-0.3.4:\n",
            "      Successfully uninstalled dill-0.3.4\n",
            "  Found existing installation: future 0.16.0\n",
            "    Uninstalling future-0.16.0:\n",
            "      Successfully uninstalled future-0.16.0\n",
            "  Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Found existing installation: h5py 2.10.0\n",
            "    Uninstalling h5py-2.10.0:\n",
            "      Successfully uninstalled h5py-2.10.0\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorflow-estimator 2.4.0\n",
            "    Uninstalling tensorflow-estimator-2.4.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.4.0\n",
            "Successfully installed apache-beam-2.31.0 avro-python3-1.10.2 dill-0.3.1.1 fastavro-1.4.2 future-0.18.2 gast-0.4.0 h5py-3.1.0 hdfs-2.6.0 lvis-0.5.3 object-detection-0.1 opencv-python-headless-4.5.3.56 portalocker-2.0.0 py-cpuinfo-8.0.0 pyyaml-5.4.1 requests-2.25.1 sacrebleu-1.5.1 sentencepiece-0.1.96 seqeval-1.2.2 tensorflow-addons-0.13.0 tensorflow-estimator-2.5.0 tensorflow-model-optimization-0.6.0 tf-models-official-2.5.0 tf-slim-1.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7rcc5JIch7U",
        "outputId": "e11aff33-c51b-4b44-9aaf-9aef0f62e659"
      },
      "source": [
        "!python object_detection/builders/model_builder_tf2_test.py"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-07-11 13:58:51.499128: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "Running tests under Python 3.7.10: /usr/bin/python3\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
            "2021-07-11 13:58:53.912180: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "2021-07-11 13:58:53.913002: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
            "2021-07-11 13:58:53.968204: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-11 13:58:53.968819: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\n",
            "coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n",
            "2021-07-11 13:58:53.968855: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-07-11 13:58:54.029566: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
            "2021-07-11 13:58:54.029642: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
            "2021-07-11 13:58:54.143624: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
            "2021-07-11 13:58:54.181682: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
            "2021-07-11 13:58:54.380390: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-07-11 13:58:54.394839: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
            "2021-07-11 13:58:54.399200: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
            "2021-07-11 13:58:54.399341: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-11 13:58:54.399993: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-11 13:58:54.400524: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
            "2021-07-11 13:58:54.400881: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2021-07-11 13:58:54.401031: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "2021-07-11 13:58:54.401175: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-11 13:58:54.401782: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\n",
            "coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n",
            "2021-07-11 13:58:54.401813: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-07-11 13:58:54.401844: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
            "2021-07-11 13:58:54.401862: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
            "2021-07-11 13:58:54.401881: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
            "2021-07-11 13:58:54.401902: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
            "2021-07-11 13:58:54.401929: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-07-11 13:58:54.401953: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
            "2021-07-11 13:58:54.401976: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
            "2021-07-11 13:58:54.402045: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-11 13:58:54.402616: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-11 13:58:54.403112: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
            "2021-07-11 13:58:54.403154: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-07-11 13:58:55.090192: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-07-11 13:58:55.090249: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
            "2021-07-11 13:58:55.090258: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
            "2021-07-11 13:58:55.090472: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-11 13:58:55.091090: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-11 13:58:55.091638: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-11 13:58:55.092135: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2021-07-11 13:58:55.092174: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14957 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "W0711 13:58:55.380081 140649210214272 model_builder.py:1088] Building experimental DeepMAC meta-arch. Some features may be omitted.\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 1.9s\n",
            "I0711 13:58:55.801658 140649210214272 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 1.9s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.56s\n",
            "I0711 13:58:56.363156 140649210214272 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.56s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.36s\n",
            "I0711 13:58:56.722324 140649210214272 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.36s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.32s\n",
            "I0711 13:58:57.044872 140649210214272 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.32s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
            "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
            "W0711 13:58:57.046968 140649210214272 mobilenet_v2.py:286] `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "9412608/9406464 [==============================] - 0s 0us/step\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 0.95s\n",
            "I0711 13:58:57.993890 140649210214272 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 0.95s\n",
            "[  FAILED  ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "I0711 13:58:57.996520 140649210214272 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.03s\n",
            "I0711 13:58:58.023272 140649210214272 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.03s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.02s\n",
            "I0711 13:58:58.042817 140649210214272 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.02s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s\n",
            "I0711 13:58:58.062610 140649210214272 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.13s\n",
            "I0711 13:58:58.196724 140649210214272 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.13s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.13s\n",
            "I0711 13:58:58.329279 140649210214272 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.13s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.14s\n",
            "I0711 13:58:58.467343 140649210214272 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.14s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.14s\n",
            "I0711 13:58:58.604243 140649210214272 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.14s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.14s\n",
            "I0711 13:58:58.745149 140649210214272 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.14s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.04s\n",
            "I0711 13:58:58.785843 140649210214272 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.04s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "I0711 13:58:59.058013 140649210214272 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b0\n",
            "I0711 13:58:59.058174 140649210214272 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 64\n",
            "I0711 13:58:59.058230 140649210214272 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 3\n",
            "I0711 13:58:59.062467 140649210214272 efficientnet_model.py:147] round_filter input=32 output=32\n",
            "I0711 13:58:59.077213 140649210214272 efficientnet_model.py:147] round_filter input=32 output=32\n",
            "I0711 13:58:59.077328 140649210214272 efficientnet_model.py:147] round_filter input=16 output=16\n",
            "I0711 13:58:59.132050 140649210214272 efficientnet_model.py:147] round_filter input=16 output=16\n",
            "I0711 13:58:59.132173 140649210214272 efficientnet_model.py:147] round_filter input=24 output=24\n",
            "I0711 13:58:59.264149 140649210214272 efficientnet_model.py:147] round_filter input=24 output=24\n",
            "I0711 13:58:59.264303 140649210214272 efficientnet_model.py:147] round_filter input=40 output=40\n",
            "I0711 13:58:59.395497 140649210214272 efficientnet_model.py:147] round_filter input=40 output=40\n",
            "I0711 13:58:59.395641 140649210214272 efficientnet_model.py:147] round_filter input=80 output=80\n",
            "I0711 13:58:59.597434 140649210214272 efficientnet_model.py:147] round_filter input=80 output=80\n",
            "I0711 13:58:59.597618 140649210214272 efficientnet_model.py:147] round_filter input=112 output=112\n",
            "I0711 13:58:59.797183 140649210214272 efficientnet_model.py:147] round_filter input=112 output=112\n",
            "I0711 13:58:59.797341 140649210214272 efficientnet_model.py:147] round_filter input=192 output=192\n",
            "I0711 13:59:00.177087 140649210214272 efficientnet_model.py:147] round_filter input=192 output=192\n",
            "I0711 13:59:00.177247 140649210214272 efficientnet_model.py:147] round_filter input=320 output=320\n",
            "I0711 13:59:00.241568 140649210214272 efficientnet_model.py:147] round_filter input=1280 output=1280\n",
            "I0711 13:59:00.267815 140649210214272 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0711 13:59:00.336806 140649210214272 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b1\n",
            "I0711 13:59:00.336946 140649210214272 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 88\n",
            "I0711 13:59:00.336993 140649210214272 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 4\n",
            "I0711 13:59:00.341204 140649210214272 efficientnet_model.py:147] round_filter input=32 output=32\n",
            "I0711 13:59:00.354748 140649210214272 efficientnet_model.py:147] round_filter input=32 output=32\n",
            "I0711 13:59:00.354853 140649210214272 efficientnet_model.py:147] round_filter input=16 output=16\n",
            "I0711 13:59:00.463995 140649210214272 efficientnet_model.py:147] round_filter input=16 output=16\n",
            "I0711 13:59:00.464129 140649210214272 efficientnet_model.py:147] round_filter input=24 output=24\n",
            "I0711 13:59:00.678424 140649210214272 efficientnet_model.py:147] round_filter input=24 output=24\n",
            "I0711 13:59:00.678589 140649210214272 efficientnet_model.py:147] round_filter input=40 output=40\n",
            "I0711 13:59:00.879857 140649210214272 efficientnet_model.py:147] round_filter input=40 output=40\n",
            "I0711 13:59:00.880012 140649210214272 efficientnet_model.py:147] round_filter input=80 output=80\n",
            "I0711 13:59:01.155412 140649210214272 efficientnet_model.py:147] round_filter input=80 output=80\n",
            "I0711 13:59:01.155586 140649210214272 efficientnet_model.py:147] round_filter input=112 output=112\n",
            "I0711 13:59:01.430155 140649210214272 efficientnet_model.py:147] round_filter input=112 output=112\n",
            "I0711 13:59:01.430313 140649210214272 efficientnet_model.py:147] round_filter input=192 output=192\n",
            "I0711 13:59:01.769102 140649210214272 efficientnet_model.py:147] round_filter input=192 output=192\n",
            "I0711 13:59:01.769261 140649210214272 efficientnet_model.py:147] round_filter input=320 output=320\n",
            "I0711 13:59:01.905709 140649210214272 efficientnet_model.py:147] round_filter input=1280 output=1280\n",
            "I0711 13:59:01.931062 140649210214272 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0711 13:59:02.006572 140649210214272 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b2\n",
            "I0711 13:59:02.006735 140649210214272 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 112\n",
            "I0711 13:59:02.006797 140649210214272 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 5\n",
            "I0711 13:59:02.011009 140649210214272 efficientnet_model.py:147] round_filter input=32 output=32\n",
            "I0711 13:59:02.026529 140649210214272 efficientnet_model.py:147] round_filter input=32 output=32\n",
            "I0711 13:59:02.026656 140649210214272 efficientnet_model.py:147] round_filter input=16 output=16\n",
            "I0711 13:59:02.134208 140649210214272 efficientnet_model.py:147] round_filter input=16 output=16\n",
            "I0711 13:59:02.134340 140649210214272 efficientnet_model.py:147] round_filter input=24 output=24\n",
            "I0711 13:59:02.337326 140649210214272 efficientnet_model.py:147] round_filter input=24 output=24\n",
            "I0711 13:59:02.337498 140649210214272 efficientnet_model.py:147] round_filter input=40 output=48\n",
            "I0711 13:59:02.544071 140649210214272 efficientnet_model.py:147] round_filter input=40 output=48\n",
            "I0711 13:59:02.544247 140649210214272 efficientnet_model.py:147] round_filter input=80 output=88\n",
            "I0711 13:59:02.814466 140649210214272 efficientnet_model.py:147] round_filter input=80 output=88\n",
            "I0711 13:59:02.814648 140649210214272 efficientnet_model.py:147] round_filter input=112 output=120\n",
            "I0711 13:59:03.230555 140649210214272 efficientnet_model.py:147] round_filter input=112 output=120\n",
            "I0711 13:59:03.230712 140649210214272 efficientnet_model.py:147] round_filter input=192 output=208\n",
            "I0711 13:59:03.570904 140649210214272 efficientnet_model.py:147] round_filter input=192 output=208\n",
            "I0711 13:59:03.571084 140649210214272 efficientnet_model.py:147] round_filter input=320 output=352\n",
            "I0711 13:59:03.706103 140649210214272 efficientnet_model.py:147] round_filter input=1280 output=1408\n",
            "I0711 13:59:03.732315 140649210214272 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0711 13:59:03.805896 140649210214272 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b3\n",
            "I0711 13:59:03.806069 140649210214272 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 160\n",
            "I0711 13:59:03.806139 140649210214272 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 6\n",
            "I0711 13:59:03.810298 140649210214272 efficientnet_model.py:147] round_filter input=32 output=40\n",
            "I0711 13:59:03.824305 140649210214272 efficientnet_model.py:147] round_filter input=32 output=40\n",
            "I0711 13:59:03.824415 140649210214272 efficientnet_model.py:147] round_filter input=16 output=24\n",
            "I0711 13:59:03.933113 140649210214272 efficientnet_model.py:147] round_filter input=16 output=24\n",
            "I0711 13:59:03.933386 140649210214272 efficientnet_model.py:147] round_filter input=24 output=32\n",
            "I0711 13:59:04.136901 140649210214272 efficientnet_model.py:147] round_filter input=24 output=32\n",
            "I0711 13:59:04.137075 140649210214272 efficientnet_model.py:147] round_filter input=40 output=48\n",
            "I0711 13:59:04.336927 140649210214272 efficientnet_model.py:147] round_filter input=40 output=48\n",
            "I0711 13:59:04.337102 140649210214272 efficientnet_model.py:147] round_filter input=80 output=96\n",
            "I0711 13:59:04.683591 140649210214272 efficientnet_model.py:147] round_filter input=80 output=96\n",
            "I0711 13:59:04.683763 140649210214272 efficientnet_model.py:147] round_filter input=112 output=136\n",
            "I0711 13:59:05.025194 140649210214272 efficientnet_model.py:147] round_filter input=112 output=136\n",
            "I0711 13:59:05.025365 140649210214272 efficientnet_model.py:147] round_filter input=192 output=232\n",
            "I0711 13:59:05.428225 140649210214272 efficientnet_model.py:147] round_filter input=192 output=232\n",
            "I0711 13:59:05.428393 140649210214272 efficientnet_model.py:147] round_filter input=320 output=384\n",
            "I0711 13:59:05.563699 140649210214272 efficientnet_model.py:147] round_filter input=1280 output=1536\n",
            "I0711 13:59:05.587972 140649210214272 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0711 13:59:05.668399 140649210214272 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b4\n",
            "I0711 13:59:05.668567 140649210214272 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 224\n",
            "I0711 13:59:05.668640 140649210214272 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 7\n",
            "I0711 13:59:05.672809 140649210214272 efficientnet_model.py:147] round_filter input=32 output=48\n",
            "I0711 13:59:05.686641 140649210214272 efficientnet_model.py:147] round_filter input=32 output=48\n",
            "I0711 13:59:05.686750 140649210214272 efficientnet_model.py:147] round_filter input=16 output=24\n",
            "I0711 13:59:05.792822 140649210214272 efficientnet_model.py:147] round_filter input=16 output=24\n",
            "I0711 13:59:05.792959 140649210214272 efficientnet_model.py:147] round_filter input=24 output=32\n",
            "I0711 13:59:06.063068 140649210214272 efficientnet_model.py:147] round_filter input=24 output=32\n",
            "I0711 13:59:06.063245 140649210214272 efficientnet_model.py:147] round_filter input=40 output=56\n",
            "I0711 13:59:06.335902 140649210214272 efficientnet_model.py:147] round_filter input=40 output=56\n",
            "I0711 13:59:06.336075 140649210214272 efficientnet_model.py:147] round_filter input=80 output=112\n",
            "I0711 13:59:06.921825 140649210214272 efficientnet_model.py:147] round_filter input=80 output=112\n",
            "I0711 13:59:06.922010 140649210214272 efficientnet_model.py:147] round_filter input=112 output=160\n",
            "I0711 13:59:07.323512 140649210214272 efficientnet_model.py:147] round_filter input=112 output=160\n",
            "I0711 13:59:07.323681 140649210214272 efficientnet_model.py:147] round_filter input=192 output=272\n",
            "I0711 13:59:07.867916 140649210214272 efficientnet_model.py:147] round_filter input=192 output=272\n",
            "I0711 13:59:07.868093 140649210214272 efficientnet_model.py:147] round_filter input=320 output=448\n",
            "I0711 13:59:08.002764 140649210214272 efficientnet_model.py:147] round_filter input=1280 output=1792\n",
            "I0711 13:59:08.026759 140649210214272 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0711 13:59:08.113618 140649210214272 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b5\n",
            "I0711 13:59:08.113763 140649210214272 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 288\n",
            "I0711 13:59:08.113815 140649210214272 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 7\n",
            "I0711 13:59:08.117964 140649210214272 efficientnet_model.py:147] round_filter input=32 output=48\n",
            "I0711 13:59:08.131822 140649210214272 efficientnet_model.py:147] round_filter input=32 output=48\n",
            "I0711 13:59:08.131936 140649210214272 efficientnet_model.py:147] round_filter input=16 output=24\n",
            "I0711 13:59:08.290612 140649210214272 efficientnet_model.py:147] round_filter input=16 output=24\n",
            "I0711 13:59:08.290764 140649210214272 efficientnet_model.py:147] round_filter input=24 output=40\n",
            "I0711 13:59:08.621977 140649210214272 efficientnet_model.py:147] round_filter input=24 output=40\n",
            "I0711 13:59:08.622130 140649210214272 efficientnet_model.py:147] round_filter input=40 output=64\n",
            "I0711 13:59:08.958444 140649210214272 efficientnet_model.py:147] round_filter input=40 output=64\n",
            "I0711 13:59:08.958612 140649210214272 efficientnet_model.py:147] round_filter input=80 output=128\n",
            "I0711 13:59:09.424235 140649210214272 efficientnet_model.py:147] round_filter input=80 output=128\n",
            "I0711 13:59:09.424396 140649210214272 efficientnet_model.py:147] round_filter input=112 output=176\n",
            "I0711 13:59:09.888801 140649210214272 efficientnet_model.py:147] round_filter input=112 output=176\n",
            "I0711 13:59:09.888958 140649210214272 efficientnet_model.py:147] round_filter input=192 output=304\n",
            "I0711 13:59:10.493459 140649210214272 efficientnet_model.py:147] round_filter input=192 output=304\n",
            "I0711 13:59:10.493625 140649210214272 efficientnet_model.py:147] round_filter input=320 output=512\n",
            "I0711 13:59:10.874530 140649210214272 efficientnet_model.py:147] round_filter input=1280 output=2048\n",
            "I0711 13:59:10.903858 140649210214272 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0711 13:59:11.003633 140649210214272 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b6\n",
            "I0711 13:59:11.003776 140649210214272 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 384\n",
            "I0711 13:59:11.003837 140649210214272 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 8\n",
            "I0711 13:59:11.007950 140649210214272 efficientnet_model.py:147] round_filter input=32 output=56\n",
            "I0711 13:59:11.022097 140649210214272 efficientnet_model.py:147] round_filter input=32 output=56\n",
            "I0711 13:59:11.022201 140649210214272 efficientnet_model.py:147] round_filter input=16 output=32\n",
            "I0711 13:59:11.186018 140649210214272 efficientnet_model.py:147] round_filter input=16 output=32\n",
            "I0711 13:59:11.186166 140649210214272 efficientnet_model.py:147] round_filter input=24 output=40\n",
            "I0711 13:59:11.590508 140649210214272 efficientnet_model.py:147] round_filter input=24 output=40\n",
            "I0711 13:59:11.590664 140649210214272 efficientnet_model.py:147] round_filter input=40 output=72\n",
            "I0711 13:59:11.993004 140649210214272 efficientnet_model.py:147] round_filter input=40 output=72\n",
            "I0711 13:59:11.993161 140649210214272 efficientnet_model.py:147] round_filter input=80 output=144\n",
            "I0711 13:59:12.533879 140649210214272 efficientnet_model.py:147] round_filter input=80 output=144\n",
            "I0711 13:59:12.534036 140649210214272 efficientnet_model.py:147] round_filter input=112 output=200\n",
            "I0711 13:59:13.081076 140649210214272 efficientnet_model.py:147] round_filter input=112 output=200\n",
            "I0711 13:59:13.081238 140649210214272 efficientnet_model.py:147] round_filter input=192 output=344\n",
            "I0711 13:59:13.822456 140649210214272 efficientnet_model.py:147] round_filter input=192 output=344\n",
            "I0711 13:59:13.822624 140649210214272 efficientnet_model.py:147] round_filter input=320 output=576\n",
            "I0711 13:59:14.021044 140649210214272 efficientnet_model.py:147] round_filter input=1280 output=2304\n",
            "I0711 13:59:14.045507 140649210214272 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0711 13:59:14.156811 140649210214272 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b7\n",
            "I0711 13:59:14.156960 140649210214272 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 384\n",
            "I0711 13:59:14.157008 140649210214272 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 8\n",
            "I0711 13:59:14.161133 140649210214272 efficientnet_model.py:147] round_filter input=32 output=64\n",
            "I0711 13:59:14.174936 140649210214272 efficientnet_model.py:147] round_filter input=32 output=64\n",
            "I0711 13:59:14.175033 140649210214272 efficientnet_model.py:147] round_filter input=16 output=32\n",
            "I0711 13:59:14.388535 140649210214272 efficientnet_model.py:147] round_filter input=16 output=32\n",
            "I0711 13:59:14.388684 140649210214272 efficientnet_model.py:147] round_filter input=24 output=48\n",
            "I0711 13:59:15.098135 140649210214272 efficientnet_model.py:147] round_filter input=24 output=48\n",
            "I0711 13:59:15.098333 140649210214272 efficientnet_model.py:147] round_filter input=40 output=80\n",
            "I0711 13:59:15.571402 140649210214272 efficientnet_model.py:147] round_filter input=40 output=80\n",
            "I0711 13:59:15.571591 140649210214272 efficientnet_model.py:147] round_filter input=80 output=160\n",
            "I0711 13:59:16.273981 140649210214272 efficientnet_model.py:147] round_filter input=80 output=160\n",
            "I0711 13:59:16.274151 140649210214272 efficientnet_model.py:147] round_filter input=112 output=224\n",
            "I0711 13:59:16.951001 140649210214272 efficientnet_model.py:147] round_filter input=112 output=224\n",
            "I0711 13:59:16.951174 140649210214272 efficientnet_model.py:147] round_filter input=192 output=384\n",
            "I0711 13:59:17.836026 140649210214272 efficientnet_model.py:147] round_filter input=192 output=384\n",
            "I0711 13:59:17.836204 140649210214272 efficientnet_model.py:147] round_filter input=320 output=640\n",
            "I0711 13:59:18.110892 140649210214272 efficientnet_model.py:147] round_filter input=1280 output=2560\n",
            "I0711 13:59:18.144716 140649210214272 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 19.48s\n",
            "I0711 13:59:18.270564 140649210214272 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 19.48s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
            "I0711 13:59:18.276804 140649210214272 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "I0711 13:59:18.278507 140649210214272 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "I0711 13:59:18.279037 140649210214272 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "I0711 13:59:18.280442 140649210214272 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "[ RUN      ] ModelBuilderTF2Test.test_session\n",
            "[  SKIPPED ] ModelBuilderTF2Test.test_session\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "I0711 13:59:18.281796 140649210214272 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "I0711 13:59:18.282207 140649210214272 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "I0711 13:59:18.283157 140649210214272 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "======================================================================\n",
            "ERROR: test_create_center_net_model_mobilenet (__main__.ModelBuilderTF2Test)\n",
            "ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
            "Test building a CenterNet model using bilinear interpolation.\n",
            "----------------------------------------------------------------------\n",
            "Traceback (most recent call last):\n",
            "  File \"object_detection/builders/model_builder_tf2_test.py\", line 497, in test_create_center_net_model_mobilenet\n",
            "    model = model_builder.build(config, is_training=True)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/object_detection/builders/model_builder.py\", line 1227, in build\n",
            "    add_summaries)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/object_detection/builders/model_builder.py\", line 1078, in _build_center_net_model\n",
            "    center_net_config.feature_extractor, is_training)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/object_detection/builders/model_builder.py\", line 1192, in _build_center_net_feature_extractor\n",
            "    **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/object_detection/models/center_net_mobilenet_v2_fpn_feature_extractor.py\", line 156, in mobilenet_v2_fpn\n",
            "    weights='imagenet' if depth_multiplier == 1.0 else None)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/object_detection/models/keras_models/mobilenet_v2.py\", line 333, in mobilenet_v2\n",
            "    **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/applications/mobilenet_v2.py\", line 407, in MobileNetV2\n",
            "    model.load_weights(weights_path)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\", line 2234, in load_weights\n",
            "    hdf5_format.load_weights_from_hdf5_group(f, self.layers)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/saving/hdf5_format.py\", line 662, in load_weights_from_hdf5_group\n",
            "    original_keras_version = f.attrs['keras_version'].decode('utf8')\n",
            "AttributeError: 'str' object has no attribute 'decode'\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "Ran 24 tests in 24.377s\n",
            "\n",
            "FAILED (errors=1, skipped=1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BNLNEuv3d2xf",
        "outputId": "4e734adc-46d9-48bf-d42c-832f66417e9e"
      },
      "source": [
        "cd /content/training_demo/pre-trained-models"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/training_demo/pre-trained-models\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H3hWZ26Yd20B",
        "outputId": "8c3c3a99-de14-4226-f692-ac20a2617f7c"
      },
      "source": [
        "!wget http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_resnet101_v1_fpn_640x640_coco17_tpu-8.tar.gz"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-07-11 14:04:13--  http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_resnet101_v1_fpn_640x640_coco17_tpu-8.tar.gz\n",
            "Resolving download.tensorflow.org (download.tensorflow.org)... 74.125.135.128, 2607:f8b0:400e:c09::80\n",
            "Connecting to download.tensorflow.org (download.tensorflow.org)|74.125.135.128|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 386527459 (369M) [application/x-tar]\n",
            "Saving to: ‘ssd_resnet101_v1_fpn_640x640_coco17_tpu-8.tar.gz.1’\n",
            "\n",
            "ssd_resnet101_v1_fp 100%[===================>] 368.62M   184MB/s    in 2.0s    \n",
            "\n",
            "2021-07-11 14:04:15 (184 MB/s) - ‘ssd_resnet101_v1_fpn_640x640_coco17_tpu-8.tar.gz.1’ saved [386527459/386527459]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3zXdQNOxd22H",
        "outputId": "c9eb2316-f291-4a19-c957-7fd90bcc9159"
      },
      "source": [
        "!tar -xvf ssd_resnet101_v1_fpn_640x640_coco17_tpu-8.tar.gz"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/\n",
            "ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/checkpoint/\n",
            "ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/checkpoint/ckpt-0.data-00000-of-00001\n",
            "ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/checkpoint/checkpoint\n",
            "ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/checkpoint/ckpt-0.index\n",
            "ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/pipeline.config\n",
            "ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/saved_model/\n",
            "ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/saved_model/saved_model.pb\n",
            "ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/saved_model/assets/\n",
            "ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/saved_model/variables/\n",
            "ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/saved_model/variables/variables.data-00000-of-00001\n",
            "ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/saved_model/variables/variables.index\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Kj0oG29md24h",
        "outputId": "28bf1ffd-f05c-4191-d662-942dc39c633b"
      },
      "source": [
        "pwd"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/training_demo/pre-trained-models'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3g9poaYd26k",
        "outputId": "ca1d4f0b-0d17-4c97-ece6-47b55acba710"
      },
      "source": [
        "cd /content/training_demo"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/training_demo\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4RVOp7i7d288",
        "outputId": "b011491b-62c0-40c1-e834-638244ca4971"
      },
      "source": [
        "ls"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mannotations\u001b[0m/         export_tflite_graph_tf2.py  \u001b[01;34mmodels\u001b[0m/\n",
            "\u001b[01;34mexported_models\u001b[0m/     \u001b[01;34mimages\u001b[0m/                     \u001b[01;34mpre-trained-models\u001b[0m/\n",
            "exporter_main_v2.py  model_main_tf2.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xuVybrOGd2_M",
        "outputId": "17b177d8-aa1e-431b-bb4b-ad74586e5a37"
      },
      "source": [
        "# Create train data:\n",
        "!python generate_tfrecord.py -x /content/training_demo/images/train -l /content/training_demo/annotations/label_map.pbtxt -o /content/training_demo/annotations/train.record\n",
        "\n",
        "# Create test data:\n",
        "!python generate_tfrecord.py -x /content/training_demo/images/test -l /content/training_demo/annotations/label_map.pbtxt -o /content/training_demo/annotations/test.record"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Successfully created the TFRecord file: /content/training_demo/annotations/train.record\n",
            "Successfully created the TFRecord file: /content/training_demo/annotations/test.record\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "XgI_HP6jd3BN",
        "outputId": "cbc84c12-4787-4020-81e3-985361ca3af8"
      },
      "source": [
        "pwd"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/training_demo'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JA7gTPphd3Dd",
        "outputId": "c44d1eb7-4513-4d6f-b312-451b2382daad"
      },
      "source": [
        "!python model_main_tf2.py --model_dir=/content/training_demo/models/my_ssd_resnet101_v1_fpn --pipeline_config_path=/content/training_demo/models/my_ssd_resnet101_v1_fpn/pipeline.config"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-07-11 15:30:45.678625: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-07-11 15:30:48.192544: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "2021-07-11 15:30:48.193399: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
            "2021-07-11 15:30:48.207170: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-11 15:30:48.207769: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\n",
            "coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n",
            "2021-07-11 15:30:48.207802: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-07-11 15:30:48.210821: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
            "2021-07-11 15:30:48.210898: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
            "2021-07-11 15:30:48.212583: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
            "2021-07-11 15:30:48.212980: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
            "2021-07-11 15:30:48.215088: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-07-11 15:30:48.215696: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
            "2021-07-11 15:30:48.215885: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
            "2021-07-11 15:30:48.215976: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-11 15:30:48.216673: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-11 15:30:48.217369: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
            "2021-07-11 15:30:48.217821: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2021-07-11 15:30:48.218000: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "2021-07-11 15:30:48.218097: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-11 15:30:48.218650: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\n",
            "coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n",
            "2021-07-11 15:30:48.218675: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-07-11 15:30:48.218701: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
            "2021-07-11 15:30:48.218715: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
            "2021-07-11 15:30:48.218726: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
            "2021-07-11 15:30:48.218739: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
            "2021-07-11 15:30:48.218752: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-07-11 15:30:48.218771: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
            "2021-07-11 15:30:48.218785: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
            "2021-07-11 15:30:48.218838: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-11 15:30:48.219373: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-11 15:30:48.219895: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
            "2021-07-11 15:30:48.219949: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-07-11 15:30:48.876629: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-07-11 15:30:48.876673: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
            "2021-07-11 15:30:48.876688: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
            "2021-07-11 15:30:48.876932: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-11 15:30:48.877581: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-11 15:30:48.878160: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-11 15:30:48.878667: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2021-07-11 15:30:48.878707: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14957 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "I0711 15:30:48.880375 140349244585856 mirrored_strategy.py:350] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "INFO:tensorflow:Maybe overwriting train_steps: None\n",
            "I0711 15:30:48.884421 140349244585856 config_util.py:552] Maybe overwriting train_steps: None\n",
            "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
            "I0711 15:30:48.884569 140349244585856 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py:558: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "W0711 15:30:49.002500 140349244585856 deprecation.py:339] From /usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py:558: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/training_demo/annotations/train.record']\n",
            "I0711 15:30:49.006522 140349244585856 dataset_builder.py:163] Reading unweighted datasets: ['/content/training_demo/annotations/train.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/training_demo/annotations/train.record']\n",
            "I0711 15:30:49.006679 140349244585856 dataset_builder.py:80] Reading record datasets for input file: ['/content/training_demo/annotations/train.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I0711 15:30:49.006742 140349244585856 dataset_builder.py:81] Number of filenames to read: 1\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W0711 15:30:49.006791 140349244585856 dataset_builder.py:88] num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.\n",
            "W0711 15:30:49.008538 140349244585856 deprecation.py:339] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W0711 15:30:49.023701 140349244585856 deprecation.py:339] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "WARNING:tensorflow:AutoGraph could not transform <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7fa51016a990>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "W0711 15:30:49.058549 140349244585856 ag_logging.py:146] AutoGraph could not transform <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7fa51016a990>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function build at 0x7fa51b804440> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "W0711 15:30:49.294633 140349244585856 ag_logging.py:146] AutoGraph could not transform <function build at 0x7fa51b804440> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function build at 0x7fa51ba3a290> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "W0711 15:30:49.362781 140349244585856 ag_logging.py:146] AutoGraph could not transform <function build at 0x7fa51ba3a290> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function transform_input_data at 0x7fa51b81b0e0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "W0711 15:30:49.400149 140349244585856 ag_logging.py:146] AutoGraph could not transform <function transform_input_data at 0x7fa51b81b0e0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:201: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "W0711 15:30:49.405857 140349244585856 deprecation.py:339] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:201: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:201: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "W0711 15:30:49.472695 140349244585856 deprecation.py:339] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:201: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/inputs.py:284: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0711 15:30:49.542808 140349244585856 deprecation.py:339] From /usr/local/lib/python3.7/dist-packages/object_detection/inputs.py:284: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:AutoGraph could not transform <function pad_input_data_to_static_shapes at 0x7fa51b81b170> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "W0711 15:30:49.800976 140349244585856 ag_logging.py:146] AutoGraph could not transform <function pad_input_data_to_static_shapes at 0x7fa51b81b170> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function _get_features_dict at 0x7fa51b81b3b0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "W0711 15:30:50.035400 140349244585856 ag_logging.py:146] AutoGraph could not transform <function _get_features_dict at 0x7fa51b81b3b0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function _get_labels_dict at 0x7fa51b81b290> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "W0711 15:30:50.053537 140349244585856 ag_logging.py:146] AutoGraph could not transform <function _get_labels_dict at 0x7fa51b81b290> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "2021-07-11 15:30:50.145659: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
            "2021-07-11 15:30:50.149709: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199995000 Hz\n",
            "WARNING:tensorflow:AutoGraph could not transform <function call_for_each_replica at 0x7fa54bf18680> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "W0711 15:30:51.170698 140349244585856 ag_logging.py:146] AutoGraph could not transform <function call_for_each_replica at 0x7fa54bf18680> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/backend.py:434: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n",
            "WARNING:tensorflow:AutoGraph could not transform <function unstack_batch at 0x7fa51b7af9e0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "W0711 15:30:51.226477 140345335805696 ag_logging.py:146] AutoGraph could not transform <function unstack_batch at 0x7fa51b7af9e0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function _compute_losses_and_predictions_dicts at 0x7fa52ee6e170> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "W0711 15:30:51.241722 140345335805696 ag_logging.py:146] AutoGraph could not transform <function _compute_losses_and_predictions_dicts at 0x7fa52ee6e170> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <bound method SSDResNetV1FpnKerasFeatureExtractor._extract_features of <object_detection.models.ssd_resnet_v1_fpn_keras_feature_extractor.SSDResNet101V1FpnKerasFeatureExtractor object at 0x7fa51b58e1d0>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "W0711 15:30:53.308272 140345335805696 ag_logging.py:146] AutoGraph could not transform <bound method SSDResNetV1FpnKerasFeatureExtractor._extract_features of <object_detection.models.ssd_resnet_v1_fpn_keras_feature_extractor.SSDResNet101V1FpnKerasFeatureExtractor object at 0x7fa51b58e1d0>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <bound method KerasFpnTopDownFeatureMaps.call of <object_detection.models.feature_map_generators.KerasFpnTopDownFeatureMaps object at 0x7fa4b619b250>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "W0711 15:30:54.156940 140345335805696 ag_logging.py:146] AutoGraph could not transform <bound method KerasFpnTopDownFeatureMaps.call of <object_detection.models.feature_map_generators.KerasFpnTopDownFeatureMaps object at 0x7fa4b619b250>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <bound method WeightSharedConvolutionalBoxPredictor._predict of <object_detection.predictors.convolutional_keras_box_predictor.WeightSharedConvolutionalBoxPredictor object at 0x7fa510211a90>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "W0711 15:30:54.817504 140345335805696 ag_logging.py:146] AutoGraph could not transform <bound method WeightSharedConvolutionalBoxPredictor._predict of <object_detection.predictors.convolutional_keras_box_predictor.WeightSharedConvolutionalBoxPredictor object at 0x7fa510211a90>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <bound method WeightSharedConvolutionalBoxHead._predict of <object_detection.predictors.heads.keras_box_head.WeightSharedConvolutionalBoxHead object at 0x7fa51022e750>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "W0711 15:30:54.889505 140345335805696 ag_logging.py:146] AutoGraph could not transform <bound method WeightSharedConvolutionalBoxHead._predict of <object_detection.predictors.heads.keras_box_head.WeightSharedConvolutionalBoxHead object at 0x7fa51022e750>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <bound method WeightSharedConvolutionalClassHead._predict of <object_detection.predictors.heads.keras_class_head.WeightSharedConvolutionalClassHead object at 0x7fa51b801c50>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "W0711 15:30:54.949277 140345335805696 ag_logging.py:146] AutoGraph could not transform <bound method WeightSharedConvolutionalClassHead._predict of <object_detection.predictors.heads.keras_class_head.WeightSharedConvolutionalClassHead object at 0x7fa51b801c50>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "2021-07-11 15:31:02.695339: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
            "2021-07-11 15:31:02.944223: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
            "2021-07-11 15:31:02.965572: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0711 15:31:13.417972 140349244585856 cross_device_ops.py:565] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0711 15:31:13.419179 140349244585856 cross_device_ops.py:565] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0711 15:31:13.420832 140349244585856 cross_device_ops.py:565] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0711 15:31:13.421562 140349244585856 cross_device_ops.py:565] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0711 15:31:13.423226 140349244585856 cross_device_ops.py:565] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0711 15:31:13.423969 140349244585856 cross_device_ops.py:565] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0711 15:31:13.425916 140349244585856 cross_device_ops.py:565] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0711 15:31:13.426650 140349244585856 cross_device_ops.py:565] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0711 15:31:13.427958 140349244585856 cross_device_ops.py:565] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0711 15:31:13.428687 140349244585856 cross_device_ops.py:565] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "WARNING:tensorflow:AutoGraph could not transform <function train_loop.<locals>.train_step_fn at 0x7fa4b5761680> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "W0711 15:31:14.181584 140348496070400 ag_logging.py:146] AutoGraph could not transform <function train_loop.<locals>.train_step_fn at 0x7fa4b5761680> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:605: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n",
            "W0711 15:31:14.197758 140348496070400 deprecation.py:537] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:605: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n",
            "INFO:tensorflow:Step 100 per-step time 1.472s\n",
            "I0711 15:33:41.292003 140349244585856 model_lib_v2.py:700] Step 100 per-step time 1.472s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.26342157,\n",
            " 'Loss/localization_loss': 0.19664383,\n",
            " 'Loss/regularization_loss': 0.28564703,\n",
            " 'Loss/total_loss': 0.7457124,\n",
            " 'learning_rate': 0.014666351}\n",
            "I0711 15:33:41.292340 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.26342157,\n",
            " 'Loss/localization_loss': 0.19664383,\n",
            " 'Loss/regularization_loss': 0.28564703,\n",
            " 'Loss/total_loss': 0.7457124,\n",
            " 'learning_rate': 0.014666351}\n",
            "INFO:tensorflow:Step 200 per-step time 0.969s\n",
            "I0711 15:35:18.212743 140349244585856 model_lib_v2.py:700] Step 200 per-step time 0.969s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.17821339,\n",
            " 'Loss/localization_loss': 0.12276799,\n",
            " 'Loss/regularization_loss': 0.2855549,\n",
            " 'Loss/total_loss': 0.5865363,\n",
            " 'learning_rate': 0.0159997}\n",
            "I0711 15:35:18.213061 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.17821339,\n",
            " 'Loss/localization_loss': 0.12276799,\n",
            " 'Loss/regularization_loss': 0.2855549,\n",
            " 'Loss/total_loss': 0.5865363,\n",
            " 'learning_rate': 0.0159997}\n",
            "INFO:tensorflow:Step 300 per-step time 0.970s\n",
            "I0711 15:36:55.243732 140349244585856 model_lib_v2.py:700] Step 300 per-step time 0.970s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.12845924,\n",
            " 'Loss/localization_loss': 0.06989343,\n",
            " 'Loss/regularization_loss': 0.28467825,\n",
            " 'Loss/total_loss': 0.48303092,\n",
            " 'learning_rate': 0.01733305}\n",
            "I0711 15:36:55.244030 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.12845924,\n",
            " 'Loss/localization_loss': 0.06989343,\n",
            " 'Loss/regularization_loss': 0.28467825,\n",
            " 'Loss/total_loss': 0.48303092,\n",
            " 'learning_rate': 0.01733305}\n",
            "INFO:tensorflow:Step 400 per-step time 0.971s\n",
            "I0711 15:38:32.297004 140349244585856 model_lib_v2.py:700] Step 400 per-step time 0.971s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.102872625,\n",
            " 'Loss/localization_loss': 0.05141472,\n",
            " 'Loss/regularization_loss': 0.28278217,\n",
            " 'Loss/total_loss': 0.4370695,\n",
            " 'learning_rate': 0.0186664}\n",
            "I0711 15:38:32.297337 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.102872625,\n",
            " 'Loss/localization_loss': 0.05141472,\n",
            " 'Loss/regularization_loss': 0.28278217,\n",
            " 'Loss/total_loss': 0.4370695,\n",
            " 'learning_rate': 0.0186664}\n",
            "INFO:tensorflow:Step 500 per-step time 0.970s\n",
            "I0711 15:40:09.274438 140349244585856 model_lib_v2.py:700] Step 500 per-step time 0.970s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.11904434,\n",
            " 'Loss/localization_loss': 0.06057071,\n",
            " 'Loss/regularization_loss': 0.28031236,\n",
            " 'Loss/total_loss': 0.4599274,\n",
            " 'learning_rate': 0.01999975}\n",
            "I0711 15:40:09.274779 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.11904434,\n",
            " 'Loss/localization_loss': 0.06057071,\n",
            " 'Loss/regularization_loss': 0.28031236,\n",
            " 'Loss/total_loss': 0.4599274,\n",
            " 'learning_rate': 0.01999975}\n",
            "INFO:tensorflow:Step 600 per-step time 0.969s\n",
            "I0711 15:41:46.177539 140349244585856 model_lib_v2.py:700] Step 600 per-step time 0.969s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.13633473,\n",
            " 'Loss/localization_loss': 0.05855053,\n",
            " 'Loss/regularization_loss': 0.27761722,\n",
            " 'Loss/total_loss': 0.47250247,\n",
            " 'learning_rate': 0.0213331}\n",
            "I0711 15:41:46.177869 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.13633473,\n",
            " 'Loss/localization_loss': 0.05855053,\n",
            " 'Loss/regularization_loss': 0.27761722,\n",
            " 'Loss/total_loss': 0.47250247,\n",
            " 'learning_rate': 0.0213331}\n",
            "INFO:tensorflow:Step 700 per-step time 0.970s\n",
            "I0711 15:43:23.176686 140349244585856 model_lib_v2.py:700] Step 700 per-step time 0.970s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07219243,\n",
            " 'Loss/localization_loss': 0.028770985,\n",
            " 'Loss/regularization_loss': 0.27458563,\n",
            " 'Loss/total_loss': 0.37554905,\n",
            " 'learning_rate': 0.02266645}\n",
            "I0711 15:43:23.176977 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.07219243,\n",
            " 'Loss/localization_loss': 0.028770985,\n",
            " 'Loss/regularization_loss': 0.27458563,\n",
            " 'Loss/total_loss': 0.37554905,\n",
            " 'learning_rate': 0.02266645}\n",
            "INFO:tensorflow:Step 800 per-step time 0.970s\n",
            "I0711 15:45:00.182701 140349244585856 model_lib_v2.py:700] Step 800 per-step time 0.970s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07628829,\n",
            " 'Loss/localization_loss': 0.03757402,\n",
            " 'Loss/regularization_loss': 0.27152947,\n",
            " 'Loss/total_loss': 0.38539177,\n",
            " 'learning_rate': 0.023999799}\n",
            "I0711 15:45:00.183031 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.07628829,\n",
            " 'Loss/localization_loss': 0.03757402,\n",
            " 'Loss/regularization_loss': 0.27152947,\n",
            " 'Loss/total_loss': 0.38539177,\n",
            " 'learning_rate': 0.023999799}\n",
            "INFO:tensorflow:Step 900 per-step time 0.970s\n",
            "I0711 15:46:37.160859 140349244585856 model_lib_v2.py:700] Step 900 per-step time 0.970s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.0751957,\n",
            " 'Loss/localization_loss': 0.032628637,\n",
            " 'Loss/regularization_loss': 0.2682393,\n",
            " 'Loss/total_loss': 0.37606364,\n",
            " 'learning_rate': 0.025333151}\n",
            "I0711 15:46:37.161149 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.0751957,\n",
            " 'Loss/localization_loss': 0.032628637,\n",
            " 'Loss/regularization_loss': 0.2682393,\n",
            " 'Loss/total_loss': 0.37606364,\n",
            " 'learning_rate': 0.025333151}\n",
            "INFO:tensorflow:Step 1000 per-step time 0.969s\n",
            "I0711 15:48:14.078894 140349244585856 model_lib_v2.py:700] Step 1000 per-step time 0.969s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.106322035,\n",
            " 'Loss/localization_loss': 0.03152837,\n",
            " 'Loss/regularization_loss': 0.26498532,\n",
            " 'Loss/total_loss': 0.40283573,\n",
            " 'learning_rate': 0.0266665}\n",
            "I0711 15:48:14.079216 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.106322035,\n",
            " 'Loss/localization_loss': 0.03152837,\n",
            " 'Loss/regularization_loss': 0.26498532,\n",
            " 'Loss/total_loss': 0.40283573,\n",
            " 'learning_rate': 0.0266665}\n",
            "INFO:tensorflow:Step 1100 per-step time 0.983s\n",
            "I0711 15:49:52.348622 140349244585856 model_lib_v2.py:700] Step 1100 per-step time 0.983s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.05866629,\n",
            " 'Loss/localization_loss': 0.023191992,\n",
            " 'Loss/regularization_loss': 0.261883,\n",
            " 'Loss/total_loss': 0.34374127,\n",
            " 'learning_rate': 0.02799985}\n",
            "I0711 15:49:52.348949 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.05866629,\n",
            " 'Loss/localization_loss': 0.023191992,\n",
            " 'Loss/regularization_loss': 0.261883,\n",
            " 'Loss/total_loss': 0.34374127,\n",
            " 'learning_rate': 0.02799985}\n",
            "INFO:tensorflow:Step 1200 per-step time 0.970s\n",
            "I0711 15:51:29.348538 140349244585856 model_lib_v2.py:700] Step 1200 per-step time 0.970s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.068819195,\n",
            " 'Loss/localization_loss': 0.038115695,\n",
            " 'Loss/regularization_loss': 0.2582491,\n",
            " 'Loss/total_loss': 0.365184,\n",
            " 'learning_rate': 0.0293332}\n",
            "I0711 15:51:29.348846 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.068819195,\n",
            " 'Loss/localization_loss': 0.038115695,\n",
            " 'Loss/regularization_loss': 0.2582491,\n",
            " 'Loss/total_loss': 0.365184,\n",
            " 'learning_rate': 0.0293332}\n",
            "INFO:tensorflow:Step 1300 per-step time 0.970s\n",
            "I0711 15:53:06.323267 140349244585856 model_lib_v2.py:700] Step 1300 per-step time 0.970s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.06368733,\n",
            " 'Loss/localization_loss': 0.027828773,\n",
            " 'Loss/regularization_loss': 0.25404984,\n",
            " 'Loss/total_loss': 0.34556594,\n",
            " 'learning_rate': 0.03066655}\n",
            "I0711 15:53:06.323581 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.06368733,\n",
            " 'Loss/localization_loss': 0.027828773,\n",
            " 'Loss/regularization_loss': 0.25404984,\n",
            " 'Loss/total_loss': 0.34556594,\n",
            " 'learning_rate': 0.03066655}\n",
            "INFO:tensorflow:Step 1400 per-step time 0.970s\n",
            "I0711 15:54:43.363641 140349244585856 model_lib_v2.py:700] Step 1400 per-step time 0.970s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.06544956,\n",
            " 'Loss/localization_loss': 0.02383212,\n",
            " 'Loss/regularization_loss': 0.25068343,\n",
            " 'Loss/total_loss': 0.3399651,\n",
            " 'learning_rate': 0.0319999}\n",
            "I0711 15:54:43.363940 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.06544956,\n",
            " 'Loss/localization_loss': 0.02383212,\n",
            " 'Loss/regularization_loss': 0.25068343,\n",
            " 'Loss/total_loss': 0.3399651,\n",
            " 'learning_rate': 0.0319999}\n",
            "INFO:tensorflow:Step 1500 per-step time 0.970s\n",
            "I0711 15:56:20.335770 140349244585856 model_lib_v2.py:700] Step 1500 per-step time 0.970s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.05883079,\n",
            " 'Loss/localization_loss': 0.01667938,\n",
            " 'Loss/regularization_loss': 0.24651168,\n",
            " 'Loss/total_loss': 0.32202184,\n",
            " 'learning_rate': 0.03333325}\n",
            "I0711 15:56:20.336070 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.05883079,\n",
            " 'Loss/localization_loss': 0.01667938,\n",
            " 'Loss/regularization_loss': 0.24651168,\n",
            " 'Loss/total_loss': 0.32202184,\n",
            " 'learning_rate': 0.03333325}\n",
            "INFO:tensorflow:Step 1600 per-step time 0.971s\n",
            "I0711 15:57:57.402230 140349244585856 model_lib_v2.py:700] Step 1600 per-step time 0.971s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.081336886,\n",
            " 'Loss/localization_loss': 0.035320885,\n",
            " 'Loss/regularization_loss': 0.24353181,\n",
            " 'Loss/total_loss': 0.3601896,\n",
            " 'learning_rate': 0.034666598}\n",
            "I0711 15:57:57.402551 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.081336886,\n",
            " 'Loss/localization_loss': 0.035320885,\n",
            " 'Loss/regularization_loss': 0.24353181,\n",
            " 'Loss/total_loss': 0.3601896,\n",
            " 'learning_rate': 0.034666598}\n",
            "INFO:tensorflow:Step 1700 per-step time 0.971s\n",
            "I0711 15:59:34.464474 140349244585856 model_lib_v2.py:700] Step 1700 per-step time 0.971s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.072279125,\n",
            " 'Loss/localization_loss': 0.032919224,\n",
            " 'Loss/regularization_loss': 0.24025744,\n",
            " 'Loss/total_loss': 0.3454558,\n",
            " 'learning_rate': 0.03599995}\n",
            "I0711 15:59:34.464779 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.072279125,\n",
            " 'Loss/localization_loss': 0.032919224,\n",
            " 'Loss/regularization_loss': 0.24025744,\n",
            " 'Loss/total_loss': 0.3454558,\n",
            " 'learning_rate': 0.03599995}\n",
            "INFO:tensorflow:Step 1800 per-step time 0.969s\n",
            "I0711 16:01:11.405317 140349244585856 model_lib_v2.py:700] Step 1800 per-step time 0.969s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.068445824,\n",
            " 'Loss/localization_loss': 0.023740629,\n",
            " 'Loss/regularization_loss': 0.23734047,\n",
            " 'Loss/total_loss': 0.3295269,\n",
            " 'learning_rate': 0.037333302}\n",
            "I0711 16:01:11.405612 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.068445824,\n",
            " 'Loss/localization_loss': 0.023740629,\n",
            " 'Loss/regularization_loss': 0.23734047,\n",
            " 'Loss/total_loss': 0.3295269,\n",
            " 'learning_rate': 0.037333302}\n",
            "INFO:tensorflow:Step 1900 per-step time 0.970s\n",
            "I0711 16:02:48.388954 140349244585856 model_lib_v2.py:700] Step 1900 per-step time 0.970s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.080561705,\n",
            " 'Loss/localization_loss': 0.022448014,\n",
            " 'Loss/regularization_loss': 0.23593894,\n",
            " 'Loss/total_loss': 0.33894867,\n",
            " 'learning_rate': 0.03866665}\n",
            "I0711 16:02:48.389266 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.080561705,\n",
            " 'Loss/localization_loss': 0.022448014,\n",
            " 'Loss/regularization_loss': 0.23593894,\n",
            " 'Loss/total_loss': 0.33894867,\n",
            " 'learning_rate': 0.03866665}\n",
            "INFO:tensorflow:Step 2000 per-step time 0.970s\n",
            "I0711 16:04:25.404817 140349244585856 model_lib_v2.py:700] Step 2000 per-step time 0.970s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07347975,\n",
            " 'Loss/localization_loss': 0.030498639,\n",
            " 'Loss/regularization_loss': 0.23476374,\n",
            " 'Loss/total_loss': 0.33874214,\n",
            " 'learning_rate': 0.04}\n",
            "I0711 16:04:25.405133 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.07347975,\n",
            " 'Loss/localization_loss': 0.030498639,\n",
            " 'Loss/regularization_loss': 0.23476374,\n",
            " 'Loss/total_loss': 0.33874214,\n",
            " 'learning_rate': 0.04}\n",
            "INFO:tensorflow:Step 2100 per-step time 0.983s\n",
            "I0711 16:06:03.708733 140349244585856 model_lib_v2.py:700] Step 2100 per-step time 0.983s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07032479,\n",
            " 'Loss/localization_loss': 0.024650251,\n",
            " 'Loss/regularization_loss': 0.23080727,\n",
            " 'Loss/total_loss': 0.32578233,\n",
            " 'learning_rate': 0.039984576}\n",
            "I0711 16:06:03.709031 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.07032479,\n",
            " 'Loss/localization_loss': 0.024650251,\n",
            " 'Loss/regularization_loss': 0.23080727,\n",
            " 'Loss/total_loss': 0.32578233,\n",
            " 'learning_rate': 0.039984576}\n",
            "INFO:tensorflow:Step 2200 per-step time 0.970s\n",
            "I0711 16:07:40.737470 140349244585856 model_lib_v2.py:700] Step 2200 per-step time 0.970s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.10236449,\n",
            " 'Loss/localization_loss': 0.0254802,\n",
            " 'Loss/regularization_loss': 0.22639993,\n",
            " 'Loss/total_loss': 0.35424462,\n",
            " 'learning_rate': 0.039938346}\n",
            "I0711 16:07:40.737890 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.10236449,\n",
            " 'Loss/localization_loss': 0.0254802,\n",
            " 'Loss/regularization_loss': 0.22639993,\n",
            " 'Loss/total_loss': 0.35424462,\n",
            " 'learning_rate': 0.039938346}\n",
            "INFO:tensorflow:Step 2300 per-step time 0.971s\n",
            "I0711 16:09:17.876973 140349244585856 model_lib_v2.py:700] Step 2300 per-step time 0.971s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07113547,\n",
            " 'Loss/localization_loss': 0.017270835,\n",
            " 'Loss/regularization_loss': 0.2216321,\n",
            " 'Loss/total_loss': 0.3100384,\n",
            " 'learning_rate': 0.03986137}\n",
            "I0711 16:09:17.877266 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.07113547,\n",
            " 'Loss/localization_loss': 0.017270835,\n",
            " 'Loss/regularization_loss': 0.2216321,\n",
            " 'Loss/total_loss': 0.3100384,\n",
            " 'learning_rate': 0.03986137}\n",
            "INFO:tensorflow:Step 2400 per-step time 0.971s\n",
            "I0711 16:10:54.971877 140349244585856 model_lib_v2.py:700] Step 2400 per-step time 0.971s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.047457904,\n",
            " 'Loss/localization_loss': 0.02514852,\n",
            " 'Loss/regularization_loss': 0.21726899,\n",
            " 'Loss/total_loss': 0.28987542,\n",
            " 'learning_rate': 0.039753765}\n",
            "I0711 16:10:54.972183 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.047457904,\n",
            " 'Loss/localization_loss': 0.02514852,\n",
            " 'Loss/regularization_loss': 0.21726899,\n",
            " 'Loss/total_loss': 0.28987542,\n",
            " 'learning_rate': 0.039753765}\n",
            "INFO:tensorflow:Step 2500 per-step time 0.971s\n",
            "I0711 16:12:32.039989 140349244585856 model_lib_v2.py:700] Step 2500 per-step time 0.971s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.06142878,\n",
            " 'Loss/localization_loss': 0.018605074,\n",
            " 'Loss/regularization_loss': 0.21238779,\n",
            " 'Loss/total_loss': 0.29242164,\n",
            " 'learning_rate': 0.039615706}\n",
            "I0711 16:12:32.040316 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.06142878,\n",
            " 'Loss/localization_loss': 0.018605074,\n",
            " 'Loss/regularization_loss': 0.21238779,\n",
            " 'Loss/total_loss': 0.29242164,\n",
            " 'learning_rate': 0.039615706}\n",
            "INFO:tensorflow:Step 2600 per-step time 0.971s\n",
            "I0711 16:14:09.119056 140349244585856 model_lib_v2.py:700] Step 2600 per-step time 0.971s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.06958792,\n",
            " 'Loss/localization_loss': 0.021662053,\n",
            " 'Loss/regularization_loss': 0.20801264,\n",
            " 'Loss/total_loss': 0.2992626,\n",
            " 'learning_rate': 0.039447397}\n",
            "I0711 16:14:09.119348 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.06958792,\n",
            " 'Loss/localization_loss': 0.021662053,\n",
            " 'Loss/regularization_loss': 0.20801264,\n",
            " 'Loss/total_loss': 0.2992626,\n",
            " 'learning_rate': 0.039447397}\n",
            "INFO:tensorflow:Step 2700 per-step time 0.970s\n",
            "I0711 16:15:46.153156 140349244585856 model_lib_v2.py:700] Step 2700 per-step time 0.970s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.06419747,\n",
            " 'Loss/localization_loss': 0.024194412,\n",
            " 'Loss/regularization_loss': 0.20331688,\n",
            " 'Loss/total_loss': 0.29170877,\n",
            " 'learning_rate': 0.039249104}\n",
            "I0711 16:15:46.153460 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.06419747,\n",
            " 'Loss/localization_loss': 0.024194412,\n",
            " 'Loss/regularization_loss': 0.20331688,\n",
            " 'Loss/total_loss': 0.29170877,\n",
            " 'learning_rate': 0.039249104}\n",
            "INFO:tensorflow:Step 2800 per-step time 0.970s\n",
            "I0711 16:17:23.198499 140349244585856 model_lib_v2.py:700] Step 2800 per-step time 0.970s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.10387731,\n",
            " 'Loss/localization_loss': 0.022894328,\n",
            " 'Loss/regularization_loss': 0.19911708,\n",
            " 'Loss/total_loss': 0.32588872,\n",
            " 'learning_rate': 0.039021127}\n",
            "I0711 16:17:23.198774 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.10387731,\n",
            " 'Loss/localization_loss': 0.022894328,\n",
            " 'Loss/regularization_loss': 0.19911708,\n",
            " 'Loss/total_loss': 0.32588872,\n",
            " 'learning_rate': 0.039021127}\n",
            "INFO:tensorflow:Step 2900 per-step time 0.970s\n",
            "I0711 16:19:00.236942 140349244585856 model_lib_v2.py:700] Step 2900 per-step time 0.970s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.06000943,\n",
            " 'Loss/localization_loss': 0.012678872,\n",
            " 'Loss/regularization_loss': 0.19507326,\n",
            " 'Loss/total_loss': 0.26776156,\n",
            " 'learning_rate': 0.03876383}\n",
            "I0711 16:19:00.237283 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.06000943,\n",
            " 'Loss/localization_loss': 0.012678872,\n",
            " 'Loss/regularization_loss': 0.19507326,\n",
            " 'Loss/total_loss': 0.26776156,\n",
            " 'learning_rate': 0.03876383}\n",
            "INFO:tensorflow:Step 3000 per-step time 0.970s\n",
            "I0711 16:20:37.234988 140349244585856 model_lib_v2.py:700] Step 3000 per-step time 0.970s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.048963804,\n",
            " 'Loss/localization_loss': 0.018066097,\n",
            " 'Loss/regularization_loss': 0.19092831,\n",
            " 'Loss/total_loss': 0.2579582,\n",
            " 'learning_rate': 0.038477592}\n",
            "I0711 16:20:37.235272 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.048963804,\n",
            " 'Loss/localization_loss': 0.018066097,\n",
            " 'Loss/regularization_loss': 0.19092831,\n",
            " 'Loss/total_loss': 0.2579582,\n",
            " 'learning_rate': 0.038477592}\n",
            "INFO:tensorflow:Step 3100 per-step time 0.983s\n",
            "I0711 16:22:15.560822 140349244585856 model_lib_v2.py:700] Step 3100 per-step time 0.983s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.049716126,\n",
            " 'Loss/localization_loss': 0.0132001955,\n",
            " 'Loss/regularization_loss': 0.18676147,\n",
            " 'Loss/total_loss': 0.24967779,\n",
            " 'learning_rate': 0.03816286}\n",
            "I0711 16:22:15.561118 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.049716126,\n",
            " 'Loss/localization_loss': 0.0132001955,\n",
            " 'Loss/regularization_loss': 0.18676147,\n",
            " 'Loss/total_loss': 0.24967779,\n",
            " 'learning_rate': 0.03816286}\n",
            "INFO:tensorflow:Step 3200 per-step time 0.970s\n",
            "I0711 16:23:52.599554 140349244585856 model_lib_v2.py:700] Step 3200 per-step time 0.970s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.041247133,\n",
            " 'Loss/localization_loss': 0.012493236,\n",
            " 'Loss/regularization_loss': 0.18312429,\n",
            " 'Loss/total_loss': 0.23686466,\n",
            " 'learning_rate': 0.037820127}\n",
            "I0711 16:23:52.599859 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.041247133,\n",
            " 'Loss/localization_loss': 0.012493236,\n",
            " 'Loss/regularization_loss': 0.18312429,\n",
            " 'Loss/total_loss': 0.23686466,\n",
            " 'learning_rate': 0.037820127}\n",
            "INFO:tensorflow:Step 3300 per-step time 0.970s\n",
            "I0711 16:25:29.583904 140349244585856 model_lib_v2.py:700] Step 3300 per-step time 0.970s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.044803116,\n",
            " 'Loss/localization_loss': 0.013319265,\n",
            " 'Loss/regularization_loss': 0.17904404,\n",
            " 'Loss/total_loss': 0.23716642,\n",
            " 'learning_rate': 0.03744992}\n",
            "I0711 16:25:29.584208 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.044803116,\n",
            " 'Loss/localization_loss': 0.013319265,\n",
            " 'Loss/regularization_loss': 0.17904404,\n",
            " 'Loss/total_loss': 0.23716642,\n",
            " 'learning_rate': 0.03744992}\n",
            "INFO:tensorflow:Step 3400 per-step time 0.970s\n",
            "I0711 16:27:06.588567 140349244585856 model_lib_v2.py:700] Step 3400 per-step time 0.970s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.06941294,\n",
            " 'Loss/localization_loss': 0.030029772,\n",
            " 'Loss/regularization_loss': 0.17525975,\n",
            " 'Loss/total_loss': 0.27470246,\n",
            " 'learning_rate': 0.037052803}\n",
            "I0711 16:27:06.588864 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.06941294,\n",
            " 'Loss/localization_loss': 0.030029772,\n",
            " 'Loss/regularization_loss': 0.17525975,\n",
            " 'Loss/total_loss': 0.27470246,\n",
            " 'learning_rate': 0.037052803}\n",
            "INFO:tensorflow:Step 3500 per-step time 0.970s\n",
            "I0711 16:28:43.629562 140349244585856 model_lib_v2.py:700] Step 3500 per-step time 0.970s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.055523153,\n",
            " 'Loss/localization_loss': 0.012610247,\n",
            " 'Loss/regularization_loss': 0.17166789,\n",
            " 'Loss/total_loss': 0.23980129,\n",
            " 'learning_rate': 0.036629394}\n",
            "I0711 16:28:43.629907 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.055523153,\n",
            " 'Loss/localization_loss': 0.012610247,\n",
            " 'Loss/regularization_loss': 0.17166789,\n",
            " 'Loss/total_loss': 0.23980129,\n",
            " 'learning_rate': 0.036629394}\n",
            "INFO:tensorflow:Step 3600 per-step time 0.971s\n",
            "I0711 16:30:20.692789 140349244585856 model_lib_v2.py:700] Step 3600 per-step time 0.971s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.043648787,\n",
            " 'Loss/localization_loss': 0.0100365905,\n",
            " 'Loss/regularization_loss': 0.16817936,\n",
            " 'Loss/total_loss': 0.22186475,\n",
            " 'learning_rate': 0.03618034}\n",
            "I0711 16:30:20.693124 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.043648787,\n",
            " 'Loss/localization_loss': 0.0100365905,\n",
            " 'Loss/regularization_loss': 0.16817936,\n",
            " 'Loss/total_loss': 0.22186475,\n",
            " 'learning_rate': 0.03618034}\n",
            "INFO:tensorflow:Step 3700 per-step time 0.971s\n",
            "I0711 16:31:57.753032 140349244585856 model_lib_v2.py:700] Step 3700 per-step time 0.971s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.06606033,\n",
            " 'Loss/localization_loss': 0.017496366,\n",
            " 'Loss/regularization_loss': 0.16495186,\n",
            " 'Loss/total_loss': 0.24850856,\n",
            " 'learning_rate': 0.035706338}\n",
            "I0711 16:31:57.753316 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.06606033,\n",
            " 'Loss/localization_loss': 0.017496366,\n",
            " 'Loss/regularization_loss': 0.16495186,\n",
            " 'Loss/total_loss': 0.24850856,\n",
            " 'learning_rate': 0.035706338}\n",
            "INFO:tensorflow:Step 3800 per-step time 0.970s\n",
            "I0711 16:33:34.765349 140349244585856 model_lib_v2.py:700] Step 3800 per-step time 0.970s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.06331398,\n",
            " 'Loss/localization_loss': 0.018491456,\n",
            " 'Loss/regularization_loss': 0.16152176,\n",
            " 'Loss/total_loss': 0.2433272,\n",
            " 'learning_rate': 0.03520812}\n",
            "I0711 16:33:34.765665 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.06331398,\n",
            " 'Loss/localization_loss': 0.018491456,\n",
            " 'Loss/regularization_loss': 0.16152176,\n",
            " 'Loss/total_loss': 0.2433272,\n",
            " 'learning_rate': 0.03520812}\n",
            "INFO:tensorflow:Step 3900 per-step time 0.970s\n",
            "I0711 16:35:11.742936 140349244585856 model_lib_v2.py:700] Step 3900 per-step time 0.970s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.041623987,\n",
            " 'Loss/localization_loss': 0.009962377,\n",
            " 'Loss/regularization_loss': 0.15821725,\n",
            " 'Loss/total_loss': 0.20980361,\n",
            " 'learning_rate': 0.03468645}\n",
            "I0711 16:35:11.743259 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.041623987,\n",
            " 'Loss/localization_loss': 0.009962377,\n",
            " 'Loss/regularization_loss': 0.15821725,\n",
            " 'Loss/total_loss': 0.20980361,\n",
            " 'learning_rate': 0.03468645}\n",
            "INFO:tensorflow:Step 4000 per-step time 0.970s\n",
            "I0711 16:36:48.751927 140349244585856 model_lib_v2.py:700] Step 4000 per-step time 0.970s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.06182041,\n",
            " 'Loss/localization_loss': 0.016577946,\n",
            " 'Loss/regularization_loss': 0.1552976,\n",
            " 'Loss/total_loss': 0.23369595,\n",
            " 'learning_rate': 0.034142137}\n",
            "I0711 16:36:48.752220 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.06182041,\n",
            " 'Loss/localization_loss': 0.016577946,\n",
            " 'Loss/regularization_loss': 0.1552976,\n",
            " 'Loss/total_loss': 0.23369595,\n",
            " 'learning_rate': 0.034142137}\n",
            "INFO:tensorflow:Step 4100 per-step time 0.984s\n",
            "I0711 16:38:27.117330 140349244585856 model_lib_v2.py:700] Step 4100 per-step time 0.984s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.051763996,\n",
            " 'Loss/localization_loss': 0.016757088,\n",
            " 'Loss/regularization_loss': 0.15234238,\n",
            " 'Loss/total_loss': 0.22086346,\n",
            " 'learning_rate': 0.03357601}\n",
            "I0711 16:38:27.117632 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.051763996,\n",
            " 'Loss/localization_loss': 0.016757088,\n",
            " 'Loss/regularization_loss': 0.15234238,\n",
            " 'Loss/total_loss': 0.22086346,\n",
            " 'learning_rate': 0.03357601}\n",
            "INFO:tensorflow:Step 4200 per-step time 0.970s\n",
            "I0711 16:40:04.120397 140349244585856 model_lib_v2.py:700] Step 4200 per-step time 0.970s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.045283806,\n",
            " 'Loss/localization_loss': 0.012387036,\n",
            " 'Loss/regularization_loss': 0.1497143,\n",
            " 'Loss/total_loss': 0.20738515,\n",
            " 'learning_rate': 0.03298896}\n",
            "I0711 16:40:04.120700 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.045283806,\n",
            " 'Loss/localization_loss': 0.012387036,\n",
            " 'Loss/regularization_loss': 0.1497143,\n",
            " 'Loss/total_loss': 0.20738515,\n",
            " 'learning_rate': 0.03298896}\n",
            "INFO:tensorflow:Step 4300 per-step time 0.970s\n",
            "I0711 16:41:41.167634 140349244585856 model_lib_v2.py:700] Step 4300 per-step time 0.970s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.05044711,\n",
            " 'Loss/localization_loss': 0.011879006,\n",
            " 'Loss/regularization_loss': 0.14698778,\n",
            " 'Loss/total_loss': 0.2093139,\n",
            " 'learning_rate': 0.032381877}\n",
            "I0711 16:41:41.167945 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.05044711,\n",
            " 'Loss/localization_loss': 0.011879006,\n",
            " 'Loss/regularization_loss': 0.14698778,\n",
            " 'Loss/total_loss': 0.2093139,\n",
            " 'learning_rate': 0.032381877}\n",
            "INFO:tensorflow:Step 4400 per-step time 0.970s\n",
            "I0711 16:43:18.202832 140349244585856 model_lib_v2.py:700] Step 4400 per-step time 0.970s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.049706157,\n",
            " 'Loss/localization_loss': 0.010988591,\n",
            " 'Loss/regularization_loss': 0.14422987,\n",
            " 'Loss/total_loss': 0.20492461,\n",
            " 'learning_rate': 0.031755704}\n",
            "I0711 16:43:18.203123 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.049706157,\n",
            " 'Loss/localization_loss': 0.010988591,\n",
            " 'Loss/regularization_loss': 0.14422987,\n",
            " 'Loss/total_loss': 0.20492461,\n",
            " 'learning_rate': 0.031755704}\n",
            "INFO:tensorflow:Step 4500 per-step time 0.970s\n",
            "I0711 16:44:55.207297 140349244585856 model_lib_v2.py:700] Step 4500 per-step time 0.970s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.04422309,\n",
            " 'Loss/localization_loss': 0.011632953,\n",
            " 'Loss/regularization_loss': 0.14157645,\n",
            " 'Loss/total_loss': 0.19743249,\n",
            " 'learning_rate': 0.031111402}\n",
            "I0711 16:44:55.207583 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.04422309,\n",
            " 'Loss/localization_loss': 0.011632953,\n",
            " 'Loss/regularization_loss': 0.14157645,\n",
            " 'Loss/total_loss': 0.19743249,\n",
            " 'learning_rate': 0.031111402}\n",
            "INFO:tensorflow:Step 4600 per-step time 0.970s\n",
            "I0711 16:46:32.223466 140349244585856 model_lib_v2.py:700] Step 4600 per-step time 0.970s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.045429237,\n",
            " 'Loss/localization_loss': 0.0074224947,\n",
            " 'Loss/regularization_loss': 0.13903455,\n",
            " 'Loss/total_loss': 0.19188629,\n",
            " 'learning_rate': 0.03044997}\n",
            "I0711 16:46:32.223770 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.045429237,\n",
            " 'Loss/localization_loss': 0.0074224947,\n",
            " 'Loss/regularization_loss': 0.13903455,\n",
            " 'Loss/total_loss': 0.19188629,\n",
            " 'learning_rate': 0.03044997}\n",
            "INFO:tensorflow:Step 4700 per-step time 0.970s\n",
            "I0711 16:48:09.183425 140349244585856 model_lib_v2.py:700] Step 4700 per-step time 0.970s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.05955597,\n",
            " 'Loss/localization_loss': 0.014502276,\n",
            " 'Loss/regularization_loss': 0.13655238,\n",
            " 'Loss/total_loss': 0.21061063,\n",
            " 'learning_rate': 0.029772423}\n",
            "I0711 16:48:09.183723 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.05955597,\n",
            " 'Loss/localization_loss': 0.014502276,\n",
            " 'Loss/regularization_loss': 0.13655238,\n",
            " 'Loss/total_loss': 0.21061063,\n",
            " 'learning_rate': 0.029772423}\n",
            "INFO:tensorflow:Step 4800 per-step time 0.970s\n",
            "I0711 16:49:46.165625 140349244585856 model_lib_v2.py:700] Step 4800 per-step time 0.970s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.041500475,\n",
            " 'Loss/localization_loss': 0.0076028947,\n",
            " 'Loss/regularization_loss': 0.13417563,\n",
            " 'Loss/total_loss': 0.18327901,\n",
            " 'learning_rate': 0.029079808}\n",
            "I0711 16:49:46.165973 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.041500475,\n",
            " 'Loss/localization_loss': 0.0076028947,\n",
            " 'Loss/regularization_loss': 0.13417563,\n",
            " 'Loss/total_loss': 0.18327901,\n",
            " 'learning_rate': 0.029079808}\n",
            "INFO:tensorflow:Step 4900 per-step time 0.970s\n",
            "I0711 16:51:23.179236 140349244585856 model_lib_v2.py:700] Step 4900 per-step time 0.970s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.03589628,\n",
            " 'Loss/localization_loss': 0.010093587,\n",
            " 'Loss/regularization_loss': 0.13186108,\n",
            " 'Loss/total_loss': 0.17785095,\n",
            " 'learning_rate': 0.028373193}\n",
            "I0711 16:51:23.179559 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.03589628,\n",
            " 'Loss/localization_loss': 0.010093587,\n",
            " 'Loss/regularization_loss': 0.13186108,\n",
            " 'Loss/total_loss': 0.17785095,\n",
            " 'learning_rate': 0.028373193}\n",
            "INFO:tensorflow:Step 5000 per-step time 0.970s\n",
            "I0711 16:53:00.160323 140349244585856 model_lib_v2.py:700] Step 5000 per-step time 0.970s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.03917432,\n",
            " 'Loss/localization_loss': 0.006646765,\n",
            " 'Loss/regularization_loss': 0.12959665,\n",
            " 'Loss/total_loss': 0.17541774,\n",
            " 'learning_rate': 0.02765367}\n",
            "I0711 16:53:00.160674 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.03917432,\n",
            " 'Loss/localization_loss': 0.006646765,\n",
            " 'Loss/regularization_loss': 0.12959665,\n",
            " 'Loss/total_loss': 0.17541774,\n",
            " 'learning_rate': 0.02765367}\n",
            "INFO:tensorflow:Step 5100 per-step time 0.983s\n",
            "I0711 16:54:38.422866 140349244585856 model_lib_v2.py:700] Step 5100 per-step time 0.983s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.030375969,\n",
            " 'Loss/localization_loss': 0.0074626612,\n",
            " 'Loss/regularization_loss': 0.1274602,\n",
            " 'Loss/total_loss': 0.16529882,\n",
            " 'learning_rate': 0.02692234}\n",
            "I0711 16:54:38.423152 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.030375969,\n",
            " 'Loss/localization_loss': 0.0074626612,\n",
            " 'Loss/regularization_loss': 0.1274602,\n",
            " 'Loss/total_loss': 0.16529882,\n",
            " 'learning_rate': 0.02692234}\n",
            "INFO:tensorflow:Step 5200 per-step time 0.970s\n",
            "I0711 16:56:15.374706 140349244585856 model_lib_v2.py:700] Step 5200 per-step time 0.970s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.048002154,\n",
            " 'Loss/localization_loss': 0.008043099,\n",
            " 'Loss/regularization_loss': 0.12540247,\n",
            " 'Loss/total_loss': 0.18144771,\n",
            " 'learning_rate': 0.026180338}\n",
            "I0711 16:56:15.374989 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.048002154,\n",
            " 'Loss/localization_loss': 0.008043099,\n",
            " 'Loss/regularization_loss': 0.12540247,\n",
            " 'Loss/total_loss': 0.18144771,\n",
            " 'learning_rate': 0.026180338}\n",
            "INFO:tensorflow:Step 5300 per-step time 0.970s\n",
            "I0711 16:57:52.353914 140349244585856 model_lib_v2.py:700] Step 5300 per-step time 0.970s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.04014027,\n",
            " 'Loss/localization_loss': 0.015708433,\n",
            " 'Loss/regularization_loss': 0.12343602,\n",
            " 'Loss/total_loss': 0.17928472,\n",
            " 'learning_rate': 0.025428807}\n",
            "I0711 16:57:52.354223 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.04014027,\n",
            " 'Loss/localization_loss': 0.015708433,\n",
            " 'Loss/regularization_loss': 0.12343602,\n",
            " 'Loss/total_loss': 0.17928472,\n",
            " 'learning_rate': 0.025428807}\n",
            "INFO:tensorflow:Step 5400 per-step time 0.970s\n",
            "I0711 16:59:29.402894 140349244585856 model_lib_v2.py:700] Step 5400 per-step time 0.970s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.065903224,\n",
            " 'Loss/localization_loss': 0.018860392,\n",
            " 'Loss/regularization_loss': 0.121646136,\n",
            " 'Loss/total_loss': 0.20640975,\n",
            " 'learning_rate': 0.024668908}\n",
            "I0711 16:59:29.403183 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.065903224,\n",
            " 'Loss/localization_loss': 0.018860392,\n",
            " 'Loss/regularization_loss': 0.121646136,\n",
            " 'Loss/total_loss': 0.20640975,\n",
            " 'learning_rate': 0.024668908}\n",
            "INFO:tensorflow:Step 5500 per-step time 0.971s\n",
            "I0711 17:01:06.494667 140349244585856 model_lib_v2.py:700] Step 5500 per-step time 0.971s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.030773696,\n",
            " 'Loss/localization_loss': 0.0047332966,\n",
            " 'Loss/regularization_loss': 0.119806476,\n",
            " 'Loss/total_loss': 0.15531346,\n",
            " 'learning_rate': 0.023901805}\n",
            "I0711 17:01:06.494945 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.030773696,\n",
            " 'Loss/localization_loss': 0.0047332966,\n",
            " 'Loss/regularization_loss': 0.119806476,\n",
            " 'Loss/total_loss': 0.15531346,\n",
            " 'learning_rate': 0.023901805}\n",
            "INFO:tensorflow:Step 5600 per-step time 0.971s\n",
            "I0711 17:02:43.602731 140349244585856 model_lib_v2.py:700] Step 5600 per-step time 0.971s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.03278194,\n",
            " 'Loss/localization_loss': 0.0036094529,\n",
            " 'Loss/regularization_loss': 0.11802754,\n",
            " 'Loss/total_loss': 0.15441893,\n",
            " 'learning_rate': 0.02312869}\n",
            "I0711 17:02:43.603013 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.03278194,\n",
            " 'Loss/localization_loss': 0.0036094529,\n",
            " 'Loss/regularization_loss': 0.11802754,\n",
            " 'Loss/total_loss': 0.15441893,\n",
            " 'learning_rate': 0.02312869}\n",
            "INFO:tensorflow:Step 5700 per-step time 0.971s\n",
            "I0711 17:04:20.684350 140349244585856 model_lib_v2.py:700] Step 5700 per-step time 0.971s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.042725682,\n",
            " 'Loss/localization_loss': 0.009163855,\n",
            " 'Loss/regularization_loss': 0.11639726,\n",
            " 'Loss/total_loss': 0.1682868,\n",
            " 'learning_rate': 0.022350745}\n",
            "I0711 17:04:20.684648 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.042725682,\n",
            " 'Loss/localization_loss': 0.009163855,\n",
            " 'Loss/regularization_loss': 0.11639726,\n",
            " 'Loss/total_loss': 0.1682868,\n",
            " 'learning_rate': 0.022350745}\n",
            "INFO:tensorflow:Step 5800 per-step time 0.971s\n",
            "I0711 17:05:57.739275 140349244585856 model_lib_v2.py:700] Step 5800 per-step time 0.971s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.040107984,\n",
            " 'Loss/localization_loss': 0.0053834375,\n",
            " 'Loss/regularization_loss': 0.114868395,\n",
            " 'Loss/total_loss': 0.16035981,\n",
            " 'learning_rate': 0.02156918}\n",
            "I0711 17:05:57.739580 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.040107984,\n",
            " 'Loss/localization_loss': 0.0053834375,\n",
            " 'Loss/regularization_loss': 0.114868395,\n",
            " 'Loss/total_loss': 0.16035981,\n",
            " 'learning_rate': 0.02156918}\n",
            "INFO:tensorflow:Step 5900 per-step time 0.971s\n",
            "I0711 17:07:34.886016 140349244585856 model_lib_v2.py:700] Step 5900 per-step time 0.971s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.035289392,\n",
            " 'Loss/localization_loss': 0.0069132606,\n",
            " 'Loss/regularization_loss': 0.1133995,\n",
            " 'Loss/total_loss': 0.15560216,\n",
            " 'learning_rate': 0.020785196}\n",
            "I0711 17:07:34.886334 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.035289392,\n",
            " 'Loss/localization_loss': 0.0069132606,\n",
            " 'Loss/regularization_loss': 0.1133995,\n",
            " 'Loss/total_loss': 0.15560216,\n",
            " 'learning_rate': 0.020785196}\n",
            "INFO:tensorflow:Step 6000 per-step time 0.971s\n",
            "I0711 17:09:11.976390 140349244585856 model_lib_v2.py:700] Step 6000 per-step time 0.971s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.033659328,\n",
            " 'Loss/localization_loss': 0.004545609,\n",
            " 'Loss/regularization_loss': 0.111995056,\n",
            " 'Loss/total_loss': 0.1502,\n",
            " 'learning_rate': 0.019999998}\n",
            "I0711 17:09:11.976693 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.033659328,\n",
            " 'Loss/localization_loss': 0.004545609,\n",
            " 'Loss/regularization_loss': 0.111995056,\n",
            " 'Loss/total_loss': 0.1502,\n",
            " 'learning_rate': 0.019999998}\n",
            "INFO:tensorflow:Step 6100 per-step time 0.996s\n",
            "I0711 17:10:51.577495 140349244585856 model_lib_v2.py:700] Step 6100 per-step time 0.996s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.039014716,\n",
            " 'Loss/localization_loss': 0.007978324,\n",
            " 'Loss/regularization_loss': 0.11062307,\n",
            " 'Loss/total_loss': 0.15761611,\n",
            " 'learning_rate': 0.019214803}\n",
            "I0711 17:10:51.577793 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.039014716,\n",
            " 'Loss/localization_loss': 0.007978324,\n",
            " 'Loss/regularization_loss': 0.11062307,\n",
            " 'Loss/total_loss': 0.15761611,\n",
            " 'learning_rate': 0.019214803}\n",
            "INFO:tensorflow:Step 6200 per-step time 0.970s\n",
            "I0711 17:12:28.622799 140349244585856 model_lib_v2.py:700] Step 6200 per-step time 0.970s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.03548705,\n",
            " 'Loss/localization_loss': 0.0068983547,\n",
            " 'Loss/regularization_loss': 0.10929249,\n",
            " 'Loss/total_loss': 0.15167789,\n",
            " 'learning_rate': 0.018430816}\n",
            "I0711 17:12:28.623137 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.03548705,\n",
            " 'Loss/localization_loss': 0.0068983547,\n",
            " 'Loss/regularization_loss': 0.10929249,\n",
            " 'Loss/total_loss': 0.15167789,\n",
            " 'learning_rate': 0.018430816}\n",
            "INFO:tensorflow:Step 6300 per-step time 0.971s\n",
            "I0711 17:14:05.703110 140349244585856 model_lib_v2.py:700] Step 6300 per-step time 0.971s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.02869458,\n",
            " 'Loss/localization_loss': 0.0061177136,\n",
            " 'Loss/regularization_loss': 0.10805373,\n",
            " 'Loss/total_loss': 0.14286602,\n",
            " 'learning_rate': 0.017649252}\n",
            "I0711 17:14:05.703446 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.02869458,\n",
            " 'Loss/localization_loss': 0.0061177136,\n",
            " 'Loss/regularization_loss': 0.10805373,\n",
            " 'Loss/total_loss': 0.14286602,\n",
            " 'learning_rate': 0.017649252}\n",
            "INFO:tensorflow:Step 6400 per-step time 0.971s\n",
            "I0711 17:15:42.797521 140349244585856 model_lib_v2.py:700] Step 6400 per-step time 0.971s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.032571234,\n",
            " 'Loss/localization_loss': 0.004224631,\n",
            " 'Loss/regularization_loss': 0.106844135,\n",
            " 'Loss/total_loss': 0.14364,\n",
            " 'learning_rate': 0.01687131}\n",
            "I0711 17:15:42.797827 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.032571234,\n",
            " 'Loss/localization_loss': 0.004224631,\n",
            " 'Loss/regularization_loss': 0.106844135,\n",
            " 'Loss/total_loss': 0.14364,\n",
            " 'learning_rate': 0.01687131}\n",
            "INFO:tensorflow:Step 6500 per-step time 0.971s\n",
            "I0711 17:17:19.898181 140349244585856 model_lib_v2.py:700] Step 6500 per-step time 0.971s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.05150721,\n",
            " 'Loss/localization_loss': 0.010646814,\n",
            " 'Loss/regularization_loss': 0.10572288,\n",
            " 'Loss/total_loss': 0.1678769,\n",
            " 'learning_rate': 0.016098194}\n",
            "I0711 17:17:19.898518 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.05150721,\n",
            " 'Loss/localization_loss': 0.010646814,\n",
            " 'Loss/regularization_loss': 0.10572288,\n",
            " 'Loss/total_loss': 0.1678769,\n",
            " 'learning_rate': 0.016098194}\n",
            "INFO:tensorflow:Step 6600 per-step time 0.970s\n",
            "I0711 17:18:56.909178 140349244585856 model_lib_v2.py:700] Step 6600 per-step time 0.970s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.023749739,\n",
            " 'Loss/localization_loss': 0.0036555587,\n",
            " 'Loss/regularization_loss': 0.1046306,\n",
            " 'Loss/total_loss': 0.1320359,\n",
            " 'learning_rate': 0.015331091}\n",
            "I0711 17:18:56.909515 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.023749739,\n",
            " 'Loss/localization_loss': 0.0036555587,\n",
            " 'Loss/regularization_loss': 0.1046306,\n",
            " 'Loss/total_loss': 0.1320359,\n",
            " 'learning_rate': 0.015331091}\n",
            "INFO:tensorflow:Step 6700 per-step time 0.970s\n",
            "I0711 17:20:33.933339 140349244585856 model_lib_v2.py:700] Step 6700 per-step time 0.970s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.026588997,\n",
            " 'Loss/localization_loss': 0.0051926714,\n",
            " 'Loss/regularization_loss': 0.10358919,\n",
            " 'Loss/total_loss': 0.13537087,\n",
            " 'learning_rate': 0.014571187}\n",
            "I0711 17:20:33.933664 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.026588997,\n",
            " 'Loss/localization_loss': 0.0051926714,\n",
            " 'Loss/regularization_loss': 0.10358919,\n",
            " 'Loss/total_loss': 0.13537087,\n",
            " 'learning_rate': 0.014571187}\n",
            "INFO:tensorflow:Step 6800 per-step time 0.971s\n",
            "I0711 17:22:11.050925 140349244585856 model_lib_v2.py:700] Step 6800 per-step time 0.971s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.022381479,\n",
            " 'Loss/localization_loss': 0.0029201594,\n",
            " 'Loss/regularization_loss': 0.102613024,\n",
            " 'Loss/total_loss': 0.12791467,\n",
            " 'learning_rate': 0.013819658}\n",
            "I0711 17:22:11.051246 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.022381479,\n",
            " 'Loss/localization_loss': 0.0029201594,\n",
            " 'Loss/regularization_loss': 0.102613024,\n",
            " 'Loss/total_loss': 0.12791467,\n",
            " 'learning_rate': 0.013819658}\n",
            "INFO:tensorflow:Step 6900 per-step time 0.971s\n",
            "I0711 17:23:48.155001 140349244585856 model_lib_v2.py:700] Step 6900 per-step time 0.971s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.027075239,\n",
            " 'Loss/localization_loss': 0.005154314,\n",
            " 'Loss/regularization_loss': 0.10168014,\n",
            " 'Loss/total_loss': 0.13390969,\n",
            " 'learning_rate': 0.013077657}\n",
            "I0711 17:23:48.155282 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.027075239,\n",
            " 'Loss/localization_loss': 0.005154314,\n",
            " 'Loss/regularization_loss': 0.10168014,\n",
            " 'Loss/total_loss': 0.13390969,\n",
            " 'learning_rate': 0.013077657}\n",
            "INFO:tensorflow:Step 7000 per-step time 0.971s\n",
            "I0711 17:25:25.259130 140349244585856 model_lib_v2.py:700] Step 7000 per-step time 0.971s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.02393849,\n",
            " 'Loss/localization_loss': 0.003690188,\n",
            " 'Loss/regularization_loss': 0.10080314,\n",
            " 'Loss/total_loss': 0.12843181,\n",
            " 'learning_rate': 0.012346329}\n",
            "I0711 17:25:25.259448 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.02393849,\n",
            " 'Loss/localization_loss': 0.003690188,\n",
            " 'Loss/regularization_loss': 0.10080314,\n",
            " 'Loss/total_loss': 0.12843181,\n",
            " 'learning_rate': 0.012346329}\n",
            "INFO:tensorflow:Step 7100 per-step time 0.984s\n",
            "I0711 17:27:03.655982 140349244585856 model_lib_v2.py:700] Step 7100 per-step time 0.984s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.026192226,\n",
            " 'Loss/localization_loss': 0.0041257935,\n",
            " 'Loss/regularization_loss': 0.09999467,\n",
            " 'Loss/total_loss': 0.13031268,\n",
            " 'learning_rate': 0.011626803}\n",
            "I0711 17:27:03.656313 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.026192226,\n",
            " 'Loss/localization_loss': 0.0041257935,\n",
            " 'Loss/regularization_loss': 0.09999467,\n",
            " 'Loss/total_loss': 0.13031268,\n",
            " 'learning_rate': 0.011626803}\n",
            "INFO:tensorflow:Step 7200 per-step time 0.971s\n",
            "I0711 17:28:40.785091 140349244585856 model_lib_v2.py:700] Step 7200 per-step time 0.971s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.026090968,\n",
            " 'Loss/localization_loss': 0.0030659717,\n",
            " 'Loss/regularization_loss': 0.09923041,\n",
            " 'Loss/total_loss': 0.12838735,\n",
            " 'learning_rate': 0.010920188}\n",
            "I0711 17:28:40.785393 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.026090968,\n",
            " 'Loss/localization_loss': 0.0030659717,\n",
            " 'Loss/regularization_loss': 0.09923041,\n",
            " 'Loss/total_loss': 0.12838735,\n",
            " 'learning_rate': 0.010920188}\n",
            "INFO:tensorflow:Step 7300 per-step time 0.970s\n",
            "I0711 17:30:17.811265 140349244585856 model_lib_v2.py:700] Step 7300 per-step time 0.970s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.02446804,\n",
            " 'Loss/localization_loss': 0.0035618283,\n",
            " 'Loss/regularization_loss': 0.0984998,\n",
            " 'Loss/total_loss': 0.12652966,\n",
            " 'learning_rate': 0.010227573}\n",
            "I0711 17:30:17.811576 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.02446804,\n",
            " 'Loss/localization_loss': 0.0035618283,\n",
            " 'Loss/regularization_loss': 0.0984998,\n",
            " 'Loss/total_loss': 0.12652966,\n",
            " 'learning_rate': 0.010227573}\n",
            "INFO:tensorflow:Step 7400 per-step time 0.971s\n",
            "I0711 17:31:54.924150 140349244585856 model_lib_v2.py:700] Step 7400 per-step time 0.971s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.029605275,\n",
            " 'Loss/localization_loss': 0.00574287,\n",
            " 'Loss/regularization_loss': 0.09781272,\n",
            " 'Loss/total_loss': 0.13316086,\n",
            " 'learning_rate': 0.009550026}\n",
            "I0711 17:31:54.924463 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.029605275,\n",
            " 'Loss/localization_loss': 0.00574287,\n",
            " 'Loss/regularization_loss': 0.09781272,\n",
            " 'Loss/total_loss': 0.13316086,\n",
            " 'learning_rate': 0.009550026}\n",
            "INFO:tensorflow:Step 7500 per-step time 0.971s\n",
            "I0711 17:33:31.989468 140349244585856 model_lib_v2.py:700] Step 7500 per-step time 0.971s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.027400628,\n",
            " 'Loss/localization_loss': 0.01123172,\n",
            " 'Loss/regularization_loss': 0.097218245,\n",
            " 'Loss/total_loss': 0.1358506,\n",
            " 'learning_rate': 0.008888596}\n",
            "I0711 17:33:31.989800 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.027400628,\n",
            " 'Loss/localization_loss': 0.01123172,\n",
            " 'Loss/regularization_loss': 0.097218245,\n",
            " 'Loss/total_loss': 0.1358506,\n",
            " 'learning_rate': 0.008888596}\n",
            "INFO:tensorflow:Step 7600 per-step time 0.971s\n",
            "I0711 17:35:09.088269 140349244585856 model_lib_v2.py:700] Step 7600 per-step time 0.971s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.026920155,\n",
            " 'Loss/localization_loss': 0.0028532585,\n",
            " 'Loss/regularization_loss': 0.09664096,\n",
            " 'Loss/total_loss': 0.12641437,\n",
            " 'learning_rate': 0.008244291}\n",
            "I0711 17:35:09.088605 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.026920155,\n",
            " 'Loss/localization_loss': 0.0028532585,\n",
            " 'Loss/regularization_loss': 0.09664096,\n",
            " 'Loss/total_loss': 0.12641437,\n",
            " 'learning_rate': 0.008244291}\n",
            "INFO:tensorflow:Step 7700 per-step time 0.971s\n",
            "I0711 17:36:46.194869 140349244585856 model_lib_v2.py:700] Step 7700 per-step time 0.971s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.020967862,\n",
            " 'Loss/localization_loss': 0.0024856192,\n",
            " 'Loss/regularization_loss': 0.09609038,\n",
            " 'Loss/total_loss': 0.11954386,\n",
            " 'learning_rate': 0.007618121}\n",
            "I0711 17:36:46.195148 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.020967862,\n",
            " 'Loss/localization_loss': 0.0024856192,\n",
            " 'Loss/regularization_loss': 0.09609038,\n",
            " 'Loss/total_loss': 0.11954386,\n",
            " 'learning_rate': 0.007618121}\n",
            "INFO:tensorflow:Step 7800 per-step time 0.971s\n",
            "I0711 17:38:23.289965 140349244585856 model_lib_v2.py:700] Step 7800 per-step time 0.971s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.025433851,\n",
            " 'Loss/localization_loss': 0.0037111256,\n",
            " 'Loss/regularization_loss': 0.095585726,\n",
            " 'Loss/total_loss': 0.124730706,\n",
            " 'learning_rate': 0.0070110355}\n",
            "I0711 17:38:23.290262 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.025433851,\n",
            " 'Loss/localization_loss': 0.0037111256,\n",
            " 'Loss/regularization_loss': 0.095585726,\n",
            " 'Loss/total_loss': 0.124730706,\n",
            " 'learning_rate': 0.0070110355}\n",
            "INFO:tensorflow:Step 7900 per-step time 0.970s\n",
            "I0711 17:40:00.303166 140349244585856 model_lib_v2.py:700] Step 7900 per-step time 0.970s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.027496135,\n",
            " 'Loss/localization_loss': 0.0030283276,\n",
            " 'Loss/regularization_loss': 0.09511573,\n",
            " 'Loss/total_loss': 0.12564018,\n",
            " 'learning_rate': 0.0064239847}\n",
            "I0711 17:40:00.303540 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.027496135,\n",
            " 'Loss/localization_loss': 0.0030283276,\n",
            " 'Loss/regularization_loss': 0.09511573,\n",
            " 'Loss/total_loss': 0.12564018,\n",
            " 'learning_rate': 0.0064239847}\n",
            "INFO:tensorflow:Step 8000 per-step time 0.971s\n",
            "I0711 17:41:37.428134 140349244585856 model_lib_v2.py:700] Step 8000 per-step time 0.971s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.033888455,\n",
            " 'Loss/localization_loss': 0.009672873,\n",
            " 'Loss/regularization_loss': 0.09468938,\n",
            " 'Loss/total_loss': 0.13825071,\n",
            " 'learning_rate': 0.0058578644}\n",
            "I0711 17:41:37.428425 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.033888455,\n",
            " 'Loss/localization_loss': 0.009672873,\n",
            " 'Loss/regularization_loss': 0.09468938,\n",
            " 'Loss/total_loss': 0.13825071,\n",
            " 'learning_rate': 0.0058578644}\n",
            "INFO:tensorflow:Step 8100 per-step time 1.000s\n",
            "I0711 17:43:17.434131 140349244585856 model_lib_v2.py:700] Step 8100 per-step time 1.000s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.032687917,\n",
            " 'Loss/localization_loss': 0.0070867497,\n",
            " 'Loss/regularization_loss': 0.094299,\n",
            " 'Loss/total_loss': 0.13407367,\n",
            " 'learning_rate': 0.0053135487}\n",
            "I0711 17:43:17.434494 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.032687917,\n",
            " 'Loss/localization_loss': 0.0070867497,\n",
            " 'Loss/regularization_loss': 0.094299,\n",
            " 'Loss/total_loss': 0.13407367,\n",
            " 'learning_rate': 0.0053135487}\n",
            "INFO:tensorflow:Step 8200 per-step time 0.971s\n",
            "I0711 17:44:54.527086 140349244585856 model_lib_v2.py:700] Step 8200 per-step time 0.971s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.021341354,\n",
            " 'Loss/localization_loss': 0.0037353844,\n",
            " 'Loss/regularization_loss': 0.09394331,\n",
            " 'Loss/total_loss': 0.11902005,\n",
            " 'learning_rate': 0.0047918796}\n",
            "I0711 17:44:54.527376 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.021341354,\n",
            " 'Loss/localization_loss': 0.0037353844,\n",
            " 'Loss/regularization_loss': 0.09394331,\n",
            " 'Loss/total_loss': 0.11902005,\n",
            " 'learning_rate': 0.0047918796}\n",
            "INFO:tensorflow:Step 8300 per-step time 0.971s\n",
            "I0711 17:46:31.615243 140349244585856 model_lib_v2.py:700] Step 8300 per-step time 0.971s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.033424802,\n",
            " 'Loss/localization_loss': 0.006249827,\n",
            " 'Loss/regularization_loss': 0.0936221,\n",
            " 'Loss/total_loss': 0.13329673,\n",
            " 'learning_rate': 0.0042936574}\n",
            "I0711 17:46:31.615548 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.033424802,\n",
            " 'Loss/localization_loss': 0.006249827,\n",
            " 'Loss/regularization_loss': 0.0936221,\n",
            " 'Loss/total_loss': 0.13329673,\n",
            " 'learning_rate': 0.0042936574}\n",
            "INFO:tensorflow:Step 8400 per-step time 0.971s\n",
            "I0711 17:48:08.718930 140349244585856 model_lib_v2.py:700] Step 8400 per-step time 0.971s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.019908683,\n",
            " 'Loss/localization_loss': 0.0026090913,\n",
            " 'Loss/regularization_loss': 0.09333927,\n",
            " 'Loss/total_loss': 0.11585705,\n",
            " 'learning_rate': 0.0038196587}\n",
            "I0711 17:48:08.719233 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.019908683,\n",
            " 'Loss/localization_loss': 0.0026090913,\n",
            " 'Loss/regularization_loss': 0.09333927,\n",
            " 'Loss/total_loss': 0.11585705,\n",
            " 'learning_rate': 0.0038196587}\n",
            "INFO:tensorflow:Step 8500 per-step time 0.971s\n",
            "I0711 17:49:45.804558 140349244585856 model_lib_v2.py:700] Step 8500 per-step time 0.971s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.018187743,\n",
            " 'Loss/localization_loss': 0.0025065697,\n",
            " 'Loss/regularization_loss': 0.09308363,\n",
            " 'Loss/total_loss': 0.113777936,\n",
            " 'learning_rate': 0.0033706068}\n",
            "I0711 17:49:45.804851 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.018187743,\n",
            " 'Loss/localization_loss': 0.0025065697,\n",
            " 'Loss/regularization_loss': 0.09308363,\n",
            " 'Loss/total_loss': 0.113777936,\n",
            " 'learning_rate': 0.0033706068}\n",
            "INFO:tensorflow:Step 8600 per-step time 0.971s\n",
            "I0711 17:51:22.873561 140349244585856 model_lib_v2.py:700] Step 8600 per-step time 0.971s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.019850112,\n",
            " 'Loss/localization_loss': 0.0018835143,\n",
            " 'Loss/regularization_loss': 0.09285975,\n",
            " 'Loss/total_loss': 0.11459338,\n",
            " 'learning_rate': 0.0029471957}\n",
            "I0711 17:51:22.873887 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.019850112,\n",
            " 'Loss/localization_loss': 0.0018835143,\n",
            " 'Loss/regularization_loss': 0.09285975,\n",
            " 'Loss/total_loss': 0.11459338,\n",
            " 'learning_rate': 0.0029471957}\n",
            "INFO:tensorflow:Step 8700 per-step time 0.970s\n",
            "I0711 17:52:59.880275 140349244585856 model_lib_v2.py:700] Step 8700 per-step time 0.970s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.01630157,\n",
            " 'Loss/localization_loss': 0.0014768142,\n",
            " 'Loss/regularization_loss': 0.09266294,\n",
            " 'Loss/total_loss': 0.11044133,\n",
            " 'learning_rate': 0.0025500786}\n",
            "I0711 17:52:59.880593 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.01630157,\n",
            " 'Loss/localization_loss': 0.0014768142,\n",
            " 'Loss/regularization_loss': 0.09266294,\n",
            " 'Loss/total_loss': 0.11044133,\n",
            " 'learning_rate': 0.0025500786}\n",
            "INFO:tensorflow:Step 8800 per-step time 0.970s\n",
            "I0711 17:54:36.918600 140349244585856 model_lib_v2.py:700] Step 8800 per-step time 0.970s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.015234782,\n",
            " 'Loss/localization_loss': 0.0019106066,\n",
            " 'Loss/regularization_loss': 0.09249444,\n",
            " 'Loss/total_loss': 0.10963983,\n",
            " 'learning_rate': 0.0021798706}\n",
            "I0711 17:54:36.918894 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.015234782,\n",
            " 'Loss/localization_loss': 0.0019106066,\n",
            " 'Loss/regularization_loss': 0.09249444,\n",
            " 'Loss/total_loss': 0.10963983,\n",
            " 'learning_rate': 0.0021798706}\n",
            "INFO:tensorflow:Step 8900 per-step time 0.971s\n",
            "I0711 17:56:13.986788 140349244585856 model_lib_v2.py:700] Step 8900 per-step time 0.971s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.050074063,\n",
            " 'Loss/localization_loss': 0.012938766,\n",
            " 'Loss/regularization_loss': 0.09235031,\n",
            " 'Loss/total_loss': 0.15536314,\n",
            " 'learning_rate': 0.0018371355}\n",
            "I0711 17:56:13.987079 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.050074063,\n",
            " 'Loss/localization_loss': 0.012938766,\n",
            " 'Loss/regularization_loss': 0.09235031,\n",
            " 'Loss/total_loss': 0.15536314,\n",
            " 'learning_rate': 0.0018371355}\n",
            "INFO:tensorflow:Step 9000 per-step time 0.971s\n",
            "I0711 17:57:51.097226 140349244585856 model_lib_v2.py:700] Step 9000 per-step time 0.971s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.019587293,\n",
            " 'Loss/localization_loss': 0.0020384495,\n",
            " 'Loss/regularization_loss': 0.09222977,\n",
            " 'Loss/total_loss': 0.11385551,\n",
            " 'learning_rate': 0.0015224098}\n",
            "I0711 17:57:51.097528 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.019587293,\n",
            " 'Loss/localization_loss': 0.0020384495,\n",
            " 'Loss/regularization_loss': 0.09222977,\n",
            " 'Loss/total_loss': 0.11385551,\n",
            " 'learning_rate': 0.0015224098}\n",
            "INFO:tensorflow:Step 9100 per-step time 0.986s\n",
            "I0711 17:59:29.667667 140349244585856 model_lib_v2.py:700] Step 9100 per-step time 0.986s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.03614593,\n",
            " 'Loss/localization_loss': 0.005721212,\n",
            " 'Loss/regularization_loss': 0.092129976,\n",
            " 'Loss/total_loss': 0.13399711,\n",
            " 'learning_rate': 0.0012361717}\n",
            "I0711 17:59:29.667961 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.03614593,\n",
            " 'Loss/localization_loss': 0.005721212,\n",
            " 'Loss/regularization_loss': 0.092129976,\n",
            " 'Loss/total_loss': 0.13399711,\n",
            " 'learning_rate': 0.0012361717}\n",
            "INFO:tensorflow:Step 9200 per-step time 0.970s\n",
            "I0711 18:01:06.696662 140349244585856 model_lib_v2.py:700] Step 9200 per-step time 0.970s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.023201277,\n",
            " 'Loss/localization_loss': 0.004170124,\n",
            " 'Loss/regularization_loss': 0.09205034,\n",
            " 'Loss/total_loss': 0.119421735,\n",
            " 'learning_rate': 0.0009788703}\n",
            "I0711 18:01:06.696949 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.023201277,\n",
            " 'Loss/localization_loss': 0.004170124,\n",
            " 'Loss/regularization_loss': 0.09205034,\n",
            " 'Loss/total_loss': 0.119421735,\n",
            " 'learning_rate': 0.0009788703}\n",
            "INFO:tensorflow:Step 9300 per-step time 0.971s\n",
            "I0711 18:02:43.795227 140349244585856 model_lib_v2.py:700] Step 9300 per-step time 0.971s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.018692626,\n",
            " 'Loss/localization_loss': 0.005224893,\n",
            " 'Loss/regularization_loss': 0.09198777,\n",
            " 'Loss/total_loss': 0.115905285,\n",
            " 'learning_rate': 0.0007508957}\n",
            "I0711 18:02:43.795581 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.018692626,\n",
            " 'Loss/localization_loss': 0.005224893,\n",
            " 'Loss/regularization_loss': 0.09198777,\n",
            " 'Loss/total_loss': 0.115905285,\n",
            " 'learning_rate': 0.0007508957}\n",
            "INFO:tensorflow:Step 9400 per-step time 0.971s\n",
            "I0711 18:04:20.917649 140349244585856 model_lib_v2.py:700] Step 9400 per-step time 0.971s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.020518739,\n",
            " 'Loss/localization_loss': 0.0033603283,\n",
            " 'Loss/regularization_loss': 0.091940425,\n",
            " 'Loss/total_loss': 0.11581949,\n",
            " 'learning_rate': 0.0005526006}\n",
            "I0711 18:04:20.917945 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.020518739,\n",
            " 'Loss/localization_loss': 0.0033603283,\n",
            " 'Loss/regularization_loss': 0.091940425,\n",
            " 'Loss/total_loss': 0.11581949,\n",
            " 'learning_rate': 0.0005526006}\n",
            "INFO:tensorflow:Step 9500 per-step time 0.971s\n",
            "I0711 18:05:58.027735 140349244585856 model_lib_v2.py:700] Step 9500 per-step time 0.971s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.021144267,\n",
            " 'Loss/localization_loss': 0.004144082,\n",
            " 'Loss/regularization_loss': 0.09190599,\n",
            " 'Loss/total_loss': 0.11719434,\n",
            " 'learning_rate': 0.0003842938}\n",
            "I0711 18:05:58.028083 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.021144267,\n",
            " 'Loss/localization_loss': 0.004144082,\n",
            " 'Loss/regularization_loss': 0.09190599,\n",
            " 'Loss/total_loss': 0.11719434,\n",
            " 'learning_rate': 0.0003842938}\n",
            "INFO:tensorflow:Step 9600 per-step time 0.971s\n",
            "I0711 18:07:35.164421 140349244585856 model_lib_v2.py:700] Step 9600 per-step time 0.971s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.016191768,\n",
            " 'Loss/localization_loss': 0.0011375485,\n",
            " 'Loss/regularization_loss': 0.091882445,\n",
            " 'Loss/total_loss': 0.10921176,\n",
            " 'learning_rate': 0.00024623275}\n",
            "I0711 18:07:35.164746 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.016191768,\n",
            " 'Loss/localization_loss': 0.0011375485,\n",
            " 'Loss/regularization_loss': 0.091882445,\n",
            " 'Loss/total_loss': 0.10921176,\n",
            " 'learning_rate': 0.00024623275}\n",
            "INFO:tensorflow:Step 9700 per-step time 0.970s\n",
            "I0711 18:09:12.194883 140349244585856 model_lib_v2.py:700] Step 9700 per-step time 0.970s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.01794994,\n",
            " 'Loss/localization_loss': 0.0022036098,\n",
            " 'Loss/regularization_loss': 0.09186811,\n",
            " 'Loss/total_loss': 0.11202166,\n",
            " 'learning_rate': 0.00013863086}\n",
            "I0711 18:09:12.195244 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.01794994,\n",
            " 'Loss/localization_loss': 0.0022036098,\n",
            " 'Loss/regularization_loss': 0.09186811,\n",
            " 'Loss/total_loss': 0.11202166,\n",
            " 'learning_rate': 0.00013863086}\n",
            "INFO:tensorflow:Step 9800 per-step time 0.971s\n",
            "I0711 18:10:49.323102 140349244585856 model_lib_v2.py:700] Step 9800 per-step time 0.971s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.01947557,\n",
            " 'Loss/localization_loss': 0.0042772563,\n",
            " 'Loss/regularization_loss': 0.09186073,\n",
            " 'Loss/total_loss': 0.11561355,\n",
            " 'learning_rate': 6.165266e-05}\n",
            "I0711 18:10:49.323404 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.01947557,\n",
            " 'Loss/localization_loss': 0.0042772563,\n",
            " 'Loss/regularization_loss': 0.09186073,\n",
            " 'Loss/total_loss': 0.11561355,\n",
            " 'learning_rate': 6.165266e-05}\n",
            "INFO:tensorflow:Step 9900 per-step time 0.971s\n",
            "I0711 18:12:26.433085 140349244585856 model_lib_v2.py:700] Step 9900 per-step time 0.971s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.017290609,\n",
            " 'Loss/localization_loss': 0.0023733887,\n",
            " 'Loss/regularization_loss': 0.091857776,\n",
            " 'Loss/total_loss': 0.11152177,\n",
            " 'learning_rate': 1.541972e-05}\n",
            "I0711 18:12:26.433376 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.017290609,\n",
            " 'Loss/localization_loss': 0.0023733887,\n",
            " 'Loss/regularization_loss': 0.091857776,\n",
            " 'Loss/total_loss': 0.11152177,\n",
            " 'learning_rate': 1.541972e-05}\n",
            "INFO:tensorflow:Step 10000 per-step time 0.971s\n",
            "I0711 18:14:03.500886 140349244585856 model_lib_v2.py:700] Step 10000 per-step time 0.971s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.017715132,\n",
            " 'Loss/localization_loss': 0.0014132076,\n",
            " 'Loss/regularization_loss': 0.09185727,\n",
            " 'Loss/total_loss': 0.11098561,\n",
            " 'learning_rate': 0.0}\n",
            "I0711 18:14:03.501177 140349244585856 model_lib_v2.py:701] {'Loss/classification_loss': 0.017715132,\n",
            " 'Loss/localization_loss': 0.0014132076,\n",
            " 'Loss/regularization_loss': 0.09185727,\n",
            " 'Loss/total_loss': 0.11098561,\n",
            " 'learning_rate': 0.0}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "EYmIuo9Nd3F3",
        "outputId": "3117533d-6e6e-4c8c-8da8-38bd9aee3f64"
      },
      "source": [
        "pwd"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/training_demo'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9vpOWvMvch92",
        "outputId": "e2514043-3236-42eb-f8c6-ea10cd3512c7"
      },
      "source": [
        "!python exporter_main_v2.py --input_type image_tensor --pipeline_config_path /content/training_demo/models/my_ssd_resnet101_v1_fpn/pipeline.config --trained_checkpoint_dir /content/training_demo/models/my_ssd_resnet101_v1_fpn --output_directory /content/training_demo/exported_models/my_model"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-07-11 18:15:33.578474: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-07-11 18:15:35.603935: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "2021-07-11 18:15:35.604836: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
            "2021-07-11 18:15:35.626837: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-11 18:15:35.627416: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\n",
            "coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n",
            "2021-07-11 18:15:35.627444: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-07-11 18:15:35.629995: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
            "2021-07-11 18:15:35.630055: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
            "2021-07-11 18:15:35.631773: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
            "2021-07-11 18:15:35.632070: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
            "2021-07-11 18:15:35.633928: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-07-11 18:15:35.634541: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
            "2021-07-11 18:15:35.634713: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
            "2021-07-11 18:15:35.634813: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-11 18:15:35.635373: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-11 18:15:35.635924: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
            "2021-07-11 18:15:35.636231: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2021-07-11 18:15:35.636413: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "2021-07-11 18:15:35.636542: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-11 18:15:35.637100: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\n",
            "coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n",
            "2021-07-11 18:15:35.637128: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-07-11 18:15:35.637161: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
            "2021-07-11 18:15:35.637183: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
            "2021-07-11 18:15:35.637203: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
            "2021-07-11 18:15:35.637222: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
            "2021-07-11 18:15:35.637244: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-07-11 18:15:35.637263: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
            "2021-07-11 18:15:35.637283: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
            "2021-07-11 18:15:35.637348: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-11 18:15:35.637975: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-11 18:15:35.638498: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
            "2021-07-11 18:15:35.638543: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-07-11 18:15:36.310850: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-07-11 18:15:36.310899: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
            "2021-07-11 18:15:36.310911: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
            "2021-07-11 18:15:36.311118: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-11 18:15:36.311779: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-11 18:15:36.312352: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-11 18:15:36.312876: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2021-07-11 18:15:36.312927: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14957 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "WARNING:tensorflow:AutoGraph could not transform <bound method DetectionInferenceModule._preprocess_input of <object_detection.exporter_lib_v2.DetectionFromImageModule object at 0x7f2fcc6a2b90>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "W0711 18:15:36.398858 139845233276800 ag_logging.py:146] AutoGraph could not transform <bound method DetectionInferenceModule._preprocess_input of <object_detection.exporter_lib_v2.DetectionFromImageModule object at 0x7f2fcc6a2b90>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/exporter_lib_v2.py:111: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
            "Instead of:\n",
            "results = tf.map_fn(fn, elems, back_prop=False)\n",
            "Use:\n",
            "results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n",
            "W0711 18:15:36.399232 139845233276800 deprecation.py:604] From /usr/local/lib/python3.7/dist-packages/object_detection/exporter_lib_v2.py:111: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
            "Instead of:\n",
            "results = tf.map_fn(fn, elems, back_prop=False)\n",
            "Use:\n",
            "results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n",
            "WARNING:tensorflow:AutoGraph could not transform <function DetectionInferenceModule._preprocess_input.<locals>._decode_and_preprocess at 0x7f2f7e1043b0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "W0711 18:15:36.418596 139845233276800 ag_logging.py:146] AutoGraph could not transform <function DetectionInferenceModule._preprocess_input.<locals>._decode_and_preprocess at 0x7f2f7e1043b0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <bound method DetectionInferenceModule._run_inference_on_images of <object_detection.exporter_lib_v2.DetectionFromImageModule object at 0x7f2fcc6a2b90>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "W0711 18:15:36.455590 139845233276800 ag_logging.py:146] AutoGraph could not transform <bound method DetectionInferenceModule._run_inference_on_images of <object_detection.exporter_lib_v2.DetectionFromImageModule object at 0x7f2fcc6a2b90>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <bound method SSDResNetV1FpnKerasFeatureExtractor._extract_features of <object_detection.models.ssd_resnet_v1_fpn_keras_feature_extractor.SSDResNet101V1FpnKerasFeatureExtractor object at 0x7f2fccef9950>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "W0711 18:15:40.365025 139845233276800 ag_logging.py:146] AutoGraph could not transform <bound method SSDResNetV1FpnKerasFeatureExtractor._extract_features of <object_detection.models.ssd_resnet_v1_fpn_keras_feature_extractor.SSDResNet101V1FpnKerasFeatureExtractor object at 0x7f2fccef9950>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <bound method KerasFpnTopDownFeatureMaps.call of <object_detection.models.feature_map_generators.KerasFpnTopDownFeatureMaps object at 0x7f2f662b6f10>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "W0711 18:15:41.002318 139845233276800 ag_logging.py:146] AutoGraph could not transform <bound method KerasFpnTopDownFeatureMaps.call of <object_detection.models.feature_map_generators.KerasFpnTopDownFeatureMaps object at 0x7f2f662b6f10>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <bound method WeightSharedConvolutionalBoxPredictor._predict of <object_detection.predictors.convolutional_keras_box_predictor.WeightSharedConvolutionalBoxPredictor object at 0x7f2fc00d3a10>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "W0711 18:15:41.766542 139845233276800 ag_logging.py:146] AutoGraph could not transform <bound method WeightSharedConvolutionalBoxPredictor._predict of <object_detection.predictors.convolutional_keras_box_predictor.WeightSharedConvolutionalBoxPredictor object at 0x7f2fc00d3a10>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <bound method WeightSharedConvolutionalBoxHead._predict of <object_detection.predictors.heads.keras_box_head.WeightSharedConvolutionalBoxHead object at 0x7f2fc00a03d0>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "W0711 18:15:41.848453 139845233276800 ag_logging.py:146] AutoGraph could not transform <bound method WeightSharedConvolutionalBoxHead._predict of <object_detection.predictors.heads.keras_box_head.WeightSharedConvolutionalBoxHead object at 0x7f2fc00a03d0>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <bound method WeightSharedConvolutionalClassHead._predict of <object_detection.predictors.heads.keras_class_head.WeightSharedConvolutionalClassHead object at 0x7f2fc00a0f10>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "W0711 18:15:41.919605 139845233276800 ag_logging.py:146] AutoGraph could not transform <bound method WeightSharedConvolutionalClassHead._predict of <object_detection.predictors.heads.keras_class_head.WeightSharedConvolutionalClassHead object at 0x7f2fc00a0f10>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function DetectionInferenceModule._preprocess_input.<locals>._decode_and_preprocess at 0x7f2f576ff050> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "W0711 18:15:43.034549 139845233276800 ag_logging.py:146] AutoGraph could not transform <function DetectionInferenceModule._preprocess_input.<locals>._decode_and_preprocess at 0x7f2f576ff050> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7f2fcc323d90>, because it is not built.\n",
            "W0711 18:15:48.114811 139845233276800 save_impl.py:78] Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7f2fcc323d90>, because it is not built.\n",
            "2021-07-11 18:16:08.065411: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
            "WARNING:tensorflow:AutoGraph could not transform <function DetectionInferenceModule._preprocess_input.<locals>._decode_and_preprocess at 0x7f2f508e9a70> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "W0711 18:16:08.342060 139845233276800 ag_logging.py:146] AutoGraph could not transform <function DetectionInferenceModule._preprocess_input.<locals>._decode_and_preprocess at 0x7f2f508e9a70> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f467390>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f467550>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f467790>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], False), {}).\n",
            "I0711 18:16:21.632989 139845233276800 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f467390>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f467550>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f467790>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], False), {}).\n",
            "INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f4548d0>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f454e50>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f4590d0>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], True), {}).\n",
            "I0711 18:16:21.633267 139845233276800 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f4548d0>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f454e50>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f4590d0>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], True), {}).\n",
            "INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f496b90>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f496c10>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f49c390>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], False), {}).\n",
            "I0711 18:16:21.633435 139845233276800 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f496b90>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f496c10>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f49c390>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], False), {}).\n",
            "INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f4fe210>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f4fe150>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f4fc550>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], True), {}).\n",
            "I0711 18:16:21.633612 139845233276800 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f4fe210>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f4fe150>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f4fc550>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], True), {}).\n",
            "INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f467390>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f467550>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f467790>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], False), {}).\n",
            "I0711 18:16:32.297509 139845233276800 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f467390>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f467550>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f467790>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], False), {}).\n",
            "INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f4548d0>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f454e50>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f4590d0>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], True), {}).\n",
            "I0711 18:16:32.297817 139845233276800 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f4548d0>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f454e50>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f4590d0>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], True), {}).\n",
            "INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f496b90>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f496c10>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f49c390>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], False), {}).\n",
            "I0711 18:16:32.298032 139845233276800 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f496b90>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f496c10>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f49c390>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], False), {}).\n",
            "INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f4fe210>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f4fe150>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f4fc550>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], True), {}).\n",
            "I0711 18:16:32.298208 139845233276800 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f4fe210>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f4fe150>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f4fc550>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], True), {}).\n",
            "INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f496b90>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f496c10>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f49c390>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], False), {}).\n",
            "I0711 18:16:32.298403 139845233276800 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f496b90>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f496c10>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f49c390>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], False), {}).\n",
            "INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f4fe210>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f4fe150>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f4fc550>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], True), {}).\n",
            "I0711 18:16:32.298590 139845233276800 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f4fe210>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f4fe150>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f4fc550>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], True), {}).\n",
            "W0711 18:16:37.716673 139845233276800 save.py:241] Found untraced functions such as WeightSharedConvolutionalBoxPredictor_layer_call_fn, WeightSharedConvolutionalBoxPredictor_layer_call_and_return_conditional_losses, WeightSharedConvolutionalBoxHead_layer_call_fn, WeightSharedConvolutionalBoxHead_layer_call_and_return_conditional_losses, WeightSharedConvolutionalBoxPredictor_layer_call_fn while saving (showing 5 of 315). These functions will not be directly callable after loading.\n",
            "INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f467390>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f467550>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f467790>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], False), {}).\n",
            "I0711 18:16:38.107218 139845233276800 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f467390>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f467550>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f467790>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], False), {}).\n",
            "INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f4548d0>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f454e50>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f4590d0>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], True), {}).\n",
            "I0711 18:16:38.107560 139845233276800 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f4548d0>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f454e50>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f4590d0>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], True), {}).\n",
            "INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f496b90>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f496c10>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f49c390>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], False), {}).\n",
            "I0711 18:16:38.107788 139845233276800 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f496b90>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f496c10>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f49c390>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], False), {}).\n",
            "INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f4fe210>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f4fe150>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f4fc550>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], True), {}).\n",
            "I0711 18:16:38.107965 139845233276800 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f4fe210>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f4fe150>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f4fc550>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], True), {}).\n",
            "INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f467390>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f467550>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f467790>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], False), {}).\n",
            "I0711 18:16:38.701032 139845233276800 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f467390>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f467550>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f467790>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], False), {}).\n",
            "INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f4548d0>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f454e50>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f4590d0>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], True), {}).\n",
            "I0711 18:16:38.701360 139845233276800 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f4548d0>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f454e50>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f4590d0>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], True), {}).\n",
            "INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f496b90>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f496c10>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f49c390>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], False), {}).\n",
            "I0711 18:16:38.701593 139845233276800 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f496b90>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f496c10>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f49c390>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], False), {}).\n",
            "INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f4fe210>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f4fe150>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f4fc550>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], True), {}).\n",
            "I0711 18:16:38.701779 139845233276800 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f4fe210>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f4fe150>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f4fc550>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], True), {}).\n",
            "INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f496b90>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f496c10>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f49c390>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], False), {}).\n",
            "I0711 18:16:38.701972 139845233276800 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f496b90>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f496c10>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f49c390>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], False), {}).\n",
            "INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f4fe210>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f4fe150>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f4fc550>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], True), {}).\n",
            "I0711 18:16:38.702136 139845233276800 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f4fe210>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f4fe150>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f4fc550>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], True), {}).\n",
            "W0711 18:16:39.733599 139845233276800 save.py:241] Found untraced functions such as WeightSharedConvolutionalBoxPredictor_layer_call_fn, WeightSharedConvolutionalBoxPredictor_layer_call_and_return_conditional_losses, WeightSharedConvolutionalBoxHead_layer_call_fn, WeightSharedConvolutionalBoxHead_layer_call_and_return_conditional_losses, WeightSharedConvolutionalBoxPredictor_layer_call_fn while saving (showing 5 of 315). These functions will not be directly callable after loading.\n",
            "INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f467390>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f467550>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f467790>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], False), {}).\n",
            "I0711 18:16:46.455459 139845233276800 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f467390>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f467550>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f467790>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], False), {}).\n",
            "INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f4548d0>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f454e50>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f4590d0>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], True), {}).\n",
            "I0711 18:16:46.455808 139845233276800 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f4548d0>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f454e50>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f4590d0>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], True), {}).\n",
            "INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f496b90>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f496c10>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f49c390>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], False), {}).\n",
            "I0711 18:16:46.456253 139845233276800 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f496b90>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f496c10>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f49c390>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], False), {}).\n",
            "INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f4fe210>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f4fe150>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f4fc550>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], True), {}).\n",
            "I0711 18:16:46.456478 139845233276800 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f4fe210>, TensorSpec(shape=(None, 80, 80, 512), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f4fe150>, TensorSpec(shape=(None, 40, 40, 1024), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f2f4f4fc550>, TensorSpec(shape=(None, 20, 20, 2048), dtype=tf.float32, name='image_features/2/1'))], True), {}).\n",
            "INFO:tensorflow:Assets written to: /content/training_demo/exported_models/my_model/saved_model/assets\n",
            "I0711 18:16:48.418128 139845233276800 builder_impl.py:775] Assets written to: /content/training_demo/exported_models/my_model/saved_model/assets\n",
            "INFO:tensorflow:Writing pipeline config file to /content/training_demo/exported_models/my_model/pipeline.config\n",
            "I0711 18:16:49.599929 139845233276800 config_util.py:254] Writing pipeline config file to /content/training_demo/exported_models/my_model/pipeline.config\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "id": "PufE9qWLciAP",
        "outputId": "0d24c6b5-ed41-4f70-c316-f1238f981b51"
      },
      "source": [
        "\"\"\"\n",
        "Object Detection (On Image) From TF2 Saved Model\n",
        "=====================================\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'    # Suppress TensorFlow logging (1)\n",
        "import pathlib\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import argparse\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Enable GPU dynamic memory allocation\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "for gpu in gpus:\n",
        "    tf.config.experimental.set_memory_growth(gpu, True)\n",
        "\n",
        "# PROVIDE PATH TO IMAGE DIRECTORY\n",
        "IMAGE_PATHS = '/content/training_demo/images/train/img48.jpg'\n",
        "\n",
        "\n",
        "# PROVIDE PATH TO MODEL DIRECTORY\n",
        "PATH_TO_MODEL_DIR = '/content/training_demo/exported_models/my_model'\n",
        "\n",
        "# PROVIDE PATH TO LABEL MAP\n",
        "PATH_TO_LABELS = '/content/training_demo/annotations/label_map.pbtxt'\n",
        "\n",
        "# PROVIDE THE MINIMUM CONFIDENCE THRESHOLD\n",
        "MIN_CONF_THRESH = float(0.60)\n",
        "\n",
        "# LOAD THE MODEL\n",
        "\n",
        "import time\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "\n",
        "PATH_TO_SAVED_MODEL = PATH_TO_MODEL_DIR + \"/saved_model\"\n",
        "\n",
        "print('Loading model...', end='')\n",
        "start_time = time.time()\n",
        "\n",
        "# LOAD SAVED MODEL AND BUILD DETECTION FUNCTION\n",
        "detect_fn = tf.saved_model.load(PATH_TO_SAVED_MODEL)\n",
        "\n",
        "end_time = time.time()\n",
        "elapsed_time = end_time - start_time\n",
        "print('Done! Took {} seconds'.format(elapsed_time))\n",
        "\n",
        "# LOAD LABEL MAP DATA FOR PLOTTING\n",
        "\n",
        "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS,\n",
        "                                                                    use_display_name=True)\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')   # Suppress Matplotlib warnings\n",
        "\n",
        "def load_image_into_numpy_array(path):\n",
        "    \"\"\"Load an image from file into a numpy array.\n",
        "    Puts image into numpy array to feed into tensorflow graph.\n",
        "    Note that by convention we put it into a numpy array with shape\n",
        "    (height, width, channels), where channels=3 for RGB.\n",
        "    Args:\n",
        "      path: the file path to the image\n",
        "    Returns:\n",
        "      uint8 numpy array with shape (img_height, img_width, 3)\n",
        "    \"\"\"\n",
        "    return np.array(Image.open(path))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print('Running inference for {}... '.format(IMAGE_PATHS), end='')\n",
        "\n",
        "image = cv2.imread(IMAGE_PATHS)\n",
        "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "image_expanded = np.expand_dims(image_rgb, axis=0)\n",
        "\n",
        "# The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n",
        "input_tensor = tf.convert_to_tensor(image)\n",
        "# The model expects a batch of images, so add an axis with `tf.newaxis`.\n",
        "input_tensor = input_tensor[tf.newaxis, ...]\n",
        "\n",
        "# input_tensor = np.expand_dims(image_np, 0)\n",
        "detections = detect_fn(input_tensor)\n",
        "\n",
        "# All outputs are batches tensors.\n",
        "# Convert to numpy arrays, and take index [0] to remove the batch dimension.\n",
        "# We're only interested in the first num_detections.\n",
        "num_detections = int(detections.pop('num_detections'))\n",
        "detections = {key: value[0, :num_detections].numpy()\n",
        "               for key, value in detections.items()}\n",
        "detections['num_detections'] = num_detections\n",
        "\n",
        "# detection_classes should be ints.\n",
        "detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
        "\n",
        "image_with_detections = image.copy()\n",
        "\n",
        "# SET MIN_SCORE_THRESH BASED ON YOU MINIMUM THRESHOLD FOR DETECTIONS\n",
        "viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "      image_with_detections,\n",
        "      detections['detection_boxes'],\n",
        "      detections['detection_classes'],\n",
        "      detections['detection_scores'],\n",
        "      category_index,\n",
        "      use_normalized_coordinates=True,\n",
        "      max_boxes_to_draw=200,\n",
        "      min_score_thresh=0.5,\n",
        "      agnostic_mode=False)\n",
        "\n",
        "print('Done')\n",
        "# DISPLAYS OUTPUT IMAGE\n",
        "cv2_imshow(image_with_detections)\n",
        "# CLOSES WINDOW ONCE KEY IS PRESSED\n"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading model...Done! Took 20.41610074043274 seconds\n",
            "Running inference for /content/training_demo/images/train/img48.jpg... Done\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=275x183 at 0x7F7A7B7D3650>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isR3eRTqciDF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMuTH3xEciFX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seeBYxXFciIU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}